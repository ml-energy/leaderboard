#!/bin/bash
### Llama-2-70b

############################## vLLM server ##############################

# vllm
docker run --gpus all --shm-size 1g -p 8000:8000 \
        --runtime nvidia \
        --network benchmark-net \
        -e HUGGING_FACE_HUB_TOKEN=$token \
        -v ~/.cache/huggingface:/root/.cache/huggingface \
        --name vllm_llama70 \
        -d vllm/vllm-openai:latest \
        --tensor-parallel-size 4 \
        --model meta-llama/Llama-2-70b-chat-hf

############################## GPUs all, rr=0.25 ##############################

# Benchmark
docker run \
        --gpus all \
        --name llama70_25 \
        --network benchmark-net \
        -v /home/ohjun/leaderboard/sharegpt:/data \
        -v /home/ohjun/leaderboard/scripts/vllm-script/results:/results \
        -d benchmark:latest \
        --backend vllm \
        --dataset /data/ShareGPT_V3_filtered_1000.json \
        --host vllm_llama70 \
        --port 8000 \
        --model meta-llama/Llama-2-70b-chat-hf \
        --out-filename /results/vllm-llama2-70b-rr025 \
        --request-rate 0.25 \
        --num-runs 1

############################## GPUs all, rr=0.50 ##############################
# Benchmark
docker run \
        --gpus all \
        --name llama70_50 \
        --network benchmark-net \
        -v /home/ohjun/leaderboard/sharegpt:/data \
        -v /home/ohjun/leaderboard/scripts/vllm-script/results:/results \
        -d benchmark:latest \
        --backend vllm \
        --dataset /data/ShareGPT_V3_filtered_1000.json \
        --host vllm_llama70 \
        --port 8000 \
        --model meta-llama/Llama-2-70b-chat-hf \
        --out-filename /results/vllm-llama2-70b-rr050 \
        --request-rate 0.5 \
        --num-runs 1


############################## GPUs all, rr=0.75 ##############################
# Benchmark
docker run \
        --gpus all \
        --name llama70_75 \
        --network benchmark-net \
        -v /home/ohjun/leaderboard/sharegpt:/data \
        -v /home/ohjun/leaderboard/scripts/vllm-script/results:/results \
        -d benchmark:latest \
        --backend vllm \
        --dataset /data/ShareGPT_V3_filtered_1000.json \
        --host vllm_llama70 \
        --port 8000 \
        --model meta-llama/Llama-2-70b-chat-hf \
        --out-filename /results/vllm-llama2-70b-rr075 \
        --request-rate 0.75 \
        --num-runs 1

############################## GPUs all, rr=1.00 ##############################
# Benchmark
docker run \
        --gpus all \
        --name llama70_1 \
        --network benchmark-net \
        -v /home/ohjun/leaderboard/sharegpt:/data \
        -v /home/ohjun/leaderboard/scripts/vllm-script/results:/results \
        -d benchmark:latest \
        --backend vllm \
        --dataset /data/ShareGPT_V3_filtered_1000.json \
        --host vllm_llama70 \
        --port 8000 \
        --model meta-llama/Llama-2-70b-chat-hf \
        --out-filename /results/vllm-llama2-70b-rr100 \
        --request-rate 1 \
        --num-runs 1
