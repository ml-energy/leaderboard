{
  "task": "lm-arena-chat",
  "task_display_name": "LLM Chat (LM Arena)",
  "configurations": [
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.12785832634365663,
      "energy_per_request_joules": 78.44358044476974,
      "avg_power_watts": 572.0829869523203,
      "median_itl_ms": 26.163955219089985,
      "output_throughput_tokens_per_sec": 3542.8247604968533,
      "p90_itl_ms": 29.976078681647778,
      "p95_itl_ms": 36.86737883836031,
      "p99_itl_ms": 72.38292438909403,
      "avg_batch_size": 127.71311475409836
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3982737927125526,
      "energy_per_request_joules": 247.5777242734419,
      "avg_power_watts": 465.2511720330447,
      "median_itl_ms": 13.344110921025276,
      "output_throughput_tokens_per_sec": 1146.6070113779494,
      "p90_itl_ms": 14.119432680308819,
      "p95_itl_ms": 14.563228283077477,
      "p99_itl_ms": 17.94641043990854,
      "avg_batch_size": 15.97373358348968
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11542786825169338,
      "energy_per_request_joules": 70.7114051695591,
      "avg_power_watts": 612.8136444798971,
      "median_itl_ms": 33.36937911808491,
      "output_throughput_tokens_per_sec": 4079.6801696610964,
      "p90_itl_ms": 39.20198418200016,
      "p95_itl_ms": 47.289641574025154,
      "p99_itl_ms": 90.8597562462091,
      "avg_batch_size": 191.65625
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11191693587449492,
      "energy_per_request_joules": 69.89933984987961,
      "avg_power_watts": 644.6719210104968,
      "median_itl_ms": 38.40287588536739,
      "output_throughput_tokens_per_sec": 4195.753115036918,
      "p90_itl_ms": 49.61365107446908,
      "p95_itl_ms": 67.32841385528444,
      "p99_itl_ms": 137.34881250187755,
      "avg_batch_size": 253.40963855421685
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24410035499880997,
      "energy_per_request_joules": 149.24495943199702,
      "avg_power_watts": 493.87015235470756,
      "median_itl_ms": 15.01433365046978,
      "output_throughput_tokens_per_sec": 1943.2793993506555,
      "p90_itl_ms": 17.230525985360146,
      "p95_itl_ms": 17.838258296251297,
      "p99_itl_ms": 28.449818044900816,
      "avg_batch_size": 31.923333333333332
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.16717357147713754,
      "energy_per_request_joules": 103.18576467353151,
      "avg_power_watts": 524.979298008556,
      "median_itl_ms": 18.936093896627426,
      "output_throughput_tokens_per_sec": 2781.413383437315,
      "p90_itl_ms": 21.735174953937534,
      "p95_itl_ms": 23.127018660306913,
      "p99_itl_ms": 44.97944485396147,
      "avg_batch_size": 63.844919786096256
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.706093187491587,
      "energy_per_request_joules": 437.4502427837893,
      "avg_power_watts": 443.0121237999165,
      "median_itl_ms": 12.535519897937775,
      "output_throughput_tokens_per_sec": 612.9796820380974,
      "p90_itl_ms": 13.173650950193405,
      "p95_itl_ms": 13.427985832095146,
      "p99_itl_ms": 14.364334940910336,
      "avg_batch_size": 7.986908358509567
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.14352529165485883,
      "energy_per_request_joules": 89.39130796863861,
      "avg_power_watts": 541.7770177610251,
      "median_itl_ms": 23.49620033055544,
      "output_throughput_tokens_per_sec": 3238.633318227844,
      "p90_itl_ms": 26.171179115772247,
      "p95_itl_ms": 29.94294641539451,
      "p99_itl_ms": 60.39297431707382,
      "avg_batch_size": 95.88235294117646
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 1.100828839199788,
      "energy_per_request_joules": 949.5175501898179,
      "avg_power_watts": 2526.2738006461814,
      "median_itl_ms": 53.126478000194766,
      "output_throughput_tokens_per_sec": 1861.8918685506842,
      "p90_itl_ms": 56.17911879380699,
      "p95_itl_ms": 60.4096467985073,
      "p99_itl_ms": 105.0155172747327,
      "avg_batch_size": 127.89090909090909
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 5.2530122413493086,
      "energy_per_request_joules": 4577.523088122597,
      "avg_power_watts": 2209.765938093048,
      "median_itl_ms": 37.27450594305992,
      "output_throughput_tokens_per_sec": 412.6975384545872,
      "p90_itl_ms": 37.85925358533859,
      "p95_itl_ms": 38.39360661804676,
      "p99_itl_ms": 67.92267538607122,
      "avg_batch_size": 15.981186685962374
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8402416447543337,
      "energy_per_request_joules": 725.8982138983607,
      "avg_power_watts": 2533.7933939862187,
      "median_itl_ms": 60.29347349976888,
      "output_throughput_tokens_per_sec": 2217.0700629568514,
      "p90_itl_ms": 63.27185699774418,
      "p95_itl_ms": 79.10008025646675,
      "p99_itl_ms": 119.78105250091176,
      "avg_batch_size": 191.75
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 3.009396535359466,
      "energy_per_request_joules": 2676.3674279469665,
      "avg_power_watts": 2201.57691316768,
      "median_itl_ms": 42.75384545326233,
      "output_throughput_tokens_per_sec": 691.0539567407151,
      "p90_itl_ms": 43.42821389436722,
      "p95_itl_ms": 43.75521503388882,
      "p99_itl_ms": 69.76336650550363,
      "avg_batch_size": 31.96929460580913
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 1.7413487365032319,
      "energy_per_request_joules": 1502.6156065506154,
      "avg_power_watts": 2198.09276787414,
      "median_itl_ms": 49.0025170147419,
      "output_throughput_tokens_per_sec": 1137.410549054293,
      "p90_itl_ms": 49.943381920456886,
      "p95_itl_ms": 51.18645802140236,
      "p99_itl_ms": 90.44502444565296,
      "avg_batch_size": 63.91310975609756
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 9.47137107940121,
      "energy_per_request_joules": 8100.649098460837,
      "avg_power_watts": 2120.09324571957,
      "median_itl_ms": 35.24416498839855,
      "output_throughput_tokens_per_sec": 222.6413878143073,
      "p90_itl_ms": 36.37699596583843,
      "p95_itl_ms": 36.59535786136985,
      "p99_itl_ms": 37.07177681848407,
      "avg_batch_size": 7.9914574165156615
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 1.2680547621589875,
      "energy_per_request_joules": 1094.4910049232049,
      "avg_power_watts": 2222.2427318286004,
      "median_itl_ms": 52.73650772869587,
      "output_throughput_tokens_per_sec": 1488.6583456074031,
      "p90_itl_ms": 53.88541780412197,
      "p95_itl_ms": 58.11721198260784,
      "p99_itl_ms": 100.46623401343822,
      "avg_batch_size": 95.8923076923077
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.3641468688010399,
      "energy_per_request_joules": 1198.584199997726,
      "avg_power_watts": 3874.1341684941376,
      "median_itl_ms": 42.144618928432465,
      "output_throughput_tokens_per_sec": 2346.234118747615,
      "p90_itl_ms": 44.59398053586483,
      "p95_itl_ms": 48.33376640453935,
      "p99_itl_ms": 101.21062705293299,
      "avg_batch_size": 127.82608695652173
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 6.296944834248159,
      "energy_per_request_joules": 5495.996818900514,
      "avg_power_watts": 3638.3735050517316,
      "median_itl_ms": 26.786433532834053,
      "output_throughput_tokens_per_sec": 567.3633207099339,
      "p90_itl_ms": 27.224621549248695,
      "p95_itl_ms": 27.381783351302147,
      "p99_itl_ms": 82.417909540236,
      "avg_batch_size": 15.984137475214805
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.1039671967014222,
      "energy_per_request_joules": 979.1941073359543,
      "avg_power_watts": 3984.6582773008904,
      "median_itl_ms": 49.6076624840498,
      "output_throughput_tokens_per_sec": 2732.7665930198195,
      "p90_itl_ms": 53.009020164608955,
      "p95_itl_ms": 59.90309827029705,
      "p99_itl_ms": 116.0414159297943,
      "avg_batch_size": 191.76960784313727
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.9503259044460555,
      "energy_per_request_joules": 819.2440372120919,
      "avg_power_watts": 4107.038743075696,
      "median_itl_ms": 54.93493750691414,
      "output_throughput_tokens_per_sec": 3030.4450437915193,
      "p90_itl_ms": 59.989769384264946,
      "p95_itl_ms": 67.8470803424716,
      "p99_itl_ms": 123.05417845025649,
      "avg_batch_size": 255.72972972972974
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 3.6444220874251374,
      "energy_per_request_joules": 3179.0357930716477,
      "avg_power_watts": 3705.948513878366,
      "median_itl_ms": 30.15841171145439,
      "output_throughput_tokens_per_sec": 962.5432143424094,
      "p90_itl_ms": 30.648254230618477,
      "p95_itl_ms": 30.96773363649845,
      "p99_itl_ms": 81.87093801796436,
      "avg_batch_size": 31.97048406139315
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8259377686610403,
      "energy_per_request_joules": 721.5324594315263,
      "avg_power_watts": 4148.866789614736,
      "median_itl_ms": 66.64565298706293,
      "output_throughput_tokens_per_sec": 3386.334192708989,
      "p90_itl_ms": 75.68840105086566,
      "p95_itl_ms": 103.03171053528784,
      "p99_itl_ms": 160.3875942155719,
      "avg_batch_size": 383.46
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7414699218950929,
      "energy_per_request_joules": 653.5586701886854,
      "avg_power_watts": 3960.90471917865,
      "median_itl_ms": 75.83757489919662,
      "output_throughput_tokens_per_sec": 3466.694034419854,
      "p90_itl_ms": 115.92580489814281,
      "p95_itl_ms": 130.9320306405425,
      "p99_itl_ms": 197.445574700832,
      "avg_batch_size": 511.18666666666667
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 2.1159702941061393,
      "energy_per_request_joules": 1854.4103294013923,
      "avg_power_watts": 3725.2104772419757,
      "median_itl_ms": 34.669145941734314,
      "output_throughput_tokens_per_sec": 1592.3839744255804,
      "p90_itl_ms": 35.32791547477245,
      "p95_itl_ms": 36.43390350043774,
      "p99_itl_ms": 83.94805938005449,
      "avg_batch_size": 63.937106918238996
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 11.389550351963965,
      "energy_per_request_joules": 9984.831726816567,
      "avg_power_watts": 3596.4456629623637,
      "median_itl_ms": 24.736017920076847,
      "output_throughput_tokens_per_sec": 313.8238698026664,
      "p90_itl_ms": 24.99899808317423,
      "p95_itl_ms": 25.11235298588872,
      "p99_itl_ms": 25.919590368866917,
      "avg_batch_size": 7.992145662263478
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.6266692596103178,
      "energy_per_request_joules": 1419.7867944188235,
      "avg_power_watts": 3817.2735790542147,
      "median_itl_ms": 38.73824793845415,
      "output_throughput_tokens_per_sec": 2003.450517998498,
      "p90_itl_ms": 39.73771445453167,
      "p95_itl_ms": 41.582258231937885,
      "p99_itl_ms": 89.86550176516175,
      "avg_batch_size": 95.9093567251462
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.4862393006169505,
      "energy_per_request_joules": 1282.582425670985,
      "avg_power_watts": 3903.4543908845462,
      "median_itl_ms": 46.639504998893244,
      "output_throughput_tokens_per_sec": 2198.012269028752,
      "p90_itl_ms": 48.37928880042455,
      "p95_itl_ms": 53.2070759001726,
      "p99_itl_ms": 89.28590384100973,
      "avg_batch_size": 127.84406779661018
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 5.17830831400822,
      "energy_per_request_joules": 4480.900425440654,
      "avg_power_watts": 3188.597383478894,
      "median_itl_ms": 25.347841999973753,
      "output_throughput_tokens_per_sec": 607.1672229769315,
      "p90_itl_ms": 26.363165998918703,
      "p95_itl_ms": 26.64854619943071,
      "p99_itl_ms": 55.88809064021912,
      "avg_batch_size": 15.974395448079658
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.148532751490339,
      "energy_per_request_joules": 1011.1754127417912,
      "avg_power_watts": 3987.424328613464,
      "median_itl_ms": 52.36333249922609,
      "output_throughput_tokens_per_sec": 2635.308451180817,
      "p90_itl_ms": 54.93876010059467,
      "p95_itl_ms": 67.49959940143513,
      "p99_itl_ms": 101.43425735997883,
      "avg_batch_size": 191.8106796116505
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.0927101193079563,
      "energy_per_request_joules": 955.2463326192346,
      "avg_power_watts": 4038.402679101194,
      "median_itl_ms": 55.47962600030587,
      "output_throughput_tokens_per_sec": 2734.117768429016,
      "p90_itl_ms": 61.82613250075519,
      "p95_itl_ms": 88.42033074961364,
      "p99_itl_ms": 184.1327575995819,
      "avg_batch_size": 228.4659090909091
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 3.825479811589516,
      "energy_per_request_joules": 3308.61788935041,
      "avg_power_watts": 3472.184599429809,
      "median_itl_ms": 34.71215199897415,
      "output_throughput_tokens_per_sec": 883.8326740291839,
      "p90_itl_ms": 35.663523800394614,
      "p95_itl_ms": 35.957775101269355,
      "p99_itl_ms": 52.50825485960378,
      "avg_batch_size": 31.966101694915253
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 2.3939569715302804,
      "energy_per_request_joules": 2104.846923791714,
      "avg_power_watts": 3704.701103562126,
      "median_itl_ms": 40.34211900034279,
      "output_throughput_tokens_per_sec": 1401.26806411588,
      "p90_itl_ms": 40.97743200145487,
      "p95_itl_ms": 41.59834450001654,
      "p99_itl_ms": 72.15075349886321,
      "avg_batch_size": 63.93071161048689
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 7.292589116187597,
      "energy_per_request_joules": 6303.880679088534,
      "avg_power_watts": 2828.5444663296767,
      "median_itl_ms": 20.238544999301666,
      "output_throughput_tokens_per_sec": 385.6961982276843,
      "p90_itl_ms": 20.947102600439393,
      "p95_itl_ms": 21.136431999184424,
      "p99_itl_ms": 21.77302635951491,
      "avg_batch_size": 7.990679094540613
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.819119929778148,
      "energy_per_request_joules": 1586.01676502642,
      "avg_power_watts": 3845.520596375327,
      "median_itl_ms": 43.67961599928094,
      "output_throughput_tokens_per_sec": 1835.8526615831263,
      "p90_itl_ms": 44.70363039945369,
      "p95_itl_ms": 46.96414245099729,
      "p99_itl_ms": 84.55999325944505,
      "avg_batch_size": 95.9023746701847
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4867984033224654,
      "energy_per_request_joules": 450.1035967267058,
      "avg_power_watts": 439.1560224761966,
      "median_itl_ms": 17.55353808403015,
      "output_throughput_tokens_per_sec": 892.4694175601203,
      "p90_itl_ms": 18.70672106742859,
      "p95_itl_ms": 19.133332185447216,
      "p99_itl_ms": 34.12651613354683,
      "avg_batch_size": 15.9658203125
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.33568588942930727,
      "energy_per_request_joules": 309.39814384987744,
      "avg_power_watts": 467.8673544859396,
      "median_itl_ms": 22.570966742932796,
      "output_throughput_tokens_per_sec": 1358.1222921720891,
      "p90_itl_ms": 24.07204359769821,
      "p95_itl_ms": 25.483781471848488,
      "p99_itl_ms": 36.4373036660254,
      "avg_batch_size": 31.92604006163328
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.22180751505555713,
      "energy_per_request_joules": 203.82810980197172,
      "avg_power_watts": 479.9613345455722,
      "median_itl_ms": 28.9388382807374,
      "output_throughput_tokens_per_sec": 2034.3412050841375,
      "p90_itl_ms": 30.66201340407133,
      "p95_itl_ms": 34.05419941991567,
      "p99_itl_ms": 44.07660672441129,
      "avg_batch_size": 63.916256157635466
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6531340305747603,
      "energy_per_request_joules": 605.7397168287757,
      "avg_power_watts": 399.25222684608104,
      "median_itl_ms": 12.851867824792862,
      "output_throughput_tokens_per_sec": 607.6866062639967,
      "p90_itl_ms": 13.437983579933643,
      "p95_itl_ms": 13.635628949850798,
      "p99_itl_ms": 14.225561413913951,
      "avg_batch_size": 7.970568999345978
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1858720223686476,
      "energy_per_request_joules": 173.0671825776575,
      "avg_power_watts": 494.18756722559067,
      "median_itl_ms": 32.06684719771147,
      "output_throughput_tokens_per_sec": 2420.7344007103875,
      "p90_itl_ms": 35.17773486673832,
      "p95_itl_ms": 39.93274671956897,
      "p99_itl_ms": 64.75569777190682,
      "avg_batch_size": 88.50769230769231
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1978992084187064,
      "energy_per_request_joules": 181.7891692443168,
      "avg_power_watts": 899.6847345336954,
      "median_itl_ms": 27.418648824095726,
      "output_throughput_tokens_per_sec": 3979.5651553806056,
      "p90_itl_ms": 28.79050448536873,
      "p95_itl_ms": 29.795746505260464,
      "p99_itl_ms": 46.54600627720355,
      "avg_batch_size": 127.86338797814207
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6060882087093973,
      "energy_per_request_joules": 561.3317906644965,
      "avg_power_watts": 759.4100917703079,
      "median_itl_ms": 12.550568208098412,
      "output_throughput_tokens_per_sec": 1239.9331668567836,
      "p90_itl_ms": 12.935153394937517,
      "p95_itl_ms": 13.052436150610447,
      "p99_itl_ms": 29.591265879571473,
      "avg_batch_size": 15.983827493261456
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.15568999487804014,
      "energy_per_request_joules": 142.40252279564615,
      "avg_power_watts": 930.269055905984,
      "median_itl_ms": 31.257938593626022,
      "output_throughput_tokens_per_sec": 4895.015875252246,
      "p90_itl_ms": 33.031379617750645,
      "p95_itl_ms": 34.63115952908993,
      "p99_itl_ms": 52.51390812918544,
      "avg_batch_size": 191.7795275590551
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.13347257800378423,
      "energy_per_request_joules": 122.8502984414401,
      "avg_power_watts": 954.8779613627548,
      "median_itl_ms": 34.58299767225981,
      "output_throughput_tokens_per_sec": 5389.039836068443,
      "p90_itl_ms": 37.12718449532986,
      "p95_itl_ms": 39.88573867827654,
      "p99_itl_ms": 56.68182469904422,
      "avg_batch_size": 255.80208333333334
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4112150550798349,
      "energy_per_request_joules": 381.0216699760385,
      "avg_power_watts": 833.105057733547,
      "median_itl_ms": 15.388114377856255,
      "output_throughput_tokens_per_sec": 1971.9152003569814,
      "p90_itl_ms": 16.06137752532959,
      "p95_itl_ms": 16.301700845360756,
      "p99_itl_ms": 30.816579908132553,
      "avg_batch_size": 31.969026548672566
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11199579160791863,
      "energy_per_request_joules": 105.32033932199157,
      "avg_power_watts": 939.3746176972072,
      "median_itl_ms": 42.92529448866844,
      "output_throughput_tokens_per_sec": 5800.515441654721,
      "p90_itl_ms": 48.14500920474529,
      "p95_itl_ms": 53.5843838006258,
      "p99_itl_ms": 69.31480057537554,
      "avg_batch_size": 383.530303030303
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.09877369834406177,
      "energy_per_request_joules": 91.56399003446357,
      "avg_power_watts": 953.1709777253628,
      "median_itl_ms": 47.386035323143005,
      "output_throughput_tokens_per_sec": 6125.001061594299,
      "p90_itl_ms": 55.81157021224499,
      "p95_itl_ms": 61.83922197669744,
      "p99_itl_ms": 82.14658012613653,
      "avg_batch_size": 511.0681818181818
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.27189034201277923,
      "energy_per_request_joules": 249.67658244884063,
      "avg_power_watts": 894.57664740362,
      "median_itl_ms": 18.69724877178669,
      "output_throughput_tokens_per_sec": 3087.7316387117944,
      "p90_itl_ms": 19.593029096722603,
      "p95_itl_ms": 22.987046465277672,
      "p99_itl_ms": 34.24973435699939,
      "avg_batch_size": 63.92537313432836
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8229520964617945,
      "energy_per_request_joules": 741.4139384512273,
      "avg_power_watts": 683.7088844029176,
      "median_itl_ms": 9.360754862427711,
      "output_throughput_tokens_per_sec": 825.9180767489507,
      "p90_itl_ms": 9.758817590773106,
      "p95_itl_ms": 9.877575561404228,
      "p99_itl_ms": 10.439677517861114,
      "avg_batch_size": 7.991780821917808
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.23391726835674045,
      "energy_per_request_joules": 215.347572397768,
      "avg_power_watts": 892.1903220809265,
      "median_itl_ms": 24.592196568846703,
      "output_throughput_tokens_per_sec": 3431.0279833711206,
      "p90_itl_ms": 25.715524330735207,
      "p95_itl_ms": 26.3423640280962,
      "p99_itl_ms": 42.27248825132847,
      "avg_batch_size": 95.89545454545454
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.08887730673438812,
      "energy_per_request_joules": 81.80765510798567,
      "avg_power_watts": 1123.3771247831066,
      "median_itl_ms": 74.8217350046616,
      "output_throughput_tokens_per_sec": 7816.21901554823,
      "p90_itl_ms": 94.91471797809936,
      "p95_itl_ms": 98.34421574487351,
      "p99_itl_ms": 134.33715586143083,
      "avg_batch_size": 1018.84375
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.14702179429298418,
      "energy_per_request_joules": 134.90642313299892,
      "avg_power_watts": 1093.4015243177876,
      "median_itl_ms": 33.661473979009315,
      "output_throughput_tokens_per_sec": 6424.329763576543,
      "p90_itl_ms": 35.56408200529404,
      "p95_itl_ms": 37.31281879299786,
      "p99_itl_ms": 54.12989009055295,
      "avg_batch_size": 255.7037037037037
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11750807799201222,
      "energy_per_request_joules": 108.86985721181036,
      "avg_power_watts": 1100.593056693011,
      "median_itl_ms": 50.20220347796567,
      "output_throughput_tokens_per_sec": 7530.330115482443,
      "p90_itl_ms": 69.28075756295587,
      "p95_itl_ms": 75.94001314428169,
      "p99_itl_ms": 83.91718219208998,
      "avg_batch_size": 511.33561643835617
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.10139157447618395,
      "energy_per_request_joules": 93.71700460697053,
      "avg_power_watts": 1081.8927539729257,
      "median_itl_ms": 64.9999399902299,
      "output_throughput_tokens_per_sec": 7803.684945997708,
      "p90_itl_ms": 87.23299278644845,
      "p95_itl_ms": 89.56072178843897,
      "p99_itl_ms": 112.6711294124834,
      "avg_batch_size": 767.1616161616162
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.9613599478219963,
      "energy_per_request_joules": 601.3437909556953,
      "avg_power_watts": 566.219327648272,
      "median_itl_ms": 26.353154331445694,
      "output_throughput_tokens_per_sec": 581.6949776922954,
      "p90_itl_ms": 27.748262882232666,
      "p95_itl_ms": 28.254767972975966,
      "p99_itl_ms": 33.39976480230688,
      "avg_batch_size": 15.969953051643193
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6239901651860145,
      "energy_per_request_joules": 392.6896857517892,
      "avg_power_watts": 599.3695473965292,
      "median_itl_ms": 28.807315975427628,
      "output_throughput_tokens_per_sec": 930.0413020110318,
      "p90_itl_ms": 29.899904504418373,
      "p95_itl_ms": 30.685177911072966,
      "p99_itl_ms": 67.19147257506849,
      "avg_batch_size": 29.26
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.7256601588401939,
      "energy_per_request_joules": 1100.4790985603745,
      "avg_power_watts": 538.4142363571873,
      "median_itl_ms": 25.205765850842,
      "output_throughput_tokens_per_sec": 309.84312360008494,
      "p90_itl_ms": 26.041114702820778,
      "p95_itl_ms": 26.380172930657864,
      "p99_itl_ms": 27.392359357327226,
      "avg_batch_size": 7.9854651162790695
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.27493467660499615,
      "energy_per_request_joules": 171.5957529632542,
      "avg_power_watts": 1073.7054290819397,
      "median_itl_ms": 29.656008817255497,
      "output_throughput_tokens_per_sec": 3372.457348426032,
      "p90_itl_ms": 33.37810207158327,
      "p95_itl_ms": 42.72646140307189,
      "p99_itl_ms": 97.02063553035259,
      "avg_batch_size": 127.84027777777777
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.9099358744238063,
      "energy_per_request_joules": 569.230646536766,
      "avg_power_watts": 882.7766718244878,
      "median_itl_ms": 16.036865301430225,
      "output_throughput_tokens_per_sec": 948.7007765865945,
      "p90_itl_ms": 16.648652032017708,
      "p95_itl_ms": 16.839390527457,
      "p99_itl_ms": 21.17397813126445,
      "avg_batch_size": 15.970496894409937
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24843677733933386,
      "energy_per_request_joules": 157.02174784007383,
      "avg_power_watts": 1143.1306846891766,
      "median_itl_ms": 37.01616916805506,
      "output_throughput_tokens_per_sec": 3777.197938187244,
      "p90_itl_ms": 43.76935381442312,
      "p95_itl_ms": 61.56245293095707,
      "p99_itl_ms": 128.9956690557327,
      "avg_batch_size": 191.74358974358975
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.22848064345644722,
      "energy_per_request_joules": 144.96092761983886,
      "avg_power_watts": 1177.9230310696903,
      "median_itl_ms": 44.45189796388149,
      "output_throughput_tokens_per_sec": 3733.522067028902,
      "p90_itl_ms": 55.59205114841466,
      "p95_itl_ms": 74.43105783313511,
      "p99_itl_ms": 148.15355882048607,
      "avg_batch_size": 255.58762886597938
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5535647504164556,
      "energy_per_request_joules": 355.2177431451657,
      "avg_power_watts": 944.462703925736,
      "median_itl_ms": 17.91422814130783,
      "output_throughput_tokens_per_sec": 1528.4446462979884,
      "p90_itl_ms": 18.73834375292063,
      "p95_itl_ms": 19.087451603263617,
      "p99_itl_ms": 33.89401728287314,
      "avg_batch_size": 31.935656836461128
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.23269302379414677,
      "energy_per_request_joules": 146.0310064197816,
      "avg_power_watts": 1179.9335260193766,
      "median_itl_ms": 54.89538051187992,
      "output_throughput_tokens_per_sec": 3829.9413180172537,
      "p90_itl_ms": 82.19895176589489,
      "p95_itl_ms": 111.24950386583802,
      "p99_itl_ms": 240.1536944136023,
      "avg_batch_size": 340.18518518518516
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3670707459382538,
      "energy_per_request_joules": 233.11824260529224,
      "avg_power_watts": 974.1410465427495,
      "median_itl_ms": 22.44568057358265,
      "output_throughput_tokens_per_sec": 2313.0304866033935,
      "p90_itl_ms": 23.600613698363304,
      "p95_itl_ms": 25.688573531806398,
      "p99_itl_ms": 64.99680075794453,
      "avg_batch_size": 63.8646288209607
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.6271197003089002,
      "energy_per_request_joules": 1026.7776792422917,
      "avg_power_watts": 850.1373193376241,
      "median_itl_ms": 15.06047509610653,
      "output_throughput_tokens_per_sec": 517.2816099750263,
      "p90_itl_ms": 15.467118471860886,
      "p95_itl_ms": 15.633875504136086,
      "p99_itl_ms": 17.32978187501431,
      "avg_batch_size": 7.990155865463494
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.30455435553491284,
      "energy_per_request_joules": 193.37327853381154,
      "avg_power_watts": 1021.968645687438,
      "median_itl_ms": 26.096563786268234,
      "output_throughput_tokens_per_sec": 2647.271172617246,
      "p90_itl_ms": 28.729891031980515,
      "p95_itl_ms": 32.105561345815666,
      "p99_itl_ms": 78.12223881483078,
      "avg_batch_size": 95.8135593220339
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.09662345454777717,
      "energy_per_request_joules": 61.97866199722847,
      "avg_power_watts": 573.0065316962111,
      "median_itl_ms": 20.701183937489986,
      "output_throughput_tokens_per_sec": 4739.167201839647,
      "p90_itl_ms": 23.542076349258423,
      "p95_itl_ms": 26.694484520703554,
      "p99_itl_ms": 40.73789641261099,
      "avg_batch_size": 127.80412371134021
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.25866195694907834,
      "energy_per_request_joules": 170.74922433101034,
      "avg_power_watts": 451.34471023541903,
      "median_itl_ms": 8.904065936803818,
      "output_throughput_tokens_per_sec": 1705.6020274589894,
      "p90_itl_ms": 9.840286523103716,
      "p95_itl_ms": 10.73058359324932,
      "p99_itl_ms": 15.232820529490677,
      "avg_batch_size": 15.955263157894738
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.08657588793746566,
      "energy_per_request_joules": 57.014618638630466,
      "avg_power_watts": 600.1541052930601,
      "median_itl_ms": 26.345420628786087,
      "output_throughput_tokens_per_sec": 5387.997697294117,
      "p90_itl_ms": 30.825260654091835,
      "p95_itl_ms": 35.26492286473511,
      "p99_itl_ms": 56.26332165673371,
      "avg_batch_size": 191.6875
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.08198224344576271,
      "energy_per_request_joules": 53.61870897628265,
      "avg_power_watts": 632.8068089048945,
      "median_itl_ms": 31.35814145207405,
      "output_throughput_tokens_per_sec": 5471.992994178976,
      "p90_itl_ms": 36.36135905981064,
      "p95_itl_ms": 42.25611686706543,
      "p99_itl_ms": 72.22084887325764,
      "avg_batch_size": 255.4923076923077
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.16328224689804693,
      "energy_per_request_joules": 105.61778198132008,
      "avg_power_watts": 478.0785440142732,
      "median_itl_ms": 10.569130070507526,
      "output_throughput_tokens_per_sec": 2815.7103116289,
      "p90_itl_ms": 11.781345307826996,
      "p95_itl_ms": 12.624603137373905,
      "p99_itl_ms": 17.41659682244062,
      "avg_batch_size": 31.940366972477065
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07528378160574141,
      "energy_per_request_joules": 48.80366717705554,
      "avg_power_watts": 621.6589983960096,
      "median_itl_ms": 42.677098885178566,
      "output_throughput_tokens_per_sec": 5878.8911252447015,
      "p90_itl_ms": 50.742095708847046,
      "p95_itl_ms": 59.25782434642315,
      "p99_itl_ms": 89.2347013950348,
      "avg_batch_size": 382.98039215686276
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07212917800029628,
      "energy_per_request_joules": 46.529870604677456,
      "avg_power_watts": 615.5932690290543,
      "median_itl_ms": 47.158295288681984,
      "output_throughput_tokens_per_sec": 5837.7842631531585,
      "p90_itl_ms": 63.71635422110558,
      "p95_itl_ms": 71.94560617208478,
      "p99_itl_ms": 141.98259882628923,
      "avg_batch_size": 474.4
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11921930959677225,
      "energy_per_request_joules": 76.84254986536409,
      "avg_power_watts": 514.3934412982122,
      "median_itl_ms": 13.950487598776817,
      "output_throughput_tokens_per_sec": 3728.8727071582844,
      "p90_itl_ms": 16.530530527234077,
      "p95_itl_ms": 17.652933299541473,
      "p99_itl_ms": 26.652423888444886,
      "avg_batch_size": 63.88194444444444
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.44401796141674094,
      "energy_per_request_joules": 287.08839845754466,
      "avg_power_watts": 427.0172598265621,
      "median_itl_ms": 8.203724399209023,
      "output_throughput_tokens_per_sec": 952.1376479625707,
      "p90_itl_ms": 8.684439584612846,
      "p95_itl_ms": 8.83135162293911,
      "p99_itl_ms": 13.145123086869724,
      "avg_batch_size": 7.971976401179941
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.10349555364751747,
      "energy_per_request_joules": 66.44737967775771,
      "avg_power_watts": 543.8369227988641,
      "median_itl_ms": 17.802705988287926,
      "output_throughput_tokens_per_sec": 4333.719051050695,
      "p90_itl_ms": 20.21986525505781,
      "p95_itl_ms": 21.761623676866293,
      "p99_itl_ms": 32.362725958228104,
      "avg_batch_size": 95.82142857142857
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.16611328329721825,
      "energy_per_request_joules": 120.10687928402726,
      "avg_power_watts": 588.9711776970237,
      "median_itl_ms": 34.7265861928463,
      "output_throughput_tokens_per_sec": 3188.9868644916364,
      "p90_itl_ms": 37.31006197631359,
      "p95_itl_ms": 41.08920879662037,
      "p99_itl_ms": 66.15548413246871,
      "avg_batch_size": 127.78142076502732
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.41790580776759967,
      "energy_per_request_joules": 302.39851981188093,
      "avg_power_watts": 452.29953029252124,
      "median_itl_ms": 14.531975612044334,
      "output_throughput_tokens_per_sec": 1045.7289546511317,
      "p90_itl_ms": 15.338726341724396,
      "p95_itl_ms": 15.611305460333824,
      "p99_itl_ms": 20.028106123209007,
      "avg_batch_size": 15.970238095238095
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.27080274077375716,
      "energy_per_request_joules": 196.38382039807516,
      "avg_power_watts": 483.82148451154814,
      "median_itl_ms": 17.485393211245537,
      "output_throughput_tokens_per_sec": 1717.2276794047439,
      "p90_itl_ms": 18.48367191851139,
      "p95_itl_ms": 19.314130954444405,
      "p99_itl_ms": 26.807269845158196,
      "avg_batch_size": 31.940298507462686
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.20083712480816784,
      "energy_per_request_joules": 144.13966692079484,
      "avg_power_watts": 540.5247225006851,
      "median_itl_ms": 22.891703993082047,
      "output_throughput_tokens_per_sec": 2468.6087601385407,
      "p90_itl_ms": 24.700338020920753,
      "p95_itl_ms": 26.22461207211016,
      "p99_itl_ms": 42.21526157110929,
      "avg_batch_size": 63.890625
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7020810160255394,
      "energy_per_request_joules": 511.1280065604447,
      "avg_power_watts": 424.23657242266853,
      "median_itl_ms": 13.095855712890625,
      "output_throughput_tokens_per_sec": 599.4838735152639,
      "p90_itl_ms": 13.650080561637878,
      "p95_itl_ms": 13.927154429256914,
      "p99_itl_ms": 17.139788120985024,
      "avg_batch_size": 7.982716049382716
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.17848004127618733,
      "energy_per_request_joules": 130.1285082972949,
      "avg_power_watts": 575.4938655265942,
      "median_itl_ms": 28.476839885115623,
      "output_throughput_tokens_per_sec": 2782.3425208152844,
      "p90_itl_ms": 30.828069895505905,
      "p95_itl_ms": 34.062905050814145,
      "p99_itl_ms": 55.01849431544541,
      "avg_batch_size": 95.83809523809524
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8633876449488428,
      "energy_per_request_joules": 626.4096583623079,
      "avg_power_watts": 539.235305519997,
      "median_itl_ms": 25.104925502091646,
      "output_throughput_tokens_per_sec": 605.6304900115186,
      "p90_itl_ms": 25.871247697796207,
      "p95_itl_ms": 26.233697752468288,
      "p99_itl_ms": 29.62442388670752,
      "avg_batch_size": 15.966552315608919
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5251489012827982,
      "energy_per_request_joules": 375.1188860253971,
      "avg_power_watts": 571.4471831334777,
      "median_itl_ms": 28.28457900614012,
      "output_throughput_tokens_per_sec": 1052.1862141792835,
      "p90_itl_ms": 29.135124199092388,
      "p95_itl_ms": 29.889975202968344,
      "p99_itl_ms": 47.08953475928857,
      "avg_batch_size": 31.734567901234566
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.5108347604441896,
      "energy_per_request_joules": 1086.455440311296,
      "avg_power_watts": 510.4211657968816,
      "median_itl_ms": 23.425721999956295,
      "output_throughput_tokens_per_sec": 332.6205512418793,
      "p90_itl_ms": 23.847885405120905,
      "p95_itl_ms": 24.02262069954304,
      "p99_itl_ms": 24.892170185485135,
      "avg_batch_size": 7.988339552238806
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3061551500968861,
      "energy_per_request_joules": 215.93595124162627,
      "avg_power_watts": 1137.067654131935,
      "median_itl_ms": 31.995583325624466,
      "output_throughput_tokens_per_sec": 3108.4218463947554,
      "p90_itl_ms": 34.478471428155906,
      "p95_itl_ms": 40.37652723491191,
      "p99_itl_ms": 90.45042231678961,
      "avg_batch_size": 127.80357142857143
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.89120135421836,
      "energy_per_request_joules": 629.7643038286432,
      "avg_power_watts": 871.8307328742193,
      "median_itl_ms": 16.05406031012535,
      "output_throughput_tokens_per_sec": 957.4647155060467,
      "p90_itl_ms": 16.38836171478033,
      "p95_itl_ms": 16.533141303807497,
      "p99_itl_ms": 19.79724021628478,
      "avg_batch_size": 15.979310344827587
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2895194806492324,
      "energy_per_request_joules": 206.79777106974888,
      "avg_power_watts": 1210.4252130316443,
      "median_itl_ms": 39.78635370731354,
      "output_throughput_tokens_per_sec": 3389.7690283137836,
      "p90_itl_ms": 45.55294439196587,
      "p95_itl_ms": 62.64864569529892,
      "p99_itl_ms": 141.18140656501055,
      "avg_batch_size": 186.993006993007
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5544002112850572,
      "energy_per_request_joules": 393.541856231028,
      "avg_power_watts": 935.1903041557412,
      "median_itl_ms": 18.39852798730135,
      "output_throughput_tokens_per_sec": 1592.540324022475,
      "p90_itl_ms": 18.943024426698685,
      "p95_itl_ms": 19.220177456736565,
      "p99_itl_ms": 28.431920204311563,
      "avg_batch_size": 31.96135265700483
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3880231496212807,
      "energy_per_request_joules": 275.8018528898932,
      "avg_power_watts": 1029.7000798888814,
      "median_itl_ms": 22.762875072658062,
      "output_throughput_tokens_per_sec": 2470.0732826959825,
      "p90_itl_ms": 23.736554197967052,
      "p95_itl_ms": 25.15928894281387,
      "p99_itl_ms": 51.5003892965615,
      "avg_batch_size": 63.91119691119691
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.5486857000794645,
      "energy_per_request_joules": 1101.4679192488024,
      "avg_power_watts": 812.9914005533786,
      "median_itl_ms": 15.06505161523819,
      "output_throughput_tokens_per_sec": 519.7547636686174,
      "p90_itl_ms": 15.434471890330315,
      "p95_itl_ms": 15.643206611275673,
      "p99_itl_ms": 16.760235279798508,
      "avg_batch_size": 7.9897810218978105
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.32930270385028265,
      "energy_per_request_joules": 233.97439485570175,
      "avg_power_watts": 1101.2112240966244,
      "median_itl_ms": 27.00553648173809,
      "output_throughput_tokens_per_sec": 2994.1903342141627,
      "p90_itl_ms": 28.48411053419113,
      "p95_itl_ms": 32.965153269469745,
      "p99_itl_ms": 63.57433378696441,
      "avg_batch_size": 95.84924623115577
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.4295126027519807,
      "energy_per_request_joules": 876.7384976636154,
      "avg_power_watts": 4606.148580022177,
      "median_itl_ms": 48.04321005940437,
      "output_throughput_tokens_per_sec": 1301.6210649006268,
      "p90_itl_ms": 99.37790222465993,
      "p95_itl_ms": 142.75479894131425,
      "p99_itl_ms": 353.72009355574846,
      "avg_batch_size": 127.65868263473054
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 7.589230370057344,
      "energy_per_request_joules": 2885.4491030407085,
      "avg_power_watts": 3384.257712479697,
      "median_itl_ms": 34.0373395010829,
      "output_throughput_tokens_per_sec": 436.4056179080141,
      "p90_itl_ms": 34.33295153081417,
      "p95_itl_ms": 34.65995714068413,
      "p99_itl_ms": 85.39401005953532,
      "avg_batch_size": 15.94773519163763
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.2338904686883065,
      "energy_per_request_joules": 802.2131915627757,
      "avg_power_watts": 4812.870137887257,
      "median_itl_ms": 62.19174154102802,
      "output_throughput_tokens_per_sec": 1391.8375703302718,
      "p90_itl_ms": 113.54916319251075,
      "p95_itl_ms": 182.43902027606964,
      "p99_itl_ms": 424.72660258412367,
      "avg_batch_size": 191.45323741007195
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.0625855382715845,
      "energy_per_request_joules": 757.2790860738882,
      "avg_power_watts": 4874.811811328656,
      "median_itl_ms": 66.90175086259842,
      "output_throughput_tokens_per_sec": 1554.293282062273,
      "p90_itl_ms": 148.1746520847082,
      "p95_itl_ms": 194.30709956213832,
      "p99_itl_ms": 569.3191265128553,
      "avg_batch_size": 255.20833333333334
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 4.76528479532573,
      "energy_per_request_joules": 1773.1699180981968,
      "avg_power_watts": 3744.284581648396,
      "median_itl_ms": 36.33137606084347,
      "output_throughput_tokens_per_sec": 756.3686860975474,
      "p90_itl_ms": 36.93876639008522,
      "p95_itl_ms": 43.746870290488005,
      "p99_itl_ms": 136.96959275752303,
      "avg_batch_size": 31.914893617021278
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 3.082473971825438,
      "energy_per_request_joules": 1108.7333771979386,
      "avg_power_watts": 4162.080045275077,
      "median_itl_ms": 39.31737877428532,
      "output_throughput_tokens_per_sec": 1231.8653140600836,
      "p90_itl_ms": 43.910397589206696,
      "p95_itl_ms": 92.15272851288307,
      "p99_itl_ms": 190.17528364434835,
      "avg_batch_size": 63.86381322957198
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 13.97486873804664,
      "energy_per_request_joules": 5110.052686327374,
      "avg_power_watts": 3260.4333583354814,
      "median_itl_ms": 33.19642134010792,
      "output_throughput_tokens_per_sec": 231.779012555466,
      "p90_itl_ms": 33.49717278033495,
      "p95_itl_ms": 33.59378566965461,
      "p99_itl_ms": 42.53464464098218,
      "avg_batch_size": 7.981012658227848
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.660912185001098,
      "energy_per_request_joules": 979.5898748564199,
      "avg_power_watts": 4474.554460755058,
      "median_itl_ms": 44.08974479883909,
      "output_throughput_tokens_per_sec": 1199.7722997161022,
      "p90_itl_ms": 57.852825708687305,
      "p95_itl_ms": 104.21531414613128,
      "p99_itl_ms": 280.5608754046261,
      "avg_batch_size": 95.71
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3731420112064737,
      "energy_per_request_joules": 130.89176771326385,
      "avg_power_watts": 2547.51808188361,
      "median_itl_ms": 105.61014339327812,
      "output_throughput_tokens_per_sec": 3895.9940367149866,
      "p90_itl_ms": 151.6728650778532,
      "p95_itl_ms": 219.92053147405286,
      "p99_itl_ms": 592.8732616081833,
      "avg_batch_size": 898.4528301886793
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5633656270485234,
      "energy_per_request_joules": 202.20864846476806,
      "avg_power_watts": 2183.755339171335,
      "median_itl_ms": 27.867806144058704,
      "output_throughput_tokens_per_sec": 2651.9515916662003,
      "p90_itl_ms": 34.00429822504521,
      "p95_itl_ms": 54.682417679578066,
      "p99_itl_ms": 121.33453141897917,
      "avg_batch_size": 127.60975609756098
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.0910101791292157,
      "energy_per_request_joules": 741.1058743374467,
      "avg_power_watts": 1803.80598644041,
      "median_itl_ms": 17.69743673503399,
      "output_throughput_tokens_per_sec": 843.7492169711852,
      "p90_itl_ms": 18.106621503829956,
      "p95_itl_ms": 18.409153632819653,
      "p99_itl_ms": 32.13571004569532,
      "avg_batch_size": 15.953771289537713
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5140014460496121,
      "energy_per_request_joules": 183.60242082890318,
      "avg_power_watts": 2293.0811079459736,
      "median_itl_ms": 33.70159678161144,
      "output_throughput_tokens_per_sec": 2655.0519119521523,
      "p90_itl_ms": 56.644922122359276,
      "p95_itl_ms": 77.61731185019016,
      "p99_itl_ms": 161.5235060453415,
      "avg_batch_size": 191.62121212121212
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.47899262868266945,
      "energy_per_request_joules": 167.19181572219904,
      "avg_power_watts": 2354.298369521534,
      "median_itl_ms": 39.83728773891926,
      "output_throughput_tokens_per_sec": 3446.233068899271,
      "p90_itl_ms": 68.45140736550097,
      "p95_itl_ms": 92.88467960432172,
      "p99_itl_ms": 240.35985104739666,
      "avg_batch_size": 255.3148148148148
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.206875200257968,
      "energy_per_request_joules": 423.09579469199866,
      "avg_power_watts": 1794.2248144020984,
      "median_itl_ms": 20.04694938659668,
      "output_throughput_tokens_per_sec": 1410.9324066554036,
      "p90_itl_ms": 20.663706585764885,
      "p95_itl_ms": 23.068370297551155,
      "p99_itl_ms": 56.29271231591702,
      "avg_batch_size": 31.875536480686694
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.44061498499723045,
      "energy_per_request_joules": 160.3236142090118,
      "avg_power_watts": 2343.5247258308104,
      "median_itl_ms": 55.124069564044476,
      "output_throughput_tokens_per_sec": 2916.3896039665997,
      "p90_itl_ms": 92.43539813905954,
      "p95_itl_ms": 114.86738631501794,
      "p99_itl_ms": 436.4945012889802,
      "avg_batch_size": 383.0232558139535
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4210099504617085,
      "energy_per_request_joules": 147.41104261576268,
      "avg_power_watts": 2492.926569137417,
      "median_itl_ms": 73.88564106076956,
      "output_throughput_tokens_per_sec": 3985.295397409021,
      "p90_itl_ms": 103.65471374243498,
      "p95_itl_ms": 136.37098474428058,
      "p99_itl_ms": 299.11049067973937,
      "avg_batch_size": 510.5056179775281
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.797248592193898,
      "energy_per_request_joules": 280.5980262398846,
      "avg_power_watts": 2001.5016204568867,
      "median_itl_ms": 22.432271391153336,
      "output_throughput_tokens_per_sec": 2266.2603498187095,
      "p90_itl_ms": 24.364156648516655,
      "p95_itl_ms": 31.98671154677868,
      "p99_itl_ms": 90.53552784025669,
      "avg_batch_size": 63.791044776119406
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3896030113390203,
      "energy_per_request_joules": 136.90855273166184,
      "avg_power_watts": 2535.3280376865096,
      "median_itl_ms": 103.63952443003654,
      "output_throughput_tokens_per_sec": 3925.664849779013,
      "p90_itl_ms": 135.2294901385903,
      "p95_itl_ms": 152.2790588438511,
      "p99_itl_ms": 561.7390470393002,
      "avg_batch_size": 766.3235294117648
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 3.7587138844121615,
      "energy_per_request_joules": 1315.4984708778682,
      "avg_power_watts": 1765.4278811426893,
      "median_itl_ms": 16.57271385192871,
      "output_throughput_tokens_per_sec": 463.9597671161966,
      "p90_itl_ms": 16.90893229097128,
      "p95_itl_ms": 17.02127968892455,
      "p99_itl_ms": 21.116143707185984,
      "avg_batch_size": 7.986666666666666
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6477575722089276,
      "energy_per_request_joules": 231.55182448905188,
      "avg_power_watts": 2101.546572444986,
      "median_itl_ms": 25.356492958962917,
      "output_throughput_tokens_per_sec": 2617.1079838674027,
      "p90_itl_ms": 28.38642876595259,
      "p95_itl_ms": 44.49358126148583,
      "p99_itl_ms": 114.1463346965611,
      "avg_batch_size": 95.72549019607843
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.09510991243206074,
      "energy_per_request_joules": 38.48050460996364,
      "avg_power_watts": 669.2439022030471,
      "median_itl_ms": 16.482017002999783,
      "output_throughput_tokens_per_sec": 4953.542215252226,
      "p90_itl_ms": 20.042716525495052,
      "p95_itl_ms": 24.74002493545413,
      "p99_itl_ms": 46.433303505182266,
      "avg_batch_size": 127.62
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.26273977845850766,
      "energy_per_request_joules": 106.2076803873686,
      "avg_power_watts": 513.280830756726,
      "median_itl_ms": 7.912369444966316,
      "output_throughput_tokens_per_sec": 1870.8595161409369,
      "p90_itl_ms": 8.581877872347832,
      "p95_itl_ms": 9.243009611964226,
      "p99_itl_ms": 13.290748298168158,
      "avg_batch_size": 15.951690821256038
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.08369519184258484,
      "energy_per_request_joules": 33.20802896960434,
      "avg_power_watts": 688.2545655688424,
      "median_itl_ms": 20.908080972731113,
      "output_throughput_tokens_per_sec": 5846.331232091927,
      "p90_itl_ms": 26.95829514414072,
      "p95_itl_ms": 33.54309350252143,
      "p99_itl_ms": 59.01624012738466,
      "avg_batch_size": 191.65853658536585
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.0766413032348523,
      "energy_per_request_joules": 30.97711994863476,
      "avg_power_watts": 690.5083838667351,
      "median_itl_ms": 26.12623802269809,
      "output_throughput_tokens_per_sec": 7257.922997194246,
      "p90_itl_ms": 32.539849379099905,
      "p95_itl_ms": 38.75030499766581,
      "p99_itl_ms": 59.66428812243974,
      "avg_batch_size": 255.18987341772151
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.16505510741316592,
      "energy_per_request_joules": 64.425811784883,
      "avg_power_watts": 559.7134507541415,
      "median_itl_ms": 8.906599134206772,
      "output_throughput_tokens_per_sec": 3159.1163815728605,
      "p90_itl_ms": 10.384867712855337,
      "p95_itl_ms": 11.403440311551089,
      "p99_itl_ms": 18.416078612208267,
      "avg_batch_size": 31.911504424778762
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07423418180476347,
      "energy_per_request_joules": 29.27382187823128,
      "avg_power_watts": 686.5186027909551,
      "median_itl_ms": 37.70148498006165,
      "output_throughput_tokens_per_sec": 6786.917653081074,
      "p90_itl_ms": 47.82290779403411,
      "p95_itl_ms": 54.311841214075685,
      "p99_itl_ms": 96.15210728254148,
      "avg_batch_size": 383.01428571428573
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07019449941326047,
      "energy_per_request_joules": 27.844149422286517,
      "avg_power_watts": 688.2983232359837,
      "median_itl_ms": 47.40760399727151,
      "output_throughput_tokens_per_sec": 7088.49254054382,
      "p90_itl_ms": 59.06887900782748,
      "p95_itl_ms": 65.01795589574611,
      "p99_itl_ms": 106.78900223167149,
      "avg_batch_size": 510.8688524590164
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11857964835952284,
      "energy_per_request_joules": 46.90311454458103,
      "avg_power_watts": 610.3476218460647,
      "median_itl_ms": 11.500172317028046,
      "output_throughput_tokens_per_sec": 4569.838329244999,
      "p90_itl_ms": 13.176492601633074,
      "p95_itl_ms": 14.754379913210862,
      "p99_itl_ms": 25.68335087969897,
      "avg_batch_size": 63.917808219178085
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07134822942888497,
      "energy_per_request_joules": 28.35051624785673,
      "avg_power_watts": 685.140945777979,
      "median_itl_ms": 62.930971500463784,
      "output_throughput_tokens_per_sec": 7643.405768056329,
      "p90_itl_ms": 87.81373900419567,
      "p95_itl_ms": 106.97549971955596,
      "p99_itl_ms": 192.04428087599808,
      "avg_batch_size": 690.8681318681319
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4547982611462042,
      "energy_per_request_joules": 176.76995773999624,
      "avg_power_watts": 486.4380535594687,
      "median_itl_ms": 7.316111586987972,
      "output_throughput_tokens_per_sec": 1061.876199768178,
      "p90_itl_ms": 7.704039663076401,
      "p95_itl_ms": 7.996502518653869,
      "p99_itl_ms": 10.866769570857286,
      "avg_batch_size": 7.978201634877384
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.102865531346047,
      "energy_per_request_joules": 40.40897607889865,
      "avg_power_watts": 643.9532367685447,
      "median_itl_ms": 14.077862724661827,
      "output_throughput_tokens_per_sec": 4515.794240962201,
      "p90_itl_ms": 16.678499430418015,
      "p95_itl_ms": 20.120452716946595,
      "p99_itl_ms": 35.39796203374864,
      "avg_batch_size": 95.70175438596492
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6036206575024905,
      "energy_per_request_joules": 248.33036375914227,
      "avg_power_watts": 2351.335081311273,
      "median_itl_ms": 27.75922231376171,
      "output_throughput_tokens_per_sec": 2620.177775110049,
      "p90_itl_ms": 32.05261752009392,
      "p95_itl_ms": 54.11705840379,
      "p99_itl_ms": 123.06474521756172,
      "avg_batch_size": 127.7127659574468
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.1016443053811678,
      "energy_per_request_joules": 861.2021161923748,
      "avg_power_watts": 1838.807782685267,
      "median_itl_ms": 17.56241451948881,
      "output_throughput_tokens_per_sec": 858.7946424306577,
      "p90_itl_ms": 17.893794924020767,
      "p95_itl_ms": 18.158955965191126,
      "p99_itl_ms": 28.45144355669618,
      "avg_batch_size": 15.970212765957447
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5400161867812329,
      "energy_per_request_joules": 219.46648076861783,
      "avg_power_watts": 2461.337558890742,
      "median_itl_ms": 33.60642120242119,
      "output_throughput_tokens_per_sec": 2874.1057218929323,
      "p90_itl_ms": 48.582508787512985,
      "p95_itl_ms": 75.1825701445341,
      "p99_itl_ms": 171.24340519309044,
      "avg_batch_size": 191.53424657534248
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4910870247635751,
      "energy_per_request_joules": 202.9719263454225,
      "avg_power_watts": 2519.352730636792,
      "median_itl_ms": 39.05790485441685,
      "output_throughput_tokens_per_sec": 3186.3541109041967,
      "p90_itl_ms": 59.90947894752055,
      "p95_itl_ms": 85.33287849277252,
      "p99_itl_ms": 181.4057970046997,
      "avg_batch_size": 255.4516129032258
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.2490713279290644,
      "energy_per_request_joules": 515.7798529031772,
      "avg_power_watts": 1895.6477994442098,
      "median_itl_ms": 19.864235073328018,
      "output_throughput_tokens_per_sec": 1464.1930980885606,
      "p90_itl_ms": 20.36301977932453,
      "p95_itl_ms": 21.960968896746593,
      "p99_itl_ms": 51.30415171384808,
      "avg_batch_size": 31.911439114391143
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4437462324400039,
      "energy_per_request_joules": 181.17673323083628,
      "avg_power_watts": 2510.6066406517143,
      "median_itl_ms": 53.8472905755043,
      "output_throughput_tokens_per_sec": 2974.754274160048,
      "p90_itl_ms": 81.16421084851027,
      "p95_itl_ms": 104.58444682881232,
      "p99_itl_ms": 268.8867459446191,
      "avg_batch_size": 382.9166666666667
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.42511732904780986,
      "energy_per_request_joules": 175.83417338370057,
      "avg_power_watts": 2490.545119063151,
      "median_itl_ms": 73.5875191166997,
      "output_throughput_tokens_per_sec": 4155.448700329297,
      "p90_itl_ms": 104.21592239290477,
      "p95_itl_ms": 134.7207486629486,
      "p99_itl_ms": 277.25199323147484,
      "avg_batch_size": 510.8
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8223267233123469,
      "energy_per_request_joules": 336.2015351773509,
      "avg_power_watts": 2108.3171636085754,
      "median_itl_ms": 22.33504317700863,
      "output_throughput_tokens_per_sec": 2381.845484597419,
      "p90_itl_ms": 23.909232392907143,
      "p95_itl_ms": 29.054128192365162,
      "p99_itl_ms": 84.97802283614882,
      "avg_batch_size": 63.857142857142854
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.42309416473966643,
      "energy_per_request_joules": 174.91534994349365,
      "avg_power_watts": 2546.049766678004,
      "median_itl_ms": 97.54406102001667,
      "output_throughput_tokens_per_sec": 4092.437563559187,
      "p90_itl_ms": 149.4576372206211,
      "p95_itl_ms": 193.7341911718247,
      "p99_itl_ms": 570.3238400816917,
      "avg_batch_size": 724.2444444444444
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 3.8469267248117465,
      "energy_per_request_joules": 1572.7957049116321,
      "avg_power_watts": 1787.3856485130575,
      "median_itl_ms": 16.86663366854191,
      "output_throughput_tokens_per_sec": 461.7619994037026,
      "p90_itl_ms": 17.01442338526249,
      "p95_itl_ms": 17.139077931642532,
      "p99_itl_ms": 20.57395108044147,
      "avg_batch_size": 7.976430976430977
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6707632297133818,
      "energy_per_request_joules": 281.94130570658655,
      "avg_power_watts": 2223.797428056266,
      "median_itl_ms": 25.379663333296776,
      "output_throughput_tokens_per_sec": 2736.5639341977685,
      "p90_itl_ms": 27.717379480600354,
      "p95_itl_ms": 39.72181230783462,
      "p99_itl_ms": 100.1505321264267,
      "avg_batch_size": 95.86324786324786
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7573396700014222,
      "energy_per_request_joules": 307.16558047394597,
      "avg_power_watts": 3140.5181505218916,
      "median_itl_ms": 27.628473937511444,
      "output_throughput_tokens_per_sec": 2903.6996309042947,
      "p90_itl_ms": 31.287204846739783,
      "p95_itl_ms": 52.70781237632036,
      "p99_itl_ms": 59.35958638787269,
      "avg_batch_size": 127.72222222222223
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.8157942573743913,
      "energy_per_request_joules": 759.546383212392,
      "avg_power_watts": 2014.707172835016,
      "median_itl_ms": 13.283604755997658,
      "output_throughput_tokens_per_sec": 1033.3459953124407,
      "p90_itl_ms": 13.624375686049461,
      "p95_itl_ms": 13.8603825122118,
      "p99_itl_ms": 48.573178388178306,
      "avg_batch_size": 15.973474801061007
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6416026507218848,
      "energy_per_request_joules": 266.3089596057839,
      "avg_power_watts": 3343.0232559162782,
      "median_itl_ms": 33.2093695178628,
      "output_throughput_tokens_per_sec": 3170.2297876970124,
      "p90_itl_ms": 38.075342774391174,
      "p95_itl_ms": 56.61759898066521,
      "p99_itl_ms": 66.56867032870652,
      "avg_batch_size": 191.56716417910448
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5604892165392596,
      "energy_per_request_joules": 229.47161977802995,
      "avg_power_watts": 3507.338192747269,
      "median_itl_ms": 36.97950020432472,
      "output_throughput_tokens_per_sec": 3715.6150817733405,
      "p90_itl_ms": 41.91430062055588,
      "p95_itl_ms": 60.561890713870525,
      "p99_itl_ms": 83.9682464301582,
      "avg_batch_size": 255.42307692307693
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.2655324258473077,
      "energy_per_request_joules": 521.8813493378412,
      "avg_power_watts": 2284.2672979381214,
      "median_itl_ms": 16.148020513355732,
      "output_throughput_tokens_per_sec": 1596.0585142354994,
      "p90_itl_ms": 16.708863899111748,
      "p95_itl_ms": 18.226942885667086,
      "p99_itl_ms": 50.50701173022389,
      "avg_batch_size": 31.9070796460177
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.48419284725112327,
      "energy_per_request_joules": 197.33553739574418,
      "avg_power_watts": 3461.5403094992657,
      "median_itl_ms": 47.900935634970665,
      "output_throughput_tokens_per_sec": 3917.16104310296,
      "p90_itl_ms": 66.18660315871239,
      "p95_itl_ms": 69.31344084441656,
      "p99_itl_ms": 112.54705876111986,
      "avg_batch_size": 383.3170731707317
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.9439309067180714,
      "energy_per_request_joules": 383.64430886159573,
      "avg_power_watts": 2655.646101321286,
      "median_itl_ms": 20.67001536488533,
      "output_throughput_tokens_per_sec": 2233.738393559282,
      "p90_itl_ms": 22.415068745613098,
      "p95_itl_ms": 47.64300063252449,
      "p99_itl_ms": 53.07567436248064,
      "avg_batch_size": 63.86231884057971
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 2.8045326473291636,
      "energy_per_request_joules": 1162.6047671829551,
      "avg_power_watts": 1845.3941329316724,
      "median_itl_ms": 11.49036269634962,
      "output_throughput_tokens_per_sec": 624.6529904756103,
      "p90_itl_ms": 11.708237417042255,
      "p95_itl_ms": 11.806785874068735,
      "p99_itl_ms": 46.78823893889785,
      "avg_batch_size": 7.984301412872841
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8487845785790009,
      "energy_per_request_joules": 345.9427115013843,
      "avg_power_watts": 3009.7765411308883,
      "median_itl_ms": 24.52058345079422,
      "output_throughput_tokens_per_sec": 2652.0463376361567,
      "p90_itl_ms": 26.628663763403893,
      "p95_itl_ms": 50.2775227651,
      "p99_itl_ms": 56.6649042069912,
      "avg_batch_size": 95.79629629629629
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6539730056498323,
      "energy_per_request_joules": 263.38188021585,
      "avg_power_watts": 1834.7612222231176,
      "median_itl_ms": 42.131686583161354,
      "output_throughput_tokens_per_sec": 1889.8039709367267,
      "p90_itl_ms": 45.737025141716,
      "p95_itl_ms": 60.89247018098831,
      "p99_itl_ms": 94.84558720141649,
      "avg_batch_size": 127.64341085271317
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 2.673432792526821,
      "energy_per_request_joules": 1078.197533845436,
      "avg_power_watts": 1423.0150897004576,
      "median_itl_ms": 28.983852826058865,
      "output_throughput_tokens_per_sec": 514.3406683803347,
      "p90_itl_ms": 29.74723931401968,
      "p95_itl_ms": 30.112036038190126,
      "p99_itl_ms": 56.53170496225357,
      "avg_batch_size": 15.955026455026456
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5163721890334115,
      "energy_per_request_joules": 213.9707172912882,
      "avg_power_watts": 1866.6037123827937,
      "median_itl_ms": 47.56573308259249,
      "output_throughput_tokens_per_sec": 2211.8975544272307,
      "p90_itl_ms": 55.65968342125416,
      "p95_itl_ms": 72.53987705335021,
      "p99_itl_ms": 124.22373022884138,
      "avg_batch_size": 191.55789473684212
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4344742176706326,
      "energy_per_request_joules": 172.79005693462804,
      "avg_power_watts": 1879.1558955956496,
      "median_itl_ms": 52.11937241256237,
      "output_throughput_tokens_per_sec": 2649.078800043216,
      "p90_itl_ms": 69.86898817121984,
      "p95_itl_ms": 82.65670957043767,
      "p99_itl_ms": 158.14138049259782,
      "avg_batch_size": 255.31944444444446
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 1.7290924591642545,
      "energy_per_request_joules": 693.7291179986164,
      "avg_power_watts": 1606.0245726119294,
      "median_itl_ms": 32.988084480166435,
      "output_throughput_tokens_per_sec": 866.7344912902594,
      "p90_itl_ms": 33.73837023973465,
      "p95_itl_ms": 34.76462010294199,
      "p99_itl_ms": 59.271730110049006,
      "avg_batch_size": 31.915690866510538
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.35891034940282546,
      "energy_per_request_joules": 146.38039430942285,
      "avg_power_watts": 1863.0366513178105,
      "median_itl_ms": 64.68318961560726,
      "output_throughput_tokens_per_sec": 2461.2690256016185,
      "p90_itl_ms": 82.68126100301743,
      "p95_itl_ms": 97.68766351044178,
      "p99_itl_ms": 213.87550570070744,
      "avg_batch_size": 383.08
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3361982577088546,
      "energy_per_request_joules": 135.24559872171807,
      "avg_power_watts": 1881.3809101037816,
      "median_itl_ms": 69.11092065274715,
      "output_throughput_tokens_per_sec": 2445.633128045501,
      "p90_itl_ms": 99.41024724394083,
      "p95_itl_ms": 127.44442112743853,
      "p99_itl_ms": 335.4441526159644,
      "avg_batch_size": 472.8205128205128
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 1.059319458747046,
      "energy_per_request_joules": 427.7302317272289,
      "avg_power_watts": 1749.6014271210397,
      "median_itl_ms": 36.49779595434666,
      "output_throughput_tokens_per_sec": 1386.7138230796097,
      "p90_itl_ms": 37.53687329590321,
      "p95_itl_ms": 54.0454238653183,
      "p99_itl_ms": 69.62598972022533,
      "avg_batch_size": 63.86899563318777
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 3.97729296565183,
      "energy_per_request_joules": 1575.5517849207724,
      "avg_power_watts": 1280.568613682407,
      "median_itl_ms": 24.152799509465694,
      "output_throughput_tokens_per_sec": 314.7555727059792,
      "p90_itl_ms": 24.903803132474422,
      "p95_itl_ms": 25.16512768343091,
      "p99_itl_ms": 55.34326063469052,
      "avg_batch_size": 7.981466559226431
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7937582042597565,
      "energy_per_request_joules": 325.2695546028074,
      "avg_power_watts": 1819.437956710615,
      "median_itl_ms": 38.966670632362366,
      "output_throughput_tokens_per_sec": 1677.5394888662233,
      "p90_itl_ms": 41.05184823274613,
      "p95_itl_ms": 58.421021327376366,
      "p99_itl_ms": 79.91059008985758,
      "avg_batch_size": 95.74534161490683
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8078851800477325,
      "energy_per_request_joules": 320.9536894339825,
      "avg_power_watts": 2991.3189947245887,
      "median_itl_ms": 30.28608113527298,
      "output_throughput_tokens_per_sec": 2199.822167854877,
      "p90_itl_ms": 32.941509410738945,
      "p95_itl_ms": 61.36552169919013,
      "p99_itl_ms": 78.7656581774354,
      "avg_batch_size": 127.58947368421053
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 3.3310723055731115,
      "energy_per_request_joules": 1344.41622832889,
      "avg_power_watts": 2292.3401072451134,
      "median_itl_ms": 21.932996809482574,
      "output_throughput_tokens_per_sec": 656.3140958631321,
      "p90_itl_ms": 22.307416424155235,
      "p95_itl_ms": 22.554870694875717,
      "p99_itl_ms": 60.24247668683532,
      "avg_batch_size": 15.96938775510204
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6448574779690641,
      "energy_per_request_joules": 261.0016560025629,
      "avg_power_watts": 3125.0239997132066,
      "median_itl_ms": 34.25414115190506,
      "output_throughput_tokens_per_sec": 2427.6065460302875,
      "p90_itl_ms": 40.279205143451684,
      "p95_itl_ms": 65.93217179179192,
      "p99_itl_ms": 105.29956094920635,
      "avg_batch_size": 191.4927536231884
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5613564613407728,
      "energy_per_request_joules": 231.81280855027526,
      "avg_power_watts": 3197.3768254564466,
      "median_itl_ms": 37.449986673891544,
      "output_throughput_tokens_per_sec": 2916.9609732867075,
      "p90_itl_ms": 66.18961375206709,
      "p95_itl_ms": 69.67382710427046,
      "p99_itl_ms": 110.03914296627045,
      "avg_batch_size": 255.42592592592592
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 2.0590071741264033,
      "energy_per_request_joules": 842.121869722538,
      "avg_power_watts": 2559.4351312278013,
      "median_itl_ms": 23.91286753118038,
      "output_throughput_tokens_per_sec": 1130.1665863708608,
      "p90_itl_ms": 24.39761534333229,
      "p95_itl_ms": 24.990255944430828,
      "p99_itl_ms": 61.95208542048931,
      "avg_batch_size": 31.91358024691358
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4701074496383626,
      "energy_per_request_joules": 192.97864898724157,
      "avg_power_watts": 3188.6593800182022,
      "median_itl_ms": 47.76894859969616,
      "output_throughput_tokens_per_sec": 2976.025084901406,
      "p90_itl_ms": 75.32594613730907,
      "p95_itl_ms": 78.70527002960439,
      "p99_itl_ms": 182.18950707465407,
      "avg_batch_size": 383.25
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.45212164203353705,
      "energy_per_request_joules": 182.34410212744567,
      "avg_power_watts": 3098.2878789821207,
      "median_itl_ms": 55.76958321034908,
      "output_throughput_tokens_per_sec": 2912.208480777301,
      "p90_itl_ms": 81.86518400907516,
      "p95_itl_ms": 87.10338044911623,
      "p99_itl_ms": 237.28490564972162,
      "avg_batch_size": 510.90625
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.261490207447033,
      "energy_per_request_joules": 507.1400061022294,
      "avg_power_watts": 2797.4258387931445,
      "median_itl_ms": 26.28241293132305,
      "output_throughput_tokens_per_sec": 1707.6427227756715,
      "p90_itl_ms": 27.173882350325584,
      "p95_itl_ms": 57.4591439217329,
      "p99_itl_ms": 66.1684792488813,
      "avg_batch_size": 63.84393063583815
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 5.2733518993890725,
      "energy_per_request_joules": 2139.4616926262606,
      "avg_power_watts": 1999.7234778327174,
      "median_itl_ms": 20.288575440645218,
      "output_throughput_tokens_per_sec": 367.69345488032127,
      "p90_itl_ms": 20.527634024620056,
      "p95_itl_ms": 20.659492164850235,
      "p99_itl_ms": 59.29509520530702,
      "avg_batch_size": 7.989833641404806
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.9636148081503074,
      "energy_per_request_joules": 399.670534041373,
      "avg_power_watts": 2932.5972254129206,
      "median_itl_ms": 28.28422375023365,
      "output_throughput_tokens_per_sec": 2118.799765369477,
      "p90_itl_ms": 29.647081159055233,
      "p95_itl_ms": 59.40303606912494,
      "p99_itl_ms": 70.17477327957747,
      "avg_batch_size": 95.76612903225806
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.20886571099347784,
      "energy_per_request_joules": 95.98195301833874,
      "avg_power_watts": 674.5290034452222,
      "median_itl_ms": 29.165392741560936,
      "output_throughput_tokens_per_sec": 2521.0959840897285,
      "p90_itl_ms": 73.33428356796503,
      "p95_itl_ms": 77.04649427905679,
      "p99_itl_ms": 174.3089305609465,
      "avg_batch_size": 127.57142857142857
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4528176832252223,
      "energy_per_request_joules": 208.3708668895252,
      "avg_power_watts": 516.6568164274356,
      "median_itl_ms": 12.23376952111721,
      "output_throughput_tokens_per_sec": 1097.824214299479,
      "p90_itl_ms": 12.520584464073181,
      "p95_itl_ms": 12.980451062321663,
      "p99_itl_ms": 56.04606762528419,
      "avg_batch_size": 15.858910891089108
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1878770881015258,
      "energy_per_request_joules": 86.82471754982495,
      "avg_power_watts": 691.9084429902782,
      "median_itl_ms": 38.656579330563545,
      "output_throughput_tokens_per_sec": 2890.390951482086,
      "p90_itl_ms": 82.72171914577484,
      "p95_itl_ms": 87.65082247555256,
      "p99_itl_ms": 236.39661975204925,
      "avg_batch_size": 191.31730769230768
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1803028832475481,
      "energy_per_request_joules": 83.22016916377432,
      "avg_power_watts": 693.5924849065933,
      "median_itl_ms": 45.98557949066162,
      "output_throughput_tokens_per_sec": 2997.777192076711,
      "p90_itl_ms": 92.31475181877613,
      "p95_itl_ms": 104.63101789355278,
      "p99_itl_ms": 285.7917774468661,
      "avg_batch_size": 241.1573033707865
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.30959750220386845,
      "energy_per_request_joules": 142.67637624757475,
      "avg_power_watts": 559.5918240402709,
      "median_itl_ms": 14.496257528662682,
      "output_throughput_tokens_per_sec": 1662.5027691181322,
      "p90_itl_ms": 15.625864267349243,
      "p95_itl_ms": 55.9028796851635,
      "p99_itl_ms": 62.74990998208523,
      "avg_batch_size": 31.768924302788843
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24638339538749862,
      "energy_per_request_joules": 113.00696845218933,
      "avg_power_watts": 628.9821341616944,
      "median_itl_ms": 19.291361793875694,
      "output_throughput_tokens_per_sec": 2290.7350482120546,
      "p90_itl_ms": 54.48200739920139,
      "p95_itl_ms": 63.501773029565804,
      "p99_itl_ms": 90.03322672098875,
      "avg_batch_size": 63.7093023255814
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7473582609026902,
      "energy_per_request_joules": 348.47257551306757,
      "avg_power_watts": 497.97820634482736,
      "median_itl_ms": 11.14979200065136,
      "output_throughput_tokens_per_sec": 626.6968119007904,
      "p90_itl_ms": 11.312101781368256,
      "p95_itl_ms": 11.4034753292799,
      "p99_itl_ms": 53.9729418605566,
      "avg_batch_size": 7.90084985835694
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.21964969150130492,
      "energy_per_request_joules": 99.74627113651152,
      "avg_power_watts": 648.1298844528815,
      "median_itl_ms": 24.107911624014378,
      "output_throughput_tokens_per_sec": 2472.582665606881,
      "p90_itl_ms": 65.90593066066504,
      "p95_itl_ms": 71.27436995506287,
      "p99_itl_ms": 130.53565505892036,
      "avg_batch_size": 95.48591549295774
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1771556022821433,
      "energy_per_request_joules": 89.06497904734755,
      "avg_power_watts": 663.0256114403097,
      "median_itl_ms": 25.85348580032587,
      "output_throughput_tokens_per_sec": 3104.6143656012327,
      "p90_itl_ms": 63.7841984629631,
      "p95_itl_ms": 70.4051981680095,
      "p99_itl_ms": 140.63350588083262,
      "avg_batch_size": 127.4873949579832
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.354120076813534,
      "energy_per_request_joules": 178.39352182101797,
      "avg_power_watts": 495.2273554020826,
      "median_itl_ms": 9.988353587687016,
      "output_throughput_tokens_per_sec": 1272.4783269186257,
      "p90_itl_ms": 10.147353261709213,
      "p95_itl_ms": 10.4744735173881,
      "p99_itl_ms": 52.39917958155275,
      "avg_batch_size": 15.847645429362881
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1646485390567957,
      "energy_per_request_joules": 83.76542661391157,
      "avg_power_watts": 691.3507118198783,
      "median_itl_ms": 34.82525423169136,
      "output_throughput_tokens_per_sec": 3496.4315947781697,
      "p90_itl_ms": 76.76311247050762,
      "p95_itl_ms": 79.32483814656734,
      "p99_itl_ms": 170.12767519801855,
      "avg_batch_size": 191.2828282828283
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1552074075399423,
      "energy_per_request_joules": 79.17199580690063,
      "avg_power_watts": 692.9838955224471,
      "median_itl_ms": 43.37812401354313,
      "output_throughput_tokens_per_sec": 3479.3885581574964,
      "p90_itl_ms": 86.51775121688843,
      "p95_itl_ms": 97.61630296707153,
      "p99_itl_ms": 242.5210145488381,
      "avg_batch_size": 255.34883720930233
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2534938568329834,
      "energy_per_request_joules": 127.15043914563014,
      "avg_power_watts": 545.0429946089819,
      "median_itl_ms": 12.150208465754986,
      "output_throughput_tokens_per_sec": 2015.4042953874011,
      "p90_itl_ms": 13.254364021122456,
      "p95_itl_ms": 47.185920644551516,
      "p99_itl_ms": 56.61105271428824,
      "avg_batch_size": 31.75862068965517
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.20730483907221142,
      "energy_per_request_joules": 104.18586509367923,
      "avg_power_watts": 617.5559167488011,
      "median_itl_ms": 16.765335574746132,
      "output_throughput_tokens_per_sec": 2725.385115103632,
      "p90_itl_ms": 50.713999196887016,
      "p95_itl_ms": 59.038255363702774,
      "p99_itl_ms": 68.72391104698187,
      "avg_batch_size": 63.592592592592595
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5858353618286317,
      "energy_per_request_joules": 296.5471140543948,
      "avg_power_watts": 467.2015190264626,
      "median_itl_ms": 9.139970876276493,
      "output_throughput_tokens_per_sec": 761.0455509247546,
      "p90_itl_ms": 9.268289431929588,
      "p95_itl_ms": 9.342021029442549,
      "p99_itl_ms": 49.64682737365365,
      "avg_batch_size": 7.936236391912908
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.18655056371185572,
      "energy_per_request_joules": 93.45563835795397,
      "avg_power_watts": 641.6266384074639,
      "median_itl_ms": 21.002349443733692,
      "output_throughput_tokens_per_sec": 2980.325844447607,
      "p90_itl_ms": 57.588535360991955,
      "p95_itl_ms": 64.92515467107296,
      "p99_itl_ms": 91.56877128407345,
      "avg_batch_size": 95.63636363636364
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.542182578567927,
      "energy_per_request_joules": 466.90285722453757,
      "avg_power_watts": 4508.793870120932,
      "median_itl_ms": 112.50159650080604,
      "output_throughput_tokens_per_sec": 5802.046387798244,
      "p90_itl_ms": 135.53495049563935,
      "p95_itl_ms": 139.58224974703626,
      "p99_itl_ms": 170.15029240646984,
      "avg_batch_size": 1022.6304347826087
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.5122787665380237,
      "energy_per_request_joules": 1331.0017335729428,
      "avg_power_watts": 4999.513810745349,
      "median_itl_ms": 36.91444099240471,
      "output_throughput_tokens_per_sec": 2750.967690192201,
      "p90_itl_ms": 39.362635600264184,
      "p95_itl_ms": 41.41223899787292,
      "p99_itl_ms": 82.56698048324324,
      "avg_batch_size": 127.82773109243698
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.46823173105889326,
      "energy_per_request_joules": 409.482366537498,
      "avg_power_watts": 4779.828628691161,
      "median_itl_ms": 143.55941200483358,
      "output_throughput_tokens_per_sec": 6706.487559812184,
      "p90_itl_ms": 171.39873139676638,
      "p95_itl_ms": 178.11441884259693,
      "p99_itl_ms": 231.99295172540582,
      "avg_batch_size": 1534.0267857142858
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 5.5810838222939285,
      "energy_per_request_joules": 4956.073287800221,
      "avg_power_watts": 4603.751957820395,
      "median_itl_ms": 18.702683999435976,
      "output_throughput_tokens_per_sec": 812.9070425417179,
      "p90_itl_ms": 19.14035200024955,
      "p95_itl_ms": 19.311960000777617,
      "p99_itl_ms": 58.10142100381199,
      "avg_batch_size": 15.98239110287303
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.41989460488784736,
      "energy_per_request_joules": 366.7888721248703,
      "avg_power_watts": 4924.190101961018,
      "median_itl_ms": 155.6095345003996,
      "output_throughput_tokens_per_sec": 7066.936494253913,
      "p90_itl_ms": 187.33278021099977,
      "p95_itl_ms": 200.78389109912675,
      "p99_itl_ms": 286.1253915645647,
      "avg_batch_size": 2044.982142857143
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.9397195034117868,
      "energy_per_request_joules": 820.2126944940134,
      "avg_power_watts": 5077.562470171535,
      "median_itl_ms": 43.46898099174723,
      "output_throughput_tokens_per_sec": 3815.879722977546,
      "p90_itl_ms": 48.61373399035074,
      "p95_itl_ms": 60.02770250051981,
      "p99_itl_ms": 96.95789399847854,
      "avg_batch_size": 255.66101694915255
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 4.200629952038238,
      "energy_per_request_joules": 3645.1335604803685,
      "avg_power_watts": 4530.013731280813,
      "median_itl_ms": 28.806008995161392,
      "output_throughput_tokens_per_sec": 1048.4010104698286,
      "p90_itl_ms": 29.66216999629978,
      "p95_itl_ms": 30.026355001609772,
      "p99_itl_ms": 62.37182980694343,
      "avg_batch_size": 31.9735516372796
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6740768160790235,
      "energy_per_request_joules": 582.6883909444114,
      "avg_power_watts": 4867.028033186916,
      "median_itl_ms": 58.895011999993585,
      "output_throughput_tokens_per_sec": 5565.049837910219,
      "p90_itl_ms": 98.12347019906156,
      "p95_itl_ms": 106.29511259903666,
      "p99_itl_ms": 120.94796748075176,
      "avg_batch_size": 511.37142857142857
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 2.5416779233101696,
      "energy_per_request_joules": 2208.2986392148973,
      "avg_power_watts": 4770.273283734266,
      "median_itl_ms": 32.98562100098934,
      "output_throughput_tokens_per_sec": 1758.5765724612713,
      "p90_itl_ms": 33.926146395970136,
      "p95_itl_ms": 35.452592905494384,
      "p99_itl_ms": 57.160001784504864,
      "avg_batch_size": 63.93736017897092
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 8.396027671034311,
      "energy_per_request_joules": 7410.486528426251,
      "avg_power_watts": 3941.7836755253757,
      "median_itl_ms": 16.562483004236128,
      "output_throughput_tokens_per_sec": 462.4465496588866,
      "p90_itl_ms": 17.01701099955244,
      "p95_itl_ms": 17.150035199301783,
      "p99_itl_ms": 17.91131647914881,
      "avg_batch_size": 7.989968321013728
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.37321453066694377,
      "energy_per_request_joules": 326.0231812181162,
      "avg_power_watts": 5395.589402297423,
      "median_itl_ms": 240.9158169903094,
      "output_throughput_tokens_per_sec": 7333.191832190612,
      "p90_itl_ms": 320.58046300080605,
      "p95_itl_ms": 367.319661048532,
      "p99_itl_ms": 789.0634731343014,
      "avg_batch_size": 4090.3977272727275
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 6.456770105737344,
      "energy_per_request_joules": 5584.70889877075,
      "avg_power_watts": 2562.1769211252954,
      "median_itl_ms": 19.666570995468646,
      "output_throughput_tokens_per_sec": 394.1203387290699,
      "p90_itl_ms": 20.312772403121926,
      "p95_itl_ms": 20.50538700132165,
      "p99_itl_ms": 21.42864028399345,
      "avg_batch_size": 7.990445859872612
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 4.550388063648032,
      "energy_per_request_joules": 3956.1002725542494,
      "avg_power_watts": 2896.7329268203844,
      "median_itl_ms": 24.541911014239304,
      "output_throughput_tokens_per_sec": 622.534349976571,
      "p90_itl_ms": 25.69366459356388,
      "p95_itl_ms": 26.0902940921369,
      "p99_itl_ms": 56.299414734530714,
      "avg_batch_size": 15.983870967741936
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 3.05275443145985,
      "energy_per_request_joules": 2660.1117799463236,
      "avg_power_watts": 3185.865439767311,
      "median_itl_ms": 29.83295900048688,
      "output_throughput_tokens_per_sec": 1018.923944515232,
      "p90_itl_ms": 30.65786920778919,
      "p95_itl_ms": 31.018828594824296,
      "p99_itl_ms": 53.95943550916854,
      "avg_batch_size": 31.96969696969697
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 1.2073053901940252,
      "energy_per_request_joules": 1047.6840546893295,
      "avg_power_watts": 3142.9811977702625,
      "median_itl_ms": 47.08670650143176,
      "output_throughput_tokens_per_sec": 2190.8937519351834,
      "p90_itl_ms": 50.35464620159473,
      "p95_itl_ms": 53.13555959728546,
      "p99_itl_ms": 85.30445821001186,
      "avg_batch_size": 127.87
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 2.043033334635237,
      "energy_per_request_joules": 1789.8288810233641,
      "avg_power_watts": 3122.5641096018644,
      "median_itl_ms": 40.821517002768815,
      "output_throughput_tokens_per_sec": 1413.4452840451318,
      "p90_itl_ms": 42.09522349992767,
      "p95_itl_ms": 43.59326000849251,
      "p99_itl_ms": 67.2282963452744,
      "avg_batch_size": 63.91256830601093
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.34368513275277296,
      "energy_per_request_joules": 298.38028333669223,
      "avg_power_watts": 3002.1073530617564,
      "median_itl_ms": 103.86629600543529,
      "output_throughput_tokens_per_sec": 5452.265759178418,
      "p90_itl_ms": 128.0457684013527,
      "p95_itl_ms": 135.17154659202788,
      "p99_itl_ms": 182.001227917498,
      "avg_batch_size": 1022.5977011494252
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3162059656469451,
      "energy_per_request_joules": 278.39042896426184,
      "avg_power_watts": 3006.796685734427,
      "median_itl_ms": 135.5150669987779,
      "output_throughput_tokens_per_sec": 5488.138886276164,
      "p90_itl_ms": 169.60162940667945,
      "p95_itl_ms": 188.24133549642283,
      "p99_itl_ms": 286.6105389723092,
      "avg_batch_size": 1411.1935483870968
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2676523879809479,
      "energy_per_request_joules": 231.9495459068565,
      "avg_power_watts": 3268.479266859503,
      "median_itl_ms": 143.62831650942098,
      "output_throughput_tokens_per_sec": 5305.98386445319,
      "p90_itl_ms": 177.43998000514694,
      "p95_itl_ms": 194.96807576797437,
      "p99_itl_ms": 353.6779921996638,
      "avg_batch_size": 2044.8076923076924
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.710970071755604,
      "energy_per_request_joules": 624.8232723189357,
      "avg_power_watts": 3203.8406083650552,
      "median_itl_ms": 53.255411505233496,
      "output_throughput_tokens_per_sec": 3217.7612268391977,
      "p90_itl_ms": 58.379866098403,
      "p95_itl_ms": 64.27994945697716,
      "p99_itl_ms": 105.64801411645021,
      "avg_batch_size": 255.7062937062937
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4629841694171579,
      "energy_per_request_joules": 407.37904725739253,
      "avg_power_watts": 3012.2719003895086,
      "median_itl_ms": 67.11570649349596,
      "output_throughput_tokens_per_sec": 4848.3612201965,
      "p90_itl_ms": 106.40274759498425,
      "p95_itl_ms": 114.1425818655989,
      "p99_itl_ms": 130.3036870845244,
      "avg_batch_size": 511.3775510204082
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24557551756706672,
      "energy_per_request_joules": 213.28545466493532,
      "avg_power_watts": 3231.4177508472008,
      "median_itl_ms": 118.4986879961798,
      "output_throughput_tokens_per_sec": 5390.174816690904,
      "p90_itl_ms": 222.9848100047093,
      "p95_itl_ms": 238.56627569039105,
      "p99_itl_ms": 360.99415537231835,
      "avg_batch_size": 3046.5263157894738
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "nickname": "Qwen 3 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24024534151505447,
      "energy_per_request_joules": 209.92863171593132,
      "avg_power_watts": 3196.0657904719633,
      "median_itl_ms": 67.7747610170627,
      "output_throughput_tokens_per_sec": 5260.241071279092,
      "p90_itl_ms": 215.12070119788407,
      "p95_itl_ms": 282.5096203494467,
      "p99_itl_ms": 393.15440698177474,
      "avg_batch_size": 3764.6470588235293
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8217263225202562,
      "energy_per_request_joules": 727.0552650013819,
      "avg_power_watts": 1853.3838545799715,
      "median_itl_ms": 53.917051991447806,
      "output_throughput_tokens_per_sec": 1805.5393989354168,
      "p90_itl_ms": 57.904711982700974,
      "p95_itl_ms": 61.82281699148007,
      "p99_itl_ms": 108.06301402044483,
      "avg_batch_size": 127.85227272727273
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 4.669943195513622,
      "energy_per_request_joules": 4068.3596537103085,
      "avg_power_watts": 1818.2945061663515,
      "median_itl_ms": 40.43045798607636,
      "output_throughput_tokens_per_sec": 383.01404784384545,
      "p90_itl_ms": 41.137090703705326,
      "p95_itl_ms": 41.47334825247526,
      "p99_itl_ms": 82.23042580037145,
      "avg_batch_size": 15.979510022271715
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5006937029286922,
      "energy_per_request_joules": 438.619907732891,
      "avg_power_watts": 1890.8444703429448,
      "median_itl_ms": 64.47548398864456,
      "output_throughput_tokens_per_sec": 3027.3774194003,
      "p90_itl_ms": 70.13620478683151,
      "p95_itl_ms": 80.76567870884868,
      "p99_itl_ms": 119.52163472480606,
      "avg_batch_size": 255.74937965260546
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 2.6271712915194674,
      "energy_per_request_joules": 2317.5088691133965,
      "avg_power_watts": 1894.6462274541648,
      "median_itl_ms": 43.2236600026954,
      "output_throughput_tokens_per_sec": 692.4756994576509,
      "p90_itl_ms": 44.146505699609406,
      "p95_itl_ms": 44.5199030888034,
      "p99_itl_ms": 90.64704591408372,
      "avg_batch_size": 31.96029776674938
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 1.4719871138494172,
      "energy_per_request_joules": 1279.8051087597003,
      "avg_power_watts": 1892.042070500693,
      "median_itl_ms": 47.80994201428257,
      "output_throughput_tokens_per_sec": 1123.240198600195,
      "p90_itl_ms": 49.54287161817774,
      "p95_itl_ms": 51.0372142191045,
      "p99_itl_ms": 93.26520285278093,
      "avg_batch_size": 63.93798449612403
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
      "nickname": "Qwen 3 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 0,
      "energy_per_token_joules": 8.421096003608643,
      "energy_per_request_joules": 7367.011627281942,
      "avg_power_watts": 1805.668383628926,
      "median_itl_ms": 36.719368494232185,
      "output_throughput_tokens_per_sec": 212.54132774460922,
      "p90_itl_ms": 37.812683993251994,
      "p95_itl_ms": 37.99658724456094,
      "p99_itl_ms": 38.57398231921252,
      "avg_batch_size": 7.990046127700898
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.06194408549009,
      "energy_per_request_joules": 37.99201956234111,
      "avg_power_watts": 932.265569899849,
      "median_itl_ms": 61.50677800178528,
      "output_throughput_tokens_per_sec": 10361.498363912235,
      "p90_itl_ms": 78.1277182046324,
      "p95_itl_ms": 85.33365190087349,
      "p99_itl_ms": 150.3133866604185,
      "avg_batch_size": 1022.0232558139535
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.12247675519829204,
      "energy_per_request_joules": 74.2123020033151,
      "avg_power_watts": 708.7273838663926,
      "median_itl_ms": 19.06669449817855,
      "output_throughput_tokens_per_sec": 5219.692467744772,
      "p90_itl_ms": 34.60722669551615,
      "p95_itl_ms": 40.30590570473578,
      "p99_itl_ms": 54.33177557948516,
      "avg_batch_size": 127.70212765957447
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3981640710999994,
      "energy_per_request_joules": 249.56838433485814,
      "avg_power_watts": 761.6265567745648,
      "median_itl_ms": 7.8423559898510575,
      "output_throughput_tokens_per_sec": 1874.397101911038,
      "p90_itl_ms": 11.547983792843299,
      "p95_itl_ms": 14.749675209168343,
      "p99_itl_ms": 21.02427156176417,
      "avg_batch_size": 15.948170731707316
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.08918614547523977,
      "energy_per_request_joules": 55.631687252929815,
      "avg_power_watts": 955.0710709996039,
      "median_itl_ms": 21.165275014936924,
      "output_throughput_tokens_per_sec": 6736.122930675008,
      "p90_itl_ms": 32.557443191763014,
      "p95_itl_ms": 37.41190079599618,
      "p99_itl_ms": 53.248244108399376,
      "avg_batch_size": 255.5681818181818
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24413006412812105,
      "energy_per_request_joules": 147.60976251438845,
      "avg_power_watts": 699.7358859610536,
      "median_itl_ms": 9.416910004802048,
      "output_throughput_tokens_per_sec": 2742.582291148786,
      "p90_itl_ms": 18.61438018968329,
      "p95_itl_ms": 23.177931003738202,
      "p99_itl_ms": 34.41342919832098,
      "avg_batch_size": 31.91346153846154
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.16689229999538066,
      "energy_per_request_joules": 101.64963425431539,
      "avg_power_watts": 696.9625164938583,
      "median_itl_ms": 12.726755507173948,
      "output_throughput_tokens_per_sec": 3789.317368446612,
      "p90_itl_ms": 25.543338389252316,
      "p95_itl_ms": 30.718190365587354,
      "p99_itl_ms": 44.96450745529728,
      "avg_batch_size": 63.75912408759124
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6993091867226764,
      "energy_per_request_joules": 430.1127103864672,
      "avg_power_watts": 759.9467920298994,
      "median_itl_ms": 7.15609549661167,
      "output_throughput_tokens_per_sec": 1077.4003041303158,
      "p90_itl_ms": 8.386991303996183,
      "p95_itl_ms": 9.683607009355912,
      "p99_itl_ms": 17.90369909140282,
      "avg_batch_size": 7.935087719298245
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.05477111725443875,
      "energy_per_request_joules": 33.58277147726921,
      "avg_power_watts": 869.4923250228219,
      "median_itl_ms": 112.645222019637,
      "output_throughput_tokens_per_sec": 9093.253106552436,
      "p90_itl_ms": 142.40702299866825,
      "p95_itl_ms": 153.51142458384857,
      "p99_itl_ms": 215.13447568984702,
      "avg_batch_size": 2044.5882352941176
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07702227314543146,
      "energy_per_request_joules": 47.80931954311802,
      "avg_power_watts": 913.3277617016568,
      "median_itl_ms": 39.11911048635375,
      "output_throughput_tokens_per_sec": 8554.685874111585,
      "p90_itl_ms": 56.06306250265334,
      "p95_itl_ms": 59.9696527569904,
      "p99_itl_ms": 71.64305746671742,
      "avg_batch_size": 511.2625
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.05640828491477477,
      "energy_per_request_joules": 52.3470536595582,
      "avg_power_watts": 600.6375753585329,
      "median_itl_ms": 88.67768199706916,
      "output_throughput_tokens_per_sec": 7828.770744253639,
      "p90_itl_ms": 114.47294919344131,
      "p95_itl_ms": 120.49813674530014,
      "p99_itl_ms": 141.11808279762045,
      "avg_batch_size": 1022.6375
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.15710887899797188,
      "energy_per_request_joules": 141.16048666000196,
      "avg_power_watts": 828.9865970187229,
      "median_itl_ms": 20.9287769976072,
      "output_throughput_tokens_per_sec": 4555.720523705224,
      "p90_itl_ms": 30.844363593496386,
      "p95_itl_ms": 38.85331525525537,
      "p99_itl_ms": 82.43987930385622,
      "avg_batch_size": 127.78378378378379
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.056932541778626215,
      "energy_per_request_joules": 52.3208391000015,
      "avg_power_watts": 606.2796373072633,
      "median_itl_ms": 123.30110900802538,
      "output_throughput_tokens_per_sec": 7441.422160776314,
      "p90_itl_ms": 161.50045840768144,
      "p95_itl_ms": 173.22267589042895,
      "p99_itl_ms": 195.9992899087957,
      "avg_batch_size": 1478.2241379310344
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.5352064009887373,
      "energy_per_request_joules": 487.79045890114133,
      "avg_power_watts": 659.3575560299904,
      "median_itl_ms": 10.813061991939321,
      "output_throughput_tokens_per_sec": 1218.3336707255166,
      "p90_itl_ms": 20.17996278591454,
      "p95_itl_ms": 24.632791586918753,
      "p99_itl_ms": 57.74696251959539,
      "avg_batch_size": 15.908594815825376
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11617219988664404,
      "energy_per_request_joules": 104.70586761853554,
      "avg_power_watts": 837.8363290346232,
      "median_itl_ms": 23.712188500212505,
      "output_throughput_tokens_per_sec": 5695.37680971048,
      "p90_itl_ms": 32.67976699862629,
      "p95_itl_ms": 43.808169750263914,
      "p99_itl_ms": 73.9106492110294,
      "avg_batch_size": 191.71844660194174
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.10259905792147143,
      "energy_per_request_joules": 93.72985029724424,
      "avg_power_watts": 910.2569463412497,
      "median_itl_ms": 26.267984503647313,
      "output_throughput_tokens_per_sec": 7526.510996866643,
      "p90_itl_ms": 35.47000579710584,
      "p95_itl_ms": 40.975108358543366,
      "p99_itl_ms": 78.78310811793199,
      "avg_batch_size": 255.62569832402235
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.38263381276297725,
      "energy_per_request_joules": 349.9358104000504,
      "avg_power_watts": 742.5519660462408,
      "median_itl_ms": 14.283012496889569,
      "output_throughput_tokens_per_sec": 1889.9771030166637,
      "p90_itl_ms": 23.598392892745327,
      "p95_itl_ms": 28.098717705870452,
      "p99_itl_ms": 67.64560521638487,
      "avg_batch_size": 31.924568965517242
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07953600569962882,
      "energy_per_request_joules": 73.45899660008183,
      "avg_power_watts": 703.0843707736994,
      "median_itl_ms": 38.00327400676906,
      "output_throughput_tokens_per_sec": 7677.051310042895,
      "p90_itl_ms": 95.90098900371231,
      "p95_itl_ms": 101.6370452067349,
      "p99_itl_ms": 113.81626507500187,
      "avg_batch_size": 511.1168831168831
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24929438124276776,
      "energy_per_request_joules": 231.63294551851206,
      "avg_power_watts": 724.6018312032227,
      "median_itl_ms": 19.317286991281435,
      "output_throughput_tokens_per_sec": 2638.6041577761766,
      "p90_itl_ms": 31.938829791033644,
      "p95_itl_ms": 37.97192979836833,
      "p99_itl_ms": 83.05495763168435,
      "avg_batch_size": 63.82214765100671
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.06817194937114986,
      "energy_per_request_joules": 62.88193259087031,
      "avg_power_watts": 547.2774521494814,
      "median_itl_ms": 86.87586602172814,
      "output_throughput_tokens_per_sec": 6988.204539837015,
      "p90_itl_ms": 112.73916799109429,
      "p95_itl_ms": 116.789551495458,
      "p99_itl_ms": 134.5816407061647,
      "avg_batch_size": 767.0610687022901
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7216811341515716,
      "energy_per_request_joules": 660.287494543943,
      "avg_power_watts": 656.7634883648834,
      "median_itl_ms": 8.242472002166323,
      "output_throughput_tokens_per_sec": 906.5188827972148,
      "p90_itl_ms": 11.42477749090176,
      "p95_itl_ms": 12.892912994720971,
      "p99_itl_ms": 17.201489711005706,
      "avg_batch_size": 7.93570722057369
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "nickname": "Qwen 3 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 0,
      "energy_per_token_joules": 0.18753276379243197,
      "energy_per_request_joules": 172.60925807376233,
      "avg_power_watts": 825.2291682923685,
      "median_itl_ms": 18.95634800894186,
      "output_throughput_tokens_per_sec": 3938.8419618035473,
      "p90_itl_ms": 28.834016789915054,
      "p95_itl_ms": 36.271817538363265,
      "p99_itl_ms": 79.3119276460493,
      "avg_batch_size": 95.734375
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.20864651577192456,
      "energy_per_request_joules": 132.2973764829926,
      "avg_power_watts": 975.5957432445775,
      "median_itl_ms": 24.72050450160168,
      "output_throughput_tokens_per_sec": 3643.9591737120145,
      "p90_itl_ms": 32.939433003775775,
      "p95_itl_ms": 38.228705797519076,
      "p99_itl_ms": 65.6113175497738,
      "avg_batch_size": 127.78048780487805
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.8159244170412998,
      "energy_per_request_joules": 512.9694499505373,
      "avg_power_watts": 836.3809406652724,
      "median_itl_ms": 15.11033899441827,
      "output_throughput_tokens_per_sec": 1000.8879222181407,
      "p90_itl_ms": 17.966197305941026,
      "p95_itl_ms": 20.78293744998517,
      "p99_itl_ms": 31.63132181711269,
      "avg_batch_size": 15.96742671009772
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.17681459087226048,
      "energy_per_request_joules": 112.34719675593938,
      "avg_power_watts": 969.4150830337443,
      "median_itl_ms": 31.635102990549058,
      "output_throughput_tokens_per_sec": 4566.646199188962,
      "p90_itl_ms": 41.79628597921692,
      "p95_itl_ms": 51.09449400333688,
      "p99_itl_ms": 83.85509598883802,
      "avg_batch_size": 191.58163265306123
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.15072305201913658,
      "energy_per_request_joules": 94.57739042768381,
      "avg_power_watts": 971.2567983598984,
      "median_itl_ms": 36.022864005644806,
      "output_throughput_tokens_per_sec": 5598.395288953967,
      "p90_itl_ms": 48.6644494056236,
      "p95_itl_ms": 56.358281818393145,
      "p99_itl_ms": 97.60897816129719,
      "avg_batch_size": 255.62285714285716
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4734976077616866,
      "energy_per_request_joules": 300.0351809182488,
      "avg_power_watts": 848.7690635227195,
      "median_itl_ms": 16.813653986901045,
      "output_throughput_tokens_per_sec": 1698.376407566365,
      "p90_itl_ms": 24.107908585574478,
      "p95_itl_ms": 27.652266106451858,
      "p99_itl_ms": 40.08290835598017,
      "avg_batch_size": 31.902298850574713
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1405811962285976,
      "energy_per_request_joules": 89.26404865431735,
      "avg_power_watts": 971.6747776603263,
      "median_itl_ms": 50.2491410006769,
      "output_throughput_tokens_per_sec": 5418.501101645695,
      "p90_itl_ms": 66.56363700749351,
      "p95_itl_ms": 77.11441750579975,
      "p99_itl_ms": 131.57422270800444,
      "avg_batch_size": 383.34640522875816
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.15078613374588773,
      "energy_per_request_joules": 94.60777040155742,
      "avg_power_watts": 968.8827415172412,
      "median_itl_ms": 57.57595301838592,
      "output_throughput_tokens_per_sec": 5508.589952542401,
      "p90_itl_ms": 93.01012900541537,
      "p95_itl_ms": 131.57266860362097,
      "p99_itl_ms": 250.04708052263587,
      "avg_batch_size": 455.73026315789474
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.31263251437703116,
      "energy_per_request_joules": 197.24272318925327,
      "avg_power_watts": 945.4371052002505,
      "median_itl_ms": 19.583309011068195,
      "output_throughput_tokens_per_sec": 2786.367213199761,
      "p90_itl_ms": 27.58910280535929,
      "p95_itl_ms": 31.90371829841751,
      "p99_itl_ms": 48.932129096356185,
      "avg_batch_size": 63.91
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.5450541142659606,
      "energy_per_request_joules": 997.7141677615186,
      "avg_power_watts": 859.6469411324731,
      "median_itl_ms": 14.126725000096485,
      "output_throughput_tokens_per_sec": 551.1340492165906,
      "p90_itl_ms": 15.713961998699233,
      "p95_itl_ms": 17.302533000474796,
      "p99_itl_ms": 27.10405021207407,
      "avg_batch_size": 7.973481608212147
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.23657720080514735,
      "energy_per_request_joules": 148.71996008309438,
      "avg_power_watts": 970.4547244114405,
      "median_itl_ms": 21.336754987714812,
      "output_throughput_tokens_per_sec": 3112.050778889969,
      "p90_itl_ms": 28.89867899939418,
      "p95_itl_ms": 33.98535900050772,
      "p99_itl_ms": 50.91743976459812,
      "avg_batch_size": 95.79577464788733
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.06121435358613941,
      "energy_per_request_joules": 39.222798162107956,
      "avg_power_watts": 722.8552752357476,
      "median_itl_ms": 79.63052600098308,
      "output_throughput_tokens_per_sec": 10752.671180776397,
      "p90_itl_ms": 110.10884499410167,
      "p95_itl_ms": 122.377487263293,
      "p99_itl_ms": 157.1214812764083,
      "avg_batch_size": 1022.3878787878788
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.0820136515330188,
      "energy_per_request_joules": 53.94159600340641,
      "avg_power_watts": 747.8724226373723,
      "median_itl_ms": 12.078401006874628,
      "output_throughput_tokens_per_sec": 7164.223284931941,
      "p90_itl_ms": 22.3784514964791,
      "p95_itl_ms": 26.97687374893576,
      "p99_itl_ms": 36.58603523945203,
      "avg_batch_size": 127.67692307692307
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.053058117691038,
      "energy_per_request_joules": 34.41909628921428,
      "avg_power_watts": 801.1575857379834,
      "median_itl_ms": 91.19931398890913,
      "output_throughput_tokens_per_sec": 12393.30535816706,
      "p90_itl_ms": 113.74230188957881,
      "p95_itl_ms": 121.03408360417234,
      "p99_itl_ms": 169.20664652658155,
      "avg_batch_size": 1426.7027027027027
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2551701203961786,
      "energy_per_request_joules": 164.9530298410289,
      "avg_power_watts": 532.3667484570893,
      "median_itl_ms": 5.781241008662619,
      "output_throughput_tokens_per_sec": 2064.690338624991,
      "p90_itl_ms": 14.502711396198729,
      "p95_itl_ms": 19.645376897824438,
      "p99_itl_ms": 29.29614132444839,
      "avg_batch_size": 15.941747572815533
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07246377449504585,
      "energy_per_request_joules": 47.42141919949401,
      "avg_power_watts": 830.6249908866325,
      "median_itl_ms": 20.050100021762773,
      "output_throughput_tokens_per_sec": 9570.257055740109,
      "p90_itl_ms": 32.296393398428336,
      "p95_itl_ms": 37.01951170514807,
      "p99_itl_ms": 49.14332657412161,
      "avg_batch_size": 255.35643564356437
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1848479220385367,
      "energy_per_request_joules": 118.890970278417,
      "avg_power_watts": 494.07917148633146,
      "median_itl_ms": 10.273801002767868,
      "output_throughput_tokens_per_sec": 2609.9561403765606,
      "p90_itl_ms": 21.252272714627917,
      "p95_itl_ms": 25.5326471538865,
      "p99_itl_ms": 34.70710960653379,
      "avg_batch_size": 31.931623931623932
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.06183710297743524,
      "energy_per_request_joules": 40.51024704674587,
      "avg_power_watts": 752.1679936463977,
      "median_itl_ms": 34.60888950212393,
      "output_throughput_tokens_per_sec": 9840.4307222526,
      "p90_itl_ms": 60.08085860521533,
      "p95_itl_ms": 65.76630160270724,
      "p99_itl_ms": 77.67809892975502,
      "avg_batch_size": 510.9753086419753
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.12252114683091954,
      "energy_per_request_joules": 78.73551093089202,
      "avg_power_watts": 542.9719727131063,
      "median_itl_ms": 12.89358499343507,
      "output_throughput_tokens_per_sec": 4115.716377449039,
      "p90_itl_ms": 23.25513940304518,
      "p95_itl_ms": 27.942761490703564,
      "p99_itl_ms": 37.58133703260676,
      "avg_batch_size": 63.82608695652174
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.43039510958494537,
      "energy_per_request_joules": 274.88167193717175,
      "avg_power_watts": 646.3385532103331,
      "median_itl_ms": 4.971045011188835,
      "output_throughput_tokens_per_sec": 1480.78481905731,
      "p90_itl_ms": 7.418043198413215,
      "p95_itl_ms": 8.840273588430135,
      "p99_itl_ms": 16.70140288886577,
      "avg_batch_size": 7.948717948717949
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7720661413385848,
      "energy_per_request_joules": 651.8722566819248,
      "avg_power_watts": 5634.6521511230185,
      "median_itl_ms": 127.63650799752213,
      "output_throughput_tokens_per_sec": 5090.667765395188,
      "p90_itl_ms": 167.937457410153,
      "p95_itl_ms": 175.6417997050448,
      "p99_itl_ms": 209.52899652125782,
      "avg_batch_size": 1022.4545454545455
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.9363851610857714,
      "energy_per_request_joules": 1645.4981296655167,
      "avg_power_watts": 5628.633143216881,
      "median_itl_ms": 38.835546001791954,
      "output_throughput_tokens_per_sec": 2423.682097263874,
      "p90_itl_ms": 45.542008604388684,
      "p95_itl_ms": 57.851680801832075,
      "p99_itl_ms": 130.0896560336696,
      "avg_batch_size": 127.86666666666666
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 6.066418282288274,
      "energy_per_request_joules": 5098.238066839519,
      "avg_power_watts": 4421.671082109635,
      "median_itl_ms": 20.335174005595036,
      "output_throughput_tokens_per_sec": 716.7100549477094,
      "p90_itl_ms": 21.167887997580692,
      "p95_itl_ms": 21.435712999664247,
      "p99_itl_ms": 109.65111887722743,
      "avg_batch_size": 15.981912144702843
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 1.3090927025194032,
      "energy_per_request_joules": 1093.9860157824724,
      "avg_power_watts": 5935.4727918451335,
      "median_itl_ms": 48.59261299134232,
      "output_throughput_tokens_per_sec": 3350.6518726402414,
      "p90_itl_ms": 62.114378809928894,
      "p95_itl_ms": 103.47795409325045,
      "p99_itl_ms": 131.67373138101533,
      "avg_batch_size": 255.69285714285715
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 4.389352963025634,
      "energy_per_request_joules": 3733.007527773207,
      "avg_power_watts": 4790.504846711863,
      "median_itl_ms": 26.71557999565266,
      "output_throughput_tokens_per_sec": 1061.212082992725,
      "p90_itl_ms": 28.485231501690578,
      "p95_itl_ms": 28.994712258281652,
      "p99_itl_ms": 121.63755995570547,
      "avg_batch_size": 31.95736434108527
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.9634798672299785,
      "energy_per_request_joules": 818.1863505330515,
      "avg_power_watts": 5383.808505403248,
      "median_itl_ms": 64.13963149680058,
      "output_throughput_tokens_per_sec": 3896.79965368589,
      "p90_itl_ms": 128.64145500498125,
      "p95_itl_ms": 140.48716849356424,
      "p99_itl_ms": 160.8727269434894,
      "avg_batch_size": 511.4634146341463
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 2.9196806888839,
      "energy_per_request_joules": 2477.5543545664264,
      "avg_power_watts": 5185.741514447487,
      "median_itl_ms": 32.58884750539437,
      "output_throughput_tokens_per_sec": 1615.8088772067629,
      "p90_itl_ms": 35.75396790110972,
      "p95_itl_ms": 39.66121470148207,
      "p99_itl_ms": 127.48976287257393,
      "avg_batch_size": 63.93899782135076
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.904697738474797,
      "energy_per_request_joules": 767.9969383479814,
      "avg_power_watts": 5265.756284829935,
      "median_itl_ms": 113.01947399624623,
      "output_throughput_tokens_per_sec": 4606.249761912595,
      "p90_itl_ms": 162.24553100473716,
      "p95_itl_ms": 168.0515918007586,
      "p99_itl_ms": 199.70160615514033,
      "avg_batch_size": 767.1405405405405
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 8.565539030815744,
      "energy_per_request_joules": 7249.766839401403,
      "avg_power_watts": 3853.81992416062,
      "median_itl_ms": 16.83571099420078,
      "output_throughput_tokens_per_sec": 446.68501684199833,
      "p90_itl_ms": 17.286713790963404,
      "p95_itl_ms": 17.45043160044588,
      "p99_itl_ms": 18.071177114616148,
      "avg_batch_size": 7.991587802313354
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.630142091962096,
      "energy_per_request_joules": 532.4669908422877,
      "avg_power_watts": 5861.563812319105,
      "median_itl_ms": 187.29518799227662,
      "output_throughput_tokens_per_sec": 5080.2366799152815,
      "p90_itl_ms": 241.26953700033485,
      "p95_itl_ms": 267.2704561962746,
      "p99_itl_ms": 459.060942842625,
      "avg_batch_size": 2042.2179487179487
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6063442759413469,
      "energy_per_request_joules": 510.3790437450712,
      "avg_power_watts": 5469.903991899082,
      "median_itl_ms": 185.5040895025013,
      "output_throughput_tokens_per_sec": 4814.353124924976,
      "p90_itl_ms": 331.0587235027924,
      "p95_itl_ms": 357.32441850268515,
      "p99_itl_ms": 627.1504627031377,
      "avg_batch_size": 3007.5081967213114
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 21.864374093759835,
      "energy_per_request_joules": 7946.248051989536,
      "avg_power_watts": 5877.9501427961595,
      "median_itl_ms": 29.06466599961277,
      "output_throughput_tokens_per_sec": 266.54460414589056,
      "p90_itl_ms": 29.44802339770831,
      "p95_itl_ms": 29.688990950671723,
      "p99_itl_ms": 37.66600416842266,
      "avg_batch_size": 7.979517190929042
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 11.620811503666276,
      "energy_per_request_joules": 4277.752356504871,
      "avg_power_watts": 6077.188012596595,
      "median_itl_ms": 29.41388850013027,
      "output_throughput_tokens_per_sec": 517.1160627247838,
      "p90_itl_ms": 29.948657004570123,
      "p95_itl_ms": 30.634326539438916,
      "p99_itl_ms": 51.67656740581149,
      "avg_batch_size": 15.947666195190948
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.7006650136579413,
      "energy_per_request_joules": 1005.0429903073642,
      "avg_power_watts": 7574.999604415671,
      "median_itl_ms": 36.52045650233049,
      "output_throughput_tokens_per_sec": 1696.3612014617338,
      "p90_itl_ms": 46.83387330442201,
      "p95_itl_ms": 81.05555580186768,
      "p99_itl_ms": 192.61761015091906,
      "avg_batch_size": 127.62931034482759
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 6.399475240900085,
      "energy_per_request_joules": 2326.384235718299,
      "avg_power_watts": 6734.613874207607,
      "median_itl_ms": 28.005737498460803,
      "output_throughput_tokens_per_sec": 997.8355622741641,
      "p90_itl_ms": 29.523408997920342,
      "p95_itl_ms": 35.40738280717051,
      "p99_itl_ms": 81.10821318012295,
      "avg_batch_size": 31.91860465116279
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 4.082156992922342,
      "energy_per_request_joules": 1490.585274632415,
      "avg_power_watts": 7349.563787335136,
      "median_itl_ms": 30.750189995160326,
      "output_throughput_tokens_per_sec": 1525.1837382796832,
      "p90_itl_ms": 34.505488503782544,
      "p95_itl_ms": 48.42060674127424,
      "p99_itl_ms": 128.18236754392274,
      "avg_batch_size": 63.80829015544042
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.1932727526589308,
      "energy_per_request_joules": 444.0431271669371,
      "avg_power_watts": 7710.24963406389,
      "median_itl_ms": 145.99897049629362,
      "output_throughput_tokens_per_sec": 3186.14870336205,
      "p90_itl_ms": 162.19715449697105,
      "p95_itl_ms": 172.50488176068762,
      "p99_itl_ms": 856.4103093843734,
      "avg_batch_size": 1021.3015873015873
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.1307190763442474,
      "energy_per_request_joules": 779.8473435026905,
      "avg_power_watts": 7642.860124607908,
      "median_itl_ms": 49.297641999146435,
      "output_throughput_tokens_per_sec": 1988.2742926288,
      "p90_itl_ms": 95.97202859731625,
      "p95_itl_ms": 135.0864815089153,
      "p99_itl_ms": 319.0174898816622,
      "avg_batch_size": 255.1038961038961
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.6819829688512744,
      "energy_per_request_joules": 602.6229605587456,
      "avg_power_watts": 7654.599729808096,
      "median_itl_ms": 77.24275349755771,
      "output_throughput_tokens_per_sec": 2309.2050649383104,
      "p90_itl_ms": 136.37292749626795,
      "p95_itl_ms": 185.58262625447242,
      "p99_itl_ms": 849.8948430991736,
      "avg_batch_size": 510.45454545454544
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.3667623472446568,
      "energy_per_request_joules": 508.16597794635663,
      "avg_power_watts": 7511.669297413645,
      "median_itl_ms": 122.20522700226866,
      "output_throughput_tokens_per_sec": 3090.9076354756,
      "p90_itl_ms": 151.11171999742515,
      "p95_itl_ms": 196.6257254520314,
      "p99_itl_ms": 851.2015087372855,
      "avg_batch_size": 765.6511627906976
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.070698455934894,
      "energy_per_request_joules": 387.8542420386501,
      "avg_power_watts": 7680.174988637808,
      "median_itl_ms": 239.57511500339024,
      "output_throughput_tokens_per_sec": 4054.0729825833246,
      "p90_itl_ms": 291.83659920236096,
      "p95_itl_ms": 303.05594674719026,
      "p99_itl_ms": 870.0112116293167,
      "avg_batch_size": 2042.7924528301887
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.0432878132259005,
      "energy_per_request_joules": 387.1649734985235,
      "avg_power_watts": 7484.256349090715,
      "median_itl_ms": 325.5319989984855,
      "output_throughput_tokens_per_sec": 4418.586432793798,
      "p90_itl_ms": 428.6404837912414,
      "p95_itl_ms": 465.4160458012483,
      "p99_itl_ms": 913.9620979560992,
      "avg_batch_size": 3062.8809523809523
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct",
      "nickname": "Llama 3.1 405B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.0150417813035275,
      "energy_per_request_joules": 375.74735377651336,
      "avg_power_watts": 7530.190882529053,
      "median_itl_ms": 272.3095130058937,
      "output_throughput_tokens_per_sec": 4656.557769006628,
      "p90_itl_ms": 544.915402593324,
      "p95_itl_ms": 616.2923471885733,
      "p99_itl_ms": 977.1967455570126,
      "avg_batch_size": 3588.6633663366338
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 7.0756457261413095,
      "energy_per_request_joules": 2541.7184328078824,
      "avg_power_watts": 3392.955404670849,
      "median_itl_ms": 31.588607496814802,
      "output_throughput_tokens_per_sec": 449.1276679839319,
      "p90_itl_ms": 32.44399398972746,
      "p95_itl_ms": 33.968448425002855,
      "p99_itl_ms": 70.30166173586625,
      "avg_batch_size": 15.94638069705094
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 12.98532478697247,
      "energy_per_request_joules": 4876.598144607552,
      "avg_power_watts": 3451.197983196121,
      "median_itl_ms": 29.202338017057627,
      "output_throughput_tokens_per_sec": 263.92857337921396,
      "p90_itl_ms": 29.674868521397002,
      "p95_itl_ms": 29.974431738082785,
      "p99_itl_ms": 41.281948534015115,
      "avg_batch_size": 7.973407977606718
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 4.095746936750917,
      "energy_per_request_joules": 1483.8283189412648,
      "avg_power_watts": 3544.362952014253,
      "median_itl_ms": 33.71466898533981,
      "output_throughput_tokens_per_sec": 747.203566170474,
      "p90_itl_ms": 36.17100650444627,
      "p95_itl_ms": 42.246173521562014,
      "p99_itl_ms": 108.67303599661682,
      "avg_batch_size": 31.898058252427184
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.7738932556923221,
      "energy_per_request_joules": 653.8476995329744,
      "avg_power_watts": 3849.82022158273,
      "median_itl_ms": 45.75715999817476,
      "output_throughput_tokens_per_sec": 1436.0122817903994,
      "p90_itl_ms": 61.618857010034866,
      "p95_itl_ms": 110.84766660351308,
      "p99_itl_ms": 250.4983342648484,
      "avg_batch_size": 127.66887417218543
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.3544944581700393,
      "energy_per_request_joules": 507.5081740501037,
      "avg_power_watts": 3898.317361100596,
      "median_itl_ms": 63.40548800653778,
      "output_throughput_tokens_per_sec": 1623.1108503540545,
      "p90_itl_ms": 115.09766280651093,
      "p95_itl_ms": 151.11726260511202,
      "p99_itl_ms": 431.80344728636555,
      "avg_batch_size": 255.36458333333334
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.1466946288350555,
      "energy_per_request_joules": 435.27251516948945,
      "avg_power_watts": 3883.077089471107,
      "median_itl_ms": 98.1649300083518,
      "output_throughput_tokens_per_sec": 1758.9086044982503,
      "p90_itl_ms": 186.06416878756139,
      "p95_itl_ms": 248.80010780179873,
      "p99_itl_ms": 959.0856144862483,
      "avg_batch_size": 510.4655172413793
    },
    {
      "model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
      "nickname": "Llama 3.1 405B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 405.0,
      "activated_params_billions": 405.0,
      "architecture": "Dense Transformer",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 2.56131564811206,
      "energy_per_request_joules": 951.8614341537074,
      "avg_power_watts": 3674.4747424311345,
      "median_itl_ms": 38.19187398767099,
      "output_throughput_tokens_per_sec": 1297.5995289581717,
      "p90_itl_ms": 42.57957520894707,
      "p95_itl_ms": 58.78698981832713,
      "p99_itl_ms": 169.6888421662152,
      "avg_batch_size": 63.855421686746986
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4809737746517962,
      "energy_per_request_joules": 169.69262046743322,
      "avg_power_watts": 1913.0743598882357,
      "median_itl_ms": 27.29597048892174,
      "output_throughput_tokens_per_sec": 2958.5029928990334,
      "p90_itl_ms": 35.82712191273459,
      "p95_itl_ms": 50.09463485621353,
      "p99_itl_ms": 103.27662374067584,
      "avg_batch_size": 127.675
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.9026557561920612,
      "energy_per_request_joules": 684.3001762506891,
      "avg_power_watts": 1732.844097605657,
      "median_itl_ms": 16.777443001046777,
      "output_throughput_tokens_per_sec": 881.1394768689895,
      "p90_itl_ms": 17.612792609725147,
      "p95_itl_ms": 18.330938415601846,
      "p99_itl_ms": 31.258267909870483,
      "avg_batch_size": 15.944162436548224
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3614289315952847,
      "energy_per_request_joules": 130.52984687087246,
      "avg_power_watts": 1941.7341341746157,
      "median_itl_ms": 35.835087997838855,
      "output_throughput_tokens_per_sec": 2989.6454814808653,
      "p90_itl_ms": 59.97263340395875,
      "p95_itl_ms": 82.05338139669036,
      "p99_itl_ms": 179.9102551862598,
      "avg_batch_size": 255.28
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.0915058034713083,
      "energy_per_request_joules": 377.8432809428633,
      "avg_power_watts": 1735.0251401691617,
      "median_itl_ms": 18.678036984056234,
      "output_throughput_tokens_per_sec": 1413.1315381750326,
      "p90_itl_ms": 20.279276999644935,
      "p95_itl_ms": 23.937293502967805,
      "p99_itl_ms": 49.35216449666768,
      "avg_batch_size": 31.934579439252335
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6970762831423647,
      "energy_per_request_joules": 240.9596658118521,
      "avg_power_watts": 1810.8450919667694,
      "median_itl_ms": 21.745624995674007,
      "output_throughput_tokens_per_sec": 2030.4988175240749,
      "p90_itl_ms": 25.51190589438193,
      "p95_itl_ms": 34.09519464912589,
      "p99_itl_ms": 80.05626511498122,
      "avg_batch_size": 63.76984126984127
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 3.5692660029879617,
      "energy_per_request_joules": 1256.5454567843215,
      "avg_power_watts": 1698.02001433363,
      "median_itl_ms": 16.356827021809295,
      "output_throughput_tokens_per_sec": 470.6817648296622,
      "p90_itl_ms": 16.857134003657848,
      "p95_itl_ms": 17.089632994611748,
      "p99_itl_ms": 22.177567987819188,
      "avg_batch_size": 7.981258366800535
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.22667457638520802,
      "energy_per_request_joules": 79.50134838645519,
      "avg_power_watts": 1938.3873829344943,
      "median_itl_ms": 105.35636899294332,
      "output_throughput_tokens_per_sec": 4711.826656556805,
      "p90_itl_ms": 128.1254446017556,
      "p95_itl_ms": 153.76852200133723,
      "p99_itl_ms": 516.3436320715109,
      "avg_batch_size": 1021.4772727272727
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.18867446763991436,
      "energy_per_request_joules": 66.19452074640198,
      "avg_power_watts": 1907.0860701591266,
      "median_itl_ms": 140.47316349751782,
      "output_throughput_tokens_per_sec": 5423.828501521738,
      "p90_itl_ms": 211.69149940833452,
      "p95_itl_ms": 251.77556945272934,
      "p99_itl_ms": 558.5651662404416,
      "avg_batch_size": 2041.9333333333334
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.27078407281977845,
      "energy_per_request_joules": 95.22793592138136,
      "avg_power_watts": 1931.7732530547523,
      "median_itl_ms": 63.735153002198786,
      "output_throughput_tokens_per_sec": 4731.756572211737,
      "p90_itl_ms": 83.2075481011998,
      "p95_itl_ms": 103.6826805502642,
      "p99_itl_ms": 225.53748196834923,
      "avg_batch_size": 510.52
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "nickname": "Llama 3.1 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.22099830937688422,
      "energy_per_request_joules": 77.24768575278874,
      "avg_power_watts": 1918.7437543923984,
      "median_itl_ms": 134.78756349650212,
      "output_throughput_tokens_per_sec": 5266.9547434129,
      "p90_itl_ms": 184.36961160332433,
      "p95_itl_ms": 224.77936413924897,
      "p99_itl_ms": 536.4187428011792,
      "avg_batch_size": 1407.2539682539682
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2185859542835205,
      "energy_per_request_joules": 89.32705003728988,
      "avg_power_watts": 1935.3379848233947,
      "median_itl_ms": 105.5690009961836,
      "output_throughput_tokens_per_sec": 4954.729085862884,
      "p90_itl_ms": 123.76886698184535,
      "p95_itl_ms": 138.31367259263013,
      "p99_itl_ms": 514.3569973506965,
      "avg_batch_size": 1021.5576923076923
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.48108686802094386,
      "energy_per_request_joules": 197.12534417158176,
      "avg_power_watts": 1911.5402435916485,
      "median_itl_ms": 27.55990250443574,
      "output_throughput_tokens_per_sec": 2619.690224009693,
      "p90_itl_ms": 33.62744760524947,
      "p95_itl_ms": 50.744753259641584,
      "p99_itl_ms": 107.72431701538142,
      "avg_batch_size": 127.72527472527473
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.9214979320441667,
      "energy_per_request_joules": 779.4169809995365,
      "avg_power_watts": 1745.5327379190146,
      "median_itl_ms": 16.940318018896505,
      "output_throughput_tokens_per_sec": 888.269249394289,
      "p90_itl_ms": 17.743828997481614,
      "p95_itl_ms": 18.33818800514564,
      "p99_itl_ms": 28.917519008973606,
      "avg_batch_size": 15.964285714285714
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.35214391557233893,
      "energy_per_request_joules": 144.4835481095945,
      "avg_power_watts": 1942.152033355922,
      "median_itl_ms": 36.69821401126683,
      "output_throughput_tokens_per_sec": 3256.7165069548123,
      "p90_itl_ms": 56.227579014375834,
      "p95_itl_ms": 78.17061689711406,
      "p99_itl_ms": 170.2859676859225,
      "avg_batch_size": 255.51724137931035
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.09837607324156,
      "energy_per_request_joules": 446.7558867279323,
      "avg_power_watts": 1757.6593043836017,
      "median_itl_ms": 18.645607007783838,
      "output_throughput_tokens_per_sec": 1519.758607548423,
      "p90_itl_ms": 20.242558198515326,
      "p95_itl_ms": 23.322992264002092,
      "p99_itl_ms": 46.5622446453199,
      "avg_batch_size": 31.916334661354583
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2726696708352643,
      "energy_per_request_joules": 112.8012327090528,
      "avg_power_watts": 1930.1302457264087,
      "median_itl_ms": 63.53210502129514,
      "output_throughput_tokens_per_sec": 4613.0055722234965,
      "p90_itl_ms": 83.94049727648962,
      "p95_itl_ms": 104.08187189023009,
      "p99_itl_ms": 183.94360792590302,
      "avg_batch_size": 510.625
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6835897220173396,
      "energy_per_request_joules": 283.8446104335905,
      "avg_power_watts": 1815.1244370249738,
      "median_itl_ms": 21.814916501170956,
      "output_throughput_tokens_per_sec": 2382.751795799994,
      "p90_itl_ms": 24.840720393694934,
      "p95_itl_ms": 31.674871589348182,
      "p99_itl_ms": 69.46604490774922,
      "avg_batch_size": 63.847682119205295
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "nickname": "Llama 3.3 70B Instruct",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 70.0,
      "activated_params_billions": 70.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 3.61682729251943,
      "energy_per_request_joules": 1487.2153646902502,
      "avg_power_watts": 1701.4827217894435,
      "median_itl_ms": 16.615877000731416,
      "output_throughput_tokens_per_sec": 464.0140587769295,
      "p90_itl_ms": 17.130404198542237,
      "p95_itl_ms": 17.365419460111298,
      "p99_itl_ms": 21.898801030183677,
      "avg_batch_size": 7.984090909090909
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2423460942028801,
      "energy_per_request_joules": 99.11245254574936,
      "avg_power_watts": 666.6801912464827,
      "median_itl_ms": 5.083433003164828,
      "output_throughput_tokens_per_sec": 2704.9137616631474,
      "p90_itl_ms": 8.795807996648364,
      "p95_itl_ms": 12.222974241012707,
      "p99_itl_ms": 18.040224708965983,
      "avg_batch_size": 15.899328859060402
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1510692760199108,
      "energy_per_request_joules": 60.090312522947194,
      "avg_power_watts": 575.5530724733363,
      "median_itl_ms": 6.345150992274284,
      "output_throughput_tokens_per_sec": 3672.4885673748113,
      "p90_itl_ms": 14.910607208730656,
      "p95_itl_ms": 18.325782212195918,
      "p99_itl_ms": 25.094780172803443,
      "avg_batch_size": 31.766990291262136
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11030269049306295,
      "energy_per_request_joules": 42.986272638295084,
      "avg_power_watts": 616.5121449284105,
      "median_itl_ms": 8.997416487545706,
      "output_throughput_tokens_per_sec": 4972.859797229301,
      "p90_itl_ms": 20.032751504913904,
      "p95_itl_ms": 24.230182738392614,
      "p99_itl_ms": 34.18971085484391,
      "avg_batch_size": 63.803030303030305
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3905238905034637,
      "energy_per_request_joules": 151.50076862712154,
      "avg_power_watts": 639.3908265351646,
      "median_itl_ms": 4.574391001369804,
      "output_throughput_tokens_per_sec": 1608.6955275830092,
      "p90_itl_ms": 6.00760200759396,
      "p95_itl_ms": 7.697059109341346,
      "p99_itl_ms": 14.804588232655046,
      "avg_batch_size": 7.957983193277311
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.054922598342342914,
      "energy_per_request_joules": 21.726446649141838,
      "avg_power_watts": 599.8901004576812,
      "median_itl_ms": 87.12003598338924,
      "output_throughput_tokens_per_sec": 8356.63801158676,
      "p90_itl_ms": 113.56322859646755,
      "p95_itl_ms": 121.82107815460766,
      "p99_itl_ms": 153.47145174542663,
      "avg_batch_size": 1021.3333333333334
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.09831669252055335,
      "energy_per_request_joules": 38.89831770775215,
      "avg_power_watts": 449.32570995413784,
      "median_itl_ms": 26.657679496565834,
      "output_throughput_tokens_per_sec": 4168.992107482729,
      "p90_itl_ms": 42.8361739992397,
      "p95_itl_ms": 48.31662949582096,
      "p99_itl_ms": 58.44129902019631,
      "avg_batch_size": 127.54268292682927
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.04669576735104617,
      "energy_per_request_joules": 18.472040700505755,
      "avg_power_watts": 691.0648132414816,
      "median_itl_ms": 124.85829350771382,
      "output_throughput_tokens_per_sec": 10820.590130145112,
      "p90_itl_ms": 175.23864297836553,
      "p95_itl_ms": 190.32727355806853,
      "p99_itl_ms": 287.23442446033016,
      "avg_batch_size": 2042.921052631579
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.07048406596246932,
      "energy_per_request_joules": 28.15810902362383,
      "avg_power_watts": 540.1979487399086,
      "median_itl_ms": 31.692558506620117,
      "output_throughput_tokens_per_sec": 5734.687394207415,
      "p90_itl_ms": 48.46516041143332,
      "p95_itl_ms": 54.20180945366155,
      "p99_itl_ms": 65.51385449856748,
      "avg_batch_size": 255.23076923076923
    },
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "nickname": "Llama 3.1 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.0602349719839345,
      "energy_per_request_joules": 23.86120572476089,
      "avg_power_watts": 576.5352555778485,
      "median_itl_ms": 50.231036002514884,
      "output_throughput_tokens_per_sec": 6989.85014477585,
      "p90_itl_ms": 71.37475250056013,
      "p95_itl_ms": 77.39006950578187,
      "p99_itl_ms": 93.56033818767166,
      "avg_batch_size": 510.5533980582524
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3942254950635437,
      "energy_per_request_joules": 282.85409780724746,
      "avg_power_watts": 680.5389114542013,
      "median_itl_ms": 8.316921012010425,
      "output_throughput_tokens_per_sec": 1690.1495690916706,
      "p90_itl_ms": 12.58522779098712,
      "p95_itl_ms": 16.907912207534537,
      "p99_itl_ms": 28.344203702872615,
      "avg_batch_size": 15.939613526570048
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6692826510827456,
      "energy_per_request_joules": 484.71031294552694,
      "avg_power_watts": 667.9603321280928,
      "median_itl_ms": 7.7277939999476075,
      "output_throughput_tokens_per_sec": 987.4183002143276,
      "p90_itl_ms": 10.196260001976043,
      "p95_itl_ms": 11.869198002386838,
      "p99_itl_ms": 18.957180011784473,
      "avg_batch_size": 7.962962962962963
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.13449311187825258,
      "energy_per_request_joules": 98.03654737603547,
      "avg_power_watts": 834.2599107877865,
      "median_itl_ms": 18.888652994064614,
      "output_throughput_tokens_per_sec": 5496.362350759415,
      "p90_itl_ms": 27.22457039926667,
      "p95_itl_ms": 32.53021871350938,
      "p99_itl_ms": 41.70991236518602,
      "avg_batch_size": 127.6826923076923
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.11320791771901445,
      "energy_per_request_joules": 81.97458288074554,
      "avg_power_watts": 943.4010862886412,
      "median_itl_ms": 28.038521006237715,
      "output_throughput_tokens_per_sec": 6033.282384922661,
      "p90_itl_ms": 40.02958402270451,
      "p95_itl_ms": 44.482655997853726,
      "p99_itl_ms": 54.81611241120845,
      "avg_batch_size": 255.62686567164178
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24654680940444612,
      "energy_per_request_joules": 178.84274416564705,
      "avg_power_watts": 624.9568836091115,
      "median_itl_ms": 11.29119799588807,
      "output_throughput_tokens_per_sec": 2388.1546296981883,
      "p90_itl_ms": 18.826704210368927,
      "p95_itl_ms": 24.09385959617794,
      "p99_itl_ms": 34.22033947543244,
      "avg_batch_size": 31.928571428571427
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.0953556387181873,
      "energy_per_request_joules": 68.98002693481025,
      "avg_power_watts": 928.0759099365115,
      "median_itl_ms": 43.514438992133364,
      "output_throughput_tokens_per_sec": 6488.1515798127775,
      "p90_itl_ms": 60.27450519613921,
      "p95_itl_ms": 66.80109159497079,
      "p99_itl_ms": 105.54652150487546,
      "avg_batch_size": 486.64102564102564
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.17167582966884148,
      "energy_per_request_joules": 123.95665510799999,
      "avg_power_watts": 751.0496334359677,
      "median_itl_ms": 12.957806000486016,
      "output_throughput_tokens_per_sec": 4007.678985386528,
      "p90_itl_ms": 21.188866085140045,
      "p95_itl_ms": 26.04149694670923,
      "p99_itl_ms": 36.92552951222747,
      "avg_batch_size": 63.855345911949684
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.7109459813163599,
      "energy_per_request_joules": 512.7246606174074,
      "avg_power_watts": 799.9626972468399,
      "median_itl_ms": 13.531176999094896,
      "output_throughput_tokens_per_sec": 1101.4578302118568,
      "p90_itl_ms": 18.042510224040598,
      "p95_itl_ms": 21.11968814861028,
      "p99_itl_ms": 35.80351640412114,
      "avg_batch_size": 15.939157566302653
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.4662487300306307,
      "energy_per_request_joules": 334.4961274728931,
      "avg_power_watts": 859.7463831809043,
      "median_itl_ms": 15.783169510541484,
      "output_throughput_tokens_per_sec": 1773.1750991429765,
      "p90_itl_ms": 23.05839310283773,
      "p95_itl_ms": 28.190243343124163,
      "p99_itl_ms": 44.58779252308886,
      "avg_batch_size": 31.92207792207792
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2937081711042084,
      "energy_per_request_joules": 209.05826375885408,
      "avg_power_watts": 899.3569074838913,
      "median_itl_ms": 19.319453509524465,
      "output_throughput_tokens_per_sec": 2727.1470444631955,
      "p90_itl_ms": 28.405169697362,
      "p95_itl_ms": 35.142206303135026,
      "p99_itl_ms": 47.441880211117734,
      "avg_batch_size": 63.83783783783784
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 1.3541189465741552,
      "energy_per_request_joules": 972.0061511013283,
      "avg_power_watts": 804.576084108009,
      "median_itl_ms": 13.200574001530185,
      "output_throughput_tokens_per_sec": 588.6790884259476,
      "p90_itl_ms": 15.534032200230286,
      "p95_itl_ms": 17.338150605792176,
      "p99_itl_ms": 25.748170475708182,
      "avg_batch_size": 7.974527526705012
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2157048892701669,
      "energy_per_request_joules": 153.91765615400791,
      "avg_power_watts": 957.4702142580207,
      "median_itl_ms": 26.413496991153806,
      "output_throughput_tokens_per_sec": 3719.0347497292682,
      "p90_itl_ms": 35.59680680336897,
      "p95_itl_ms": 40.885346494906116,
      "p99_itl_ms": 60.39131319092144,
      "avg_batch_size": 127.81944444444444
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.17674549907133558,
      "energy_per_request_joules": 126.64505420566941,
      "avg_power_watts": 973.9345699315605,
      "median_itl_ms": 39.601704498636536,
      "output_throughput_tokens_per_sec": 4196.034943904649,
      "p90_itl_ms": 54.347466814215295,
      "p95_itl_ms": 63.79778845002875,
      "p99_itl_ms": 111.33141885075047,
      "avg_batch_size": 247.31
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1576766960092536,
      "energy_per_request_joules": 221.7610323131786,
      "avg_power_watts": 719.0804003733156,
      "median_itl_ms": 23.154423019150272,
      "output_throughput_tokens_per_sec": 3622.185160374584,
      "p90_itl_ms": 40.37621141760609,
      "p95_itl_ms": 66.97639439080375,
      "p99_itl_ms": 88.08277491712941,
      "avg_batch_size": 127.74460431654676
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.420760577941986,
      "energy_per_request_joules": 559.8601625589888,
      "avg_power_watts": 510.2741532840746,
      "median_itl_ms": 10.752652015071362,
      "output_throughput_tokens_per_sec": 1160.4594034919587,
      "p90_itl_ms": 22.949242484173737,
      "p95_itl_ms": 27.950524745392613,
      "p99_itl_ms": 50.69378914340633,
      "avg_batch_size": 15.939309056956116
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.14196225091495468,
      "energy_per_request_joules": 207.8776530829472,
      "avg_power_watts": 884.8116469596908,
      "median_itl_ms": 33.855443994980305,
      "output_throughput_tokens_per_sec": 4793.052914190367,
      "p90_itl_ms": 68.01143300253898,
      "p95_itl_ms": 84.35218151134904,
      "p99_itl_ms": 107.42822773754584,
      "avg_batch_size": 255.61928934010152
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.3021101274247577,
      "energy_per_request_joules": 423.5923270329613,
      "avg_power_watts": 518.6896311880196,
      "median_itl_ms": 15.963502984959632,
      "output_throughput_tokens_per_sec": 1614.5012704585167,
      "p90_itl_ms": 31.53710138867609,
      "p95_itl_ms": 37.65478119021279,
      "p99_itl_ms": 56.877935969969116,
      "avg_batch_size": 31.92829705505762
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.2047758552589889,
      "energy_per_request_joules": 278.49116362380187,
      "avg_power_watts": 565.9963988572973,
      "median_itl_ms": 20.077912515262142,
      "output_throughput_tokens_per_sec": 2391.8047044463233,
      "p90_itl_ms": 35.47910900088027,
      "p95_itl_ms": 45.731572841759764,
      "p99_itl_ms": 78.18046510219585,
      "avg_batch_size": 63.8372591006424
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.6566271907937724,
      "energy_per_request_joules": 878.8845938401172,
      "avg_power_watts": 677.5667436886174,
      "median_itl_ms": 7.196357488282956,
      "output_throughput_tokens_per_sec": 1002.2707910271274,
      "p90_itl_ms": 10.500433313427497,
      "p95_itl_ms": 12.215735411155038,
      "p99_itl_ms": 16.57573381176917,
      "avg_batch_size": 7.955950540958269
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.15891455264736762,
      "energy_per_request_joules": 177.17358644256166,
      "avg_power_watts": 641.7001737751592,
      "median_itl_ms": 24.563489510910586,
      "output_throughput_tokens_per_sec": 3370.5556641638996,
      "p90_itl_ms": 52.835576294455684,
      "p95_itl_ms": 65.90449873765465,
      "p99_itl_ms": 85.10220431315243,
      "avg_batch_size": 127.75113122171946
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.32834782205610513,
      "energy_per_request_joules": 345.1031805460658,
      "avg_power_watts": 592.2426120376942,
      "median_itl_ms": 7.11653899634257,
      "output_throughput_tokens_per_sec": 1679.4810466744498,
      "p90_itl_ms": 14.086036605294794,
      "p95_itl_ms": 17.208993987878785,
      "p99_itl_ms": 45.85801072535106,
      "avg_batch_size": 15.919786096256685
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.1473680567378021,
      "energy_per_request_joules": 183.01198589066843,
      "avg_power_watts": 799.5262572910163,
      "median_itl_ms": 40.74862599372864,
      "output_throughput_tokens_per_sec": 4305.511571048413,
      "p90_itl_ms": 70.74995161383413,
      "p95_itl_ms": 81.06225341325613,
      "p99_itl_ms": 102.12520816014153,
      "avg_batch_size": 255.30769230769232
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.24193421780454263,
      "energy_per_request_joules": 246.55884708120877,
      "avg_power_watts": 546.609468787951,
      "median_itl_ms": 10.740508500020951,
      "output_throughput_tokens_per_sec": 1962.4816681393447,
      "p90_itl_ms": 27.64044899959117,
      "p95_itl_ms": 37.33884826215217,
      "p99_itl_ms": 58.475531692965916,
      "avg_batch_size": 31.854721549636803
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.19135159820758374,
      "energy_per_request_joules": 209.51729309523571,
      "avg_power_watts": 575.9831359663104,
      "median_itl_ms": 16.043806506786495,
      "output_throughput_tokens_per_sec": 2779.2629428731766,
      "p90_itl_ms": 33.93647558987141,
      "p95_itl_ms": 47.784045957087066,
      "p99_itl_ms": 68.23242199607193,
      "avg_batch_size": 63.807817589576544
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 0,
      "data_parallel": 0,
      "energy_per_token_joules": 0.516187661323585,
      "energy_per_request_joules": 556.9241430490553,
      "avg_power_watts": 636.7976028882379,
      "median_itl_ms": 5.901763011934236,
      "output_throughput_tokens_per_sec": 1193.1672135217198,
      "p90_itl_ms": 8.14572680974379,
      "p95_itl_ms": 9.750498400535442,
      "p99_itl_ms": 14.144910586765016,
      "avg_batch_size": 7.947916666666667
    }
  ]
}