{
  "task": "image-chat",
  "task_display_name": "Image Chat",
  "configurations": [
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6017722591837747,
      "energy_per_request_joules": 565.9579947390123,
      "avg_output_len": 940.4853515625,
      "avg_power_watts": 535.6640895500041,
      "median_itl_ms": 16.982789005851373,
      "output_throughput_tokens_per_sec": 890.1442055115041,
      "p90_itl_ms": 17.97059419332072,
      "p95_itl_ms": 21.874672209378325,
      "p99_itl_ms": 67.06122953910382,
      "avg_batch_size": 15.919024390243903
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.42064587167040457,
      "energy_per_request_joules": 388.917917383093,
      "avg_output_len": 924.5732421875,
      "avg_power_watts": 557.042007086968,
      "median_itl_ms": 22.154652993776836,
      "output_throughput_tokens_per_sec": 1324.2540688083495,
      "p90_itl_ms": 24.94026039561885,
      "p95_itl_ms": 36.56293428796955,
      "p99_itl_ms": 77.63206866016847,
      "avg_batch_size": 31.80327868852459
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.784283060915658,
      "energy_per_request_joules": 728.4748875595249,
      "avg_output_len": 928.841796875,
      "avg_power_watts": 496.8889249776025,
      "median_itl_ms": 12.165323016233742,
      "output_throughput_tokens_per_sec": 633.5581497801061,
      "p90_itl_ms": 12.6995415892452,
      "p95_itl_ms": 12.889946793438867,
      "p99_itl_ms": 23.38465000812888,
      "avg_batch_size": 7.950344827586207
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.22514513410178152,
      "energy_per_request_joules": 210.72177394838616,
      "avg_output_len": 935.9375,
      "avg_power_watts": 942.0298202874875,
      "median_itl_ms": 25.571873513399623,
      "output_throughput_tokens_per_sec": 4184.10028733565,
      "p90_itl_ms": 40.2215727126368,
      "p95_itl_ms": 71.02481509937206,
      "p99_itl_ms": 79.71882487065159,
      "avg_batch_size": 127.87027027027027
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6806696661806808,
      "energy_per_request_joules": 631.119041575434,
      "avg_output_len": 927.203125,
      "avg_power_watts": 856.7782632272523,
      "median_itl_ms": 11.906124505912885,
      "output_throughput_tokens_per_sec": 1258.7284343589715,
      "p90_itl_ms": 12.324141507269815,
      "p95_itl_ms": 13.436813361075675,
      "p99_itl_ms": 60.25252692314099,
      "avg_batch_size": 15.980662983425415
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.18436774901284408,
      "energy_per_request_joules": 174.01092672137355,
      "avg_output_len": 943.8251953125,
      "avg_power_watts": 941.8578329871856,
      "median_itl_ms": 29.689154005609453,
      "output_throughput_tokens_per_sec": 5108.5823742501225,
      "p90_itl_ms": 52.02631429419853,
      "p95_itl_ms": 78.70412280171877,
      "p99_itl_ms": 93.39407151710475,
      "avg_batch_size": 191.4469696969697
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.15847922428759087,
      "energy_per_request_joules": 146.419945814457,
      "avg_output_len": 923.90625,
      "avg_power_watts": 938.2410130936585,
      "median_itl_ms": 30.229980279036994,
      "output_throughput_tokens_per_sec": 5920.277672428789,
      "p90_itl_ms": 55.177570412596985,
      "p95_itl_ms": 83.20593490789179,
      "p99_itl_ms": 104.39358878007629,
      "avg_batch_size": 251.15151515151516
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.46918750411040666,
      "energy_per_request_joules": 435.88343875516347,
      "avg_output_len": 929.017578125,
      "avg_power_watts": 919.8470688399545,
      "median_itl_ms": 14.74564999807626,
      "output_throughput_tokens_per_sec": 1960.5105864530892,
      "p90_itl_ms": 17.160637637858304,
      "p95_itl_ms": 20.590041025234544,
      "p99_itl_ms": 63.943592994473875,
      "avg_batch_size": 31.96949891067538
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1382149158544565,
      "energy_per_request_joules": 127.02004757226058,
      "avg_output_len": 919.00390625,
      "avg_power_watts": 1005.8746427702692,
      "median_itl_ms": 27.160923506016843,
      "output_throughput_tokens_per_sec": 7277.612814448178,
      "p90_itl_ms": 38.91398001287599,
      "p95_itl_ms": 46.31462465040386,
      "p99_itl_ms": 156.53573861900009,
      "avg_batch_size": 348.625
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.31017292317510253,
      "energy_per_request_joules": 284.5566986243259,
      "avg_output_len": 917.4130859375,
      "avg_power_watts": 953.1508575409222,
      "median_itl_ms": 17.97010649170261,
      "output_throughput_tokens_per_sec": 3072.966033862466,
      "p90_itl_ms": 23.25233998708427,
      "p95_itl_ms": 61.30895564128877,
      "p99_itl_ms": 69.2810194814228,
      "avg_batch_size": 63.083636363636366
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.9377829930646485,
      "energy_per_request_joules": 853.3120068036095,
      "avg_output_len": 909.9248046875,
      "avg_power_watts": 750.5171559319674,
      "median_itl_ms": 9.55027699819766,
      "output_throughput_tokens_per_sec": 800.3100519868658,
      "p90_itl_ms": 9.884005994535983,
      "p95_itl_ms": 10.280133999185631,
      "p99_itl_ms": 20.611840424213828,
      "avg_batch_size": 7.991228070175438
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2693919770255376,
      "energy_per_request_joules": 244.70814789626502,
      "avg_output_len": 908.3720703125,
      "avg_power_watts": 955.1316474339901,
      "median_itl_ms": 22.778183993068524,
      "output_throughput_tokens_per_sec": 3545.5088825583193,
      "p90_itl_ms": 30.494484554657987,
      "p95_itl_ms": 66.43483100197045,
      "p99_itl_ms": 73.48209620686248,
      "avg_batch_size": 95.70403587443946
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 5.361291941472724,
      "energy_per_request_joules": 4998.881171757156,
      "avg_output_len": 932.40234375,
      "avg_power_watts": 2212.203636670805,
      "median_itl_ms": 37.1500002220273,
      "output_throughput_tokens_per_sec": 412.6251024604943,
      "p90_itl_ms": 38.16250171512365,
      "p95_itl_ms": 38.738379348069415,
      "p99_itl_ms": 131.69068951159713,
      "avg_batch_size": 15.985333333333333
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 3.0783652690352787,
      "energy_per_request_joules": 2797.638798768626,
      "avg_output_len": 908.806640625,
      "avg_power_watts": 2202.60783164473,
      "median_itl_ms": 41.73819161951542,
      "output_throughput_tokens_per_sec": 715.5121758292835,
      "p90_itl_ms": 43.30527223646641,
      "p95_itl_ms": 47.579519264400005,
      "p99_itl_ms": 135.2543289586902,
      "avg_batch_size": 31.973983739837397
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 10.081913788887013,
      "energy_per_request_joules": 9305.862413235009,
      "avg_output_len": 923.025390625,
      "avg_power_watts": 2363.214069839988,
      "median_itl_ms": 33.2266440091189,
      "output_throughput_tokens_per_sec": 234.40133682207116,
      "p90_itl_ms": 34.26524801761843,
      "p95_itl_ms": 34.40390300238505,
      "p99_itl_ms": 39.68359341379253,
      "avg_batch_size": 7.9929257200606365
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.9329863119168873,
      "energy_per_request_joules": 1749.4979637945657,
      "avg_output_len": 905.0751953125,
      "avg_power_watts": 2226.399452511597,
      "median_itl_ms": 47.49224241822958,
      "output_throughput_tokens_per_sec": 1151.7926633964316,
      "p90_itl_ms": 52.70032750872465,
      "p95_itl_ms": 96.83710243552923,
      "p99_itl_ms": 145.87322231382132,
      "avg_batch_size": 60.85402455661664
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.516540744911418,
      "energy_per_request_joules": 1395.7358342059256,
      "avg_output_len": 920.341796875,
      "avg_power_watts": 3480.2284564350794,
      "median_itl_ms": 42.62426681816578,
      "output_throughput_tokens_per_sec": 2294.84665553009,
      "p90_itl_ms": 72.11171160452068,
      "p95_itl_ms": 152.61421473696828,
      "p99_itl_ms": 158.6471839807928,
      "avg_batch_size": 127.84571428571428
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 6.978268126402804,
      "energy_per_request_joules": 6404.891638493352,
      "avg_output_len": 917.833984375,
      "avg_power_watts": 3964.0284004536393,
      "median_itl_ms": 25.919047999195755,
      "output_throughput_tokens_per_sec": 568.0533233533173,
      "p90_itl_ms": 26.280071184737608,
      "p95_itl_ms": 27.4373285849263,
      "p99_itl_ms": 142.30308621306904,
      "avg_batch_size": 15.985552763819095
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.2289192537576366,
      "energy_per_request_joules": 1130.6957221914317,
      "avg_output_len": 920.0732421875,
      "avg_power_watts": 3545.390231394801,
      "median_itl_ms": 50.02221651375294,
      "output_throughput_tokens_per_sec": 2884.965973601722,
      "p90_itl_ms": 146.31957560777664,
      "p95_itl_ms": 158.24205242097378,
      "p99_itl_ms": 166.92388020455837,
      "avg_batch_size": 191.81274900398407
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.0900983277168166,
      "energy_per_request_joules": 1001.9887883709789,
      "avg_output_len": 919.1728515625,
      "avg_power_watts": 3609.760585676512,
      "median_itl_ms": 55.1033690571785,
      "output_throughput_tokens_per_sec": 3311.408240793346,
      "p90_itl_ms": 157.21938852220774,
      "p95_itl_ms": 163.49651301279664,
      "p99_itl_ms": 177.74222860112783,
      "avg_batch_size": 255.25130890052355
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 4.08783840222643,
      "energy_per_request_joules": 3844.8914593722343,
      "avg_output_len": 940.568359375,
      "avg_power_watts": 3986.043493665406,
      "median_itl_ms": 28.96841049368959,
      "output_throughput_tokens_per_sec": 975.0981084512584,
      "p90_itl_ms": 30.5063020932721,
      "p95_itl_ms": 34.317532788038314,
      "p99_itl_ms": 143.4579001032398,
      "avg_batch_size": 31.964630225080384
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8567941242776116,
      "energy_per_request_joules": 803.232777528093,
      "avg_output_len": 937.486328125,
      "avg_power_watts": 3644.439014177174,
      "median_itl_ms": 58.677997440099716,
      "output_throughput_tokens_per_sec": 4253.576105286563,
      "p90_itl_ms": 160.82807388156652,
      "p95_itl_ms": 168.71721325442192,
      "p99_itl_ms": 224.98375266790381,
      "avg_batch_size": 383.4695652173913
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.48196908646473957,
      "energy_per_request_joules": 436.73082789396614,
      "avg_output_len": 906.138671875,
      "avg_power_watts": 3648.13622468253,
      "median_itl_ms": 53.4059964120388,
      "output_throughput_tokens_per_sec": 7569.232814166027,
      "p90_itl_ms": 97.44621962308885,
      "p95_itl_ms": 179.00135554373264,
      "p99_itl_ms": 303.56877967715263,
      "avg_batch_size": 511.46153846153845
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.2990191353317746,
      "energy_per_request_joules": 2121.900366204505,
      "avg_output_len": 922.958984375,
      "avg_power_watts": 3439.0068586986677,
      "median_itl_ms": 35.368237644433975,
      "output_throughput_tokens_per_sec": 1495.8583014153032,
      "p90_itl_ms": 41.44383650273085,
      "p95_itl_ms": 143.72925283387303,
      "p99_itl_ms": 153.15585708245635,
      "avg_batch_size": 63.92566371681416
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 12.42517833780704,
      "energy_per_request_joules": 11378.806019485955,
      "avg_output_len": 915.7861328125,
      "avg_power_watts": 4037.5076656236174,
      "median_itl_ms": 23.588323005242273,
      "output_throughput_tokens_per_sec": 324.94565114919794,
      "p90_itl_ms": 23.83061550790444,
      "p95_itl_ms": 23.932546755531803,
      "p99_itl_ms": 29.932429257314652,
      "avg_batch_size": 7.994695898161245
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.7818674847661364,
      "energy_per_request_joules": 1619.9246161433234,
      "avg_output_len": 909.1162109375,
      "avg_power_watts": 3449.575065431318,
      "median_itl_ms": 39.21047691255808,
      "output_throughput_tokens_per_sec": 1935.932438816606,
      "p90_itl_ms": 55.315070756478235,
      "p95_itl_ms": 146.49962587282062,
      "p99_itl_ms": 154.7284028492868,
      "avg_batch_size": 95.91190476190476
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 5.136495244410268,
      "energy_per_request_joules": 4791.030826463218,
      "avg_output_len": 932.7431640625,
      "avg_power_watts": 2841.8114988827124,
      "median_itl_ms": 27.37360540777445,
      "output_throughput_tokens_per_sec": 553.2588591365447,
      "p90_itl_ms": 28.28204296529293,
      "p95_itl_ms": 29.233950867571615,
      "p99_itl_ms": 111.12419929355383,
      "avg_batch_size": 15.982727814175105
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.8395604792118903,
      "energy_per_request_joules": 3554.608098178505,
      "avg_output_len": 925.78515625,
      "avg_power_watts": 3049.2194705464035,
      "median_itl_ms": 37.81948797404766,
      "output_throughput_tokens_per_sec": 794.15846867251,
      "p90_itl_ms": 39.09982144832611,
      "p95_itl_ms": 42.64666661620134,
      "p99_itl_ms": 116.63883622735739,
      "avg_batch_size": 31.954664341761116
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.5697371745541453,
      "energy_per_request_joules": 2425.7139458580154,
      "avg_output_len": 943.9541015625,
      "avg_power_watts": 3551.0381833591005,
      "median_itl_ms": 41.118471999652684,
      "output_throughput_tokens_per_sec": 1381.8682387140284,
      "p90_itl_ms": 46.23301705271986,
      "p95_itl_ms": 112.81313904328272,
      "p99_itl_ms": 122.29739578906447,
      "avg_batch_size": 63.635239567233384
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 7.2639104637587995,
      "energy_per_request_joules": 6681.882544187563,
      "avg_output_len": 919.8740234375,
      "avg_power_watts": 2548.7774892329094,
      "median_itl_ms": 22.06612192094326,
      "output_throughput_tokens_per_sec": 350.882283303092,
      "p90_itl_ms": 22.59829081594944,
      "p95_itl_ms": 22.774748411029577,
      "p99_itl_ms": 28.695954624563605,
      "avg_batch_size": 7.992794842624194
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5931095748757166,
      "energy_per_request_joules": 610.9150255019416,
      "avg_output_len": 1030.0205078125,
      "avg_power_watts": 528.5805374201382,
      "median_itl_ms": 17.01978498022072,
      "output_throughput_tokens_per_sec": 891.2021653518235,
      "p90_itl_ms": 17.8959215991199,
      "p95_itl_ms": 21.205552190076556,
      "p99_itl_ms": 69.56671374267897,
      "avg_batch_size": 15.943810359964882
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4249593263428773,
      "energy_per_request_joules": 429.24087455565024,
      "avg_output_len": 1010.0751953125,
      "avg_power_watts": 554.0634400287397,
      "median_itl_ms": 22.422156005632132,
      "output_throughput_tokens_per_sec": 1303.803459961472,
      "p90_itl_ms": 24.960404195007868,
      "p95_itl_ms": 33.88416528144006,
      "p99_itl_ms": 77.41237484675368,
      "avg_batch_size": 31.180240320427238
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7762361693821952,
      "energy_per_request_joules": 794.423140257017,
      "avg_output_len": 1023.4296875,
      "avg_power_watts": 493.443690508069,
      "median_itl_ms": 12.202361511299387,
      "output_throughput_tokens_per_sec": 635.6875780483147,
      "p90_itl_ms": 12.721468618838117,
      "p95_itl_ms": 12.910716845362911,
      "p99_itl_ms": 23.32224783516722,
      "avg_batch_size": 7.949438202247191
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.22921330531329542,
      "energy_per_request_joules": 236.88926494786918,
      "avg_output_len": 1033.48828125,
      "avg_power_watts": 954.7537712059926,
      "median_itl_ms": 25.73422997375019,
      "output_throughput_tokens_per_sec": 4165.350566805044,
      "p90_itl_ms": 34.55316815489289,
      "p95_itl_ms": 74.25043360271957,
      "p99_itl_ms": 81.48782263509929,
      "avg_batch_size": 126.74038461538461
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6795184142946896,
      "energy_per_request_joules": 716.0896441093329,
      "avg_output_len": 1053.8193359375,
      "avg_power_watts": 847.5818315697452,
      "median_itl_ms": 12.059359505656175,
      "output_throughput_tokens_per_sec": 1247.3272449128522,
      "p90_itl_ms": 12.687903104233555,
      "p95_itl_ms": 13.643140281783415,
      "p99_itl_ms": 62.963619643996964,
      "avg_batch_size": 15.981971153846153
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.18133759249933099,
      "energy_per_request_joules": 190.20347782011126,
      "avg_output_len": 1048.8916015625,
      "avg_power_watts": 968.137466299607,
      "median_itl_ms": 30.332675509271212,
      "output_throughput_tokens_per_sec": 5338.867980742486,
      "p90_itl_ms": 43.54439775958286,
      "p95_itl_ms": 78.66989194153572,
      "p99_itl_ms": 89.32172891305527,
      "avg_batch_size": 191.8108108108108
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.16082023637814086,
      "energy_per_request_joules": 165.1553154648067,
      "avg_output_len": 1026.9560546875,
      "avg_power_watts": 953.9526876036877,
      "median_itl_ms": 32.45010749378707,
      "output_throughput_tokens_per_sec": 5931.795084299177,
      "p90_itl_ms": 52.2726398207937,
      "p95_itl_ms": 92.23962204850974,
      "p99_itl_ms": 105.85501487454167,
      "avg_batch_size": 250.8272727272727
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.46287857476983923,
      "energy_per_request_joules": 473.6020790952932,
      "avg_output_len": 1023.1669921875,
      "avg_power_watts": 910.647309380498,
      "median_itl_ms": 14.853871500235982,
      "output_throughput_tokens_per_sec": 1967.3567951018392,
      "p90_itl_ms": 16.679277413641106,
      "p95_itl_ms": 19.81806075636995,
      "p99_itl_ms": 66.31800942093832,
      "avg_batch_size": 31.96831683168317
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.31158770252829454,
      "energy_per_request_joules": 320.7208127737894,
      "avg_output_len": 1029.3115234375,
      "avg_power_watts": 953.4698491526892,
      "median_itl_ms": 18.132087498088367,
      "output_throughput_tokens_per_sec": 3060.03684168539,
      "p90_itl_ms": 22.195347002707422,
      "p95_itl_ms": 50.58648350677686,
      "p99_itl_ms": 71.15790840907721,
      "avg_batch_size": 63.942122186495176
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.9299364040680338,
      "energy_per_request_joules": 954.777693518109,
      "avg_output_len": 1026.712890625,
      "avg_power_watts": 751.6269906557037,
      "median_itl_ms": 9.496004990069196,
      "output_throughput_tokens_per_sec": 808.2563359899555,
      "p90_itl_ms": 9.86870220513083,
      "p95_itl_ms": 10.155389491873475,
      "p99_itl_ms": 16.1177105363854,
      "avg_batch_size": 7.9866457187745485
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.27035972366065375,
      "energy_per_request_joules": 279.332815035977,
      "avg_output_len": 1033.189453125,
      "avg_power_watts": 952.5221191553584,
      "median_itl_ms": 23.293303995160386,
      "output_throughput_tokens_per_sec": 3523.1657521256066,
      "p90_itl_ms": 30.295032154054542,
      "p95_itl_ms": 69.32039871171581,
      "p99_itl_ms": 76.05685902526602,
      "avg_batch_size": 95.91538461538461
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.35143196951424455,
      "energy_per_request_joules": 331.08254842012576,
      "avg_output_len": 942.095703125,
      "avg_power_watts": 1278.0334700918388,
      "median_itl_ms": 30.139634996885434,
      "output_throughput_tokens_per_sec": 3636.6454419566867,
      "p90_itl_ms": 41.82081742291279,
      "p95_itl_ms": 79.97744850290472,
      "p99_itl_ms": 109.76323896087708,
      "avg_batch_size": 127.84234234234235
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.0819765109485588,
      "energy_per_request_joules": 1016.5327813014682,
      "avg_output_len": 939.5146484375,
      "avg_power_watts": 1020.0699515367832,
      "median_itl_ms": 16.266300997813232,
      "output_throughput_tokens_per_sec": 942.7838231372484,
      "p90_itl_ms": 16.717714595142752,
      "p95_itl_ms": 17.841420869404423,
      "p99_itl_ms": 57.83402329339878,
      "avg_batch_size": 15.976791120080726
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6784437177975452,
      "energy_per_request_joules": 640.3077603791597,
      "avg_output_len": 943.7890625,
      "avg_power_watts": 1092.1921292745512,
      "median_itl_ms": 18.336353488848545,
      "output_throughput_tokens_per_sec": 1609.8492780214276,
      "p90_itl_ms": 19.3590039450167,
      "p95_itl_ms": 22.854162511066534,
      "p99_itl_ms": 72.44962169643297,
      "avg_batch_size": 31.947552447552447
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.45773588679929567,
      "energy_per_request_joules": 435.5473184897806,
      "avg_output_len": 951.525390625,
      "avg_power_watts": 1143.4033351777207,
      "median_itl_ms": 22.629524508374743,
      "output_throughput_tokens_per_sec": 2497.9543185327543,
      "p90_itl_ms": 26.823773775497216,
      "p95_itl_ms": 53.14142275456105,
      "p99_itl_ms": 86.62330896768253,
      "avg_batch_size": 63.89801699716714
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.9253417656758551,
      "energy_per_request_joules": 1796.4153156051584,
      "avg_output_len": 933.037109375,
      "avg_power_watts": 965.1258969493875,
      "median_itl_ms": 15.593631993397139,
      "output_throughput_tokens_per_sec": 501.275105622922,
      "p90_itl_ms": 15.92206548084505,
      "p95_itl_ms": 16.024292194924783,
      "p99_itl_ms": 22.027823201206026,
      "avg_batch_size": 7.994136460554371
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.38127864727873784,
      "energy_per_request_joules": 364.112916617757,
      "avg_output_len": 954.978515625,
      "avg_power_watts": 1211.015829743394,
      "median_itl_ms": 26.47213899763301,
      "output_throughput_tokens_per_sec": 3176.1963025903938,
      "p90_itl_ms": 33.18210100987926,
      "p95_itl_ms": 67.46957179275327,
      "p99_itl_ms": 97.21258907578887,
      "avg_batch_size": 95.9090909090909
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.13340515060256208,
      "energy_per_request_joules": 124.49749067355859,
      "avg_output_len": 933.228515625,
      "avg_power_watts": 560.81400254595,
      "median_itl_ms": 21.71056199586019,
      "output_throughput_tokens_per_sec": 4203.84070639608,
      "p90_itl_ms": 52.51905661425554,
      "p95_itl_ms": 55.17786220298149,
      "p99_itl_ms": 101.22411114745772,
      "avg_batch_size": 127.6413043478261
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3062606777199601,
      "energy_per_request_joules": 287.30033039177954,
      "avg_output_len": 938.0908203125,
      "avg_power_watts": 475.9879633670381,
      "median_itl_ms": 9.239587001502514,
      "output_throughput_tokens_per_sec": 1554.1922224905215,
      "p90_itl_ms": 10.145119787193835,
      "p95_itl_ms": 17.247005394892764,
      "p99_itl_ms": 43.28132888651453,
      "avg_batch_size": 15.917369308600337
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.12152898105443803,
      "energy_per_request_joules": 114.76169196390569,
      "avg_output_len": 944.3154296875,
      "avg_power_watts": 583.1445583344137,
      "median_itl_ms": 29.186497995397076,
      "output_throughput_tokens_per_sec": 4798.399141297813,
      "p90_itl_ms": 61.47042198572309,
      "p95_itl_ms": 66.71863080700858,
      "p99_itl_ms": 125.92199766426343,
      "avg_batch_size": 189.43421052631578
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.11916010082811408,
      "energy_per_request_joules": 110.7325492439601,
      "avg_output_len": 929.275390625,
      "avg_power_watts": 587.9845169177557,
      "median_itl_ms": 30.14742850791663,
      "output_throughput_tokens_per_sec": 4934.407682030338,
      "p90_itl_ms": 72.95880045248418,
      "p95_itl_ms": 83.45739044325686,
      "p99_itl_ms": 153.33483365975547,
      "avg_batch_size": 224.390625
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2132336220240711,
      "energy_per_request_joules": 204.14995302022928,
      "avg_output_len": 957.400390625,
      "avg_power_watts": 498.38077919908017,
      "median_itl_ms": 11.076862996560521,
      "output_throughput_tokens_per_sec": 2337.2523266655385,
      "p90_itl_ms": 19.816928388900124,
      "p95_itl_ms": 32.465869358677054,
      "p99_itl_ms": 47.65862087486314,
      "avg_batch_size": 31.824120603015075
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1597199026842124,
      "energy_per_request_joules": 151.71004315047963,
      "avg_output_len": 949.8505859375,
      "avg_power_watts": 528.2965755694432,
      "median_itl_ms": 14.901366492267698,
      "output_throughput_tokens_per_sec": 3307.643986072019,
      "p90_itl_ms": 36.69337861129962,
      "p95_itl_ms": 46.226240195392165,
      "p99_itl_ms": 57.328204565274056,
      "avg_batch_size": 63.77735849056604
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5128151491353574,
      "energy_per_request_joules": 486.26845163485336,
      "avg_output_len": 948.2333984375,
      "avg_power_watts": 482.8031037812383,
      "median_itl_ms": 8.181623503332958,
      "output_throughput_tokens_per_sec": 941.4758994450115,
      "p90_itl_ms": 8.53958138905,
      "p95_itl_ms": 8.75181088777026,
      "p99_itl_ms": 22.107527183431642,
      "avg_batch_size": 7.946268656716418
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.14258416881180042,
      "energy_per_request_joules": 135.51929033799854,
      "avg_output_len": 950.451171875,
      "avg_power_watts": 558.7111672079719,
      "median_itl_ms": 18.14341900171712,
      "output_throughput_tokens_per_sec": 3918.4656463890146,
      "p90_itl_ms": 46.581654388061374,
      "p95_itl_ms": 51.293681414972525,
      "p99_itl_ms": 82.79547477199225,
      "avg_batch_size": 95.72248803827752
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.20183709642853842,
      "energy_per_request_joules": 107.11242411091999,
      "avg_output_len": 530.6875,
      "avg_power_watts": 685.5611828561655,
      "median_itl_ms": 31.610988080501556,
      "output_throughput_tokens_per_sec": 3396.60644642147,
      "p90_itl_ms": 65.25578256696463,
      "p95_itl_ms": 66.51142099872231,
      "p99_itl_ms": 81.57670469954628,
      "avg_batch_size": 127.67441860465117
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.47005657599851564,
      "energy_per_request_joules": 247.42740731009366,
      "avg_output_len": 526.3779296875,
      "avg_power_watts": 516.9861863087898,
      "median_itl_ms": 13.786384835839272,
      "output_throughput_tokens_per_sec": 1099.8382167307925,
      "p90_itl_ms": 14.221685007214546,
      "p95_itl_ms": 14.62812949385908,
      "p99_itl_ms": 46.87051940709351,
      "avg_batch_size": 15.90238611713666
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3226715991744637,
      "energy_per_request_joules": 172.09929224797534,
      "avg_output_len": 533.357421875,
      "avg_power_watts": 577.3878460805918,
      "median_itl_ms": 16.3925401866436,
      "output_throughput_tokens_per_sec": 1789.3977888286563,
      "p90_itl_ms": 17.404925078153614,
      "p95_itl_ms": 47.93844893574714,
      "p99_itl_ms": 50.01947186887264,
      "avg_batch_size": 31.842657342657343
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2448901941383204,
      "energy_per_request_joules": 131.64713309460384,
      "avg_output_len": 537.576171875,
      "avg_power_watts": 645.7503591168161,
      "median_itl_ms": 21.331800147891045,
      "output_throughput_tokens_per_sec": 2636.897575213156,
      "p90_itl_ms": 45.33519819378852,
      "p95_itl_ms": 54.77351099252701,
      "p99_itl_ms": 59.61616013199091,
      "avg_batch_size": 63.751295336787564
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8027836090370855,
      "energy_per_request_joules": 420.02594866229515,
      "avg_output_len": 523.2119140625,
      "avg_power_watts": 487.3839903549126,
      "median_itl_ms": 12.81965896487236,
      "output_throughput_tokens_per_sec": 607.1175156895828,
      "p90_itl_ms": 13.104967772960663,
      "p95_itl_ms": 13.216262683272362,
      "p99_itl_ms": 44.831784907728434,
      "avg_batch_size": 7.946100917431193
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.21764742286503166,
      "energy_per_request_joules": 115.68173071587825,
      "avg_output_len": 531.509765625,
      "avg_power_watts": 685.3893677360132,
      "median_itl_ms": 25.882079266011715,
      "output_throughput_tokens_per_sec": 3149.0810169667825,
      "p90_itl_ms": 58.88683721423149,
      "p95_itl_ms": 60.79908600077033,
      "p99_itl_ms": 75.16882829368114,
      "avg_batch_size": 95.61437908496733
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8982221081842604,
      "energy_per_request_joules": 471.9595789690673,
      "avg_output_len": 525.4375,
      "avg_power_watts": 547.1006070518715,
      "median_itl_ms": 25.229133665561676,
      "output_throughput_tokens_per_sec": 609.0927868139711,
      "p90_itl_ms": 25.79164933413267,
      "p95_itl_ms": 26.248719077557325,
      "p99_itl_ms": 62.06366254016757,
      "avg_batch_size": 15.930475086906142
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5932750203384852,
      "energy_per_request_joules": 307.59282009070785,
      "avg_output_len": 518.4658203125,
      "avg_power_watts": 578.778115504773,
      "median_itl_ms": 27.876002714037895,
      "output_throughput_tokens_per_sec": 975.5646128073264,
      "p90_itl_ms": 29.018796235322952,
      "p95_itl_ms": 62.922720983624444,
      "p99_itl_ms": 83.81860494613645,
      "avg_batch_size": 29.81142857142857
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.5452108441620982,
      "energy_per_request_joules": 791.0996643721143,
      "avg_output_len": 511.96875,
      "avg_power_watts": 526.1543579430693,
      "median_itl_ms": 22.962702438235283,
      "output_throughput_tokens_per_sec": 340.5065140015764,
      "p90_itl_ms": 23.274200037121773,
      "p95_itl_ms": 23.416871577501297,
      "p99_itl_ms": 59.16070081293583,
      "avg_batch_size": 7.960238568588469
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3537615894921871,
      "energy_per_request_joules": 178.95707126254672,
      "avg_output_len": 505.869140625,
      "avg_power_watts": 1258.8744352991482,
      "median_itl_ms": 29.243190016131848,
      "output_throughput_tokens_per_sec": 3558.53906328898,
      "p90_itl_ms": 56.31067559006624,
      "p95_itl_ms": 59.336438000900664,
      "p99_itl_ms": 86.63082778919473,
      "avg_batch_size": 127.7983193277311
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.9831915541495624,
      "energy_per_request_joules": 512.3436152521424,
      "avg_output_len": 521.1025390625,
      "avg_power_watts": 966.1273273511088,
      "median_itl_ms": 15.434223489137366,
      "output_throughput_tokens_per_sec": 982.6440465986165,
      "p90_itl_ms": 15.76049451250583,
      "p95_itl_ms": 18.981650238856673,
      "p99_itl_ms": 41.971410585392725,
      "avg_batch_size": 15.975425330812854
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.32982683363064874,
      "energy_per_request_joules": 166.48460362631099,
      "avg_output_len": 504.763671875,
      "avg_power_watts": 1308.3084137430042,
      "median_itl_ms": 37.07924351328984,
      "output_throughput_tokens_per_sec": 3966.6524380126457,
      "p90_itl_ms": 67.62476489820983,
      "p95_itl_ms": 86.76845120207872,
      "p99_itl_ms": 138.73316316632554,
      "avg_batch_size": 189.72380952380954
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.621021514483831,
      "energy_per_request_joules": 319.237807626117,
      "avg_output_len": 514.052734375,
      "avg_power_watts": 1038.6325766482362,
      "median_itl_ms": 17.56939198821783,
      "output_throughput_tokens_per_sec": 1672.4582843341705,
      "p90_itl_ms": 20.473205787129707,
      "p95_itl_ms": 40.847870614379644,
      "p99_itl_ms": 44.44260292686522,
      "avg_batch_size": 31.93687707641196
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4395756098733716,
      "energy_per_request_joules": 228.96179942750985,
      "avg_output_len": 520.8701171875,
      "avg_power_watts": 1149.1926002823673,
      "median_itl_ms": 21.316227997886017,
      "output_throughput_tokens_per_sec": 2614.3229389215085,
      "p90_itl_ms": 43.23381799622439,
      "p95_itl_ms": 46.62160949665122,
      "p99_itl_ms": 66.80185103381515,
      "avg_batch_size": 63.87428571428571
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.6508754581998644,
      "energy_per_request_joules": 843.3442463989809,
      "avg_output_len": 510.8466796875,
      "avg_power_watts": 856.5900559478847,
      "median_itl_ms": 14.95746651198715,
      "output_throughput_tokens_per_sec": 518.8701859326939,
      "p90_itl_ms": 15.304522486985661,
      "p95_itl_ms": 15.406824000820052,
      "p99_itl_ms": 39.097515764296986,
      "avg_batch_size": 7.987939698492462
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3813253949660844,
      "energy_per_request_joules": 196.89014336196587,
      "avg_output_len": 516.3310546875,
      "avg_power_watts": 1215.0674793576222,
      "median_itl_ms": 25.04304249305278,
      "output_throughput_tokens_per_sec": 3186.432100767094,
      "p90_itl_ms": 50.58443721791264,
      "p95_itl_ms": 51.86817364592571,
      "p99_itl_ms": 74.10011598607521,
      "avg_batch_size": 95.81954887218045
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.9883188151628524,
      "energy_per_request_joules": 464.5387977793286,
      "avg_output_len": 470.029296875,
      "avg_power_watts": 3176.0940067706288,
      "median_itl_ms": 33.491447747040255,
      "output_throughput_tokens_per_sec": 3213.633048407847,
      "p90_itl_ms": 50.708362733684304,
      "p95_itl_ms": 78.5571220330894,
      "p99_itl_ms": 198.03789915200673,
      "avg_batch_size": 114.01724137931035
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.004227169639193,
      "energy_per_request_joules": 934.0892534906803,
      "avg_output_len": 466.0595703125,
      "avg_power_watts": 2186.6096757160853,
      "median_itl_ms": 12.998633086681366,
      "output_throughput_tokens_per_sec": 1090.9989191044272,
      "p90_itl_ms": 16.632903980659574,
      "p95_itl_ms": 34.34370929567979,
      "p99_itl_ms": 76.86544388532639,
      "avg_batch_size": 15.94927536231884
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.5308139809168704,
      "energy_per_request_joules": 720.7861548115536,
      "avg_output_len": 470.8515625,
      "avg_power_watts": 2465.9747181854223,
      "median_itl_ms": 16.251688823103905,
      "output_throughput_tokens_per_sec": 1610.89116569764,
      "p90_itl_ms": 24.53194786642,
      "p95_itl_ms": 67.71142780780792,
      "p99_itl_ms": 85.55312063544993,
      "avg_batch_size": 31.926056338028168
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.184524145034153,
      "energy_per_request_joules": 557.0571820581221,
      "avg_output_len": 470.279296875,
      "avg_power_watts": 2774.5154566521956,
      "median_itl_ms": 21.697504445910454,
      "output_throughput_tokens_per_sec": 2342.3038426727876,
      "p90_itl_ms": 47.85144738852981,
      "p95_itl_ms": 71.09987214207648,
      "p99_itl_ms": 111.37769671834329,
      "avg_batch_size": 63.80327868852459
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.0535574887712604,
      "energy_per_request_joules": 1433.8897641363874,
      "avg_output_len": 469.580078125,
      "avg_power_watts": 1972.1724498489032,
      "median_itl_ms": 11.242572218179703,
      "output_throughput_tokens_per_sec": 645.8605928007262,
      "p90_itl_ms": 11.56354546546936,
      "p95_itl_ms": 15.598137676715847,
      "p99_itl_ms": 66.34518124163151,
      "avg_batch_size": 7.97119341563786
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "nickname": "Llama 4 Maverick 17B 128E Instruct FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 400.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.0781669743556241,
      "energy_per_request_joules": 511.69973066507663,
      "avg_output_len": 474.6015625,
      "avg_power_watts": 3063.707501524729,
      "median_itl_ms": 31.02301713079214,
      "output_throughput_tokens_per_sec": 2841.5890807226597,
      "p90_itl_ms": 66.96578123582862,
      "p95_itl_ms": 78.34599139168859,
      "p99_itl_ms": 155.14940737436214,
      "avg_batch_size": 95.56462585034014
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.9681839572288371,
      "energy_per_request_joules": 392.0369723217291,
      "avg_output_len": 404.919921875,
      "avg_power_watts": 2007.0117080432462,
      "median_itl_ms": 45.39153299992904,
      "output_throughput_tokens_per_sec": 2072.9652593994333,
      "p90_itl_ms": 110.40538362484736,
      "p95_itl_ms": 136.1798012076178,
      "p99_itl_ms": 213.7727963348152,
      "avg_batch_size": 127.1055900621118
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 2.9527550460335243,
      "energy_per_request_joules": 1195.9580672387658,
      "avg_output_len": 405.03125,
      "avg_power_watts": 1569.0969711869452,
      "median_itl_ms": 27.600298984907568,
      "output_throughput_tokens_per_sec": 531.4009955870652,
      "p90_itl_ms": 30.733293207595132,
      "p95_itl_ms": 37.610499759439264,
      "p99_itl_ms": 122.55690176622012,
      "avg_batch_size": 15.952755905511811
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.9727695019409526,
      "energy_per_request_joules": 816.3239284657559,
      "avg_output_len": 413.7958984375,
      "avg_power_watts": 1735.5413141839526,
      "median_itl_ms": 32.43006301636342,
      "output_throughput_tokens_per_sec": 879.7486541009491,
      "p90_itl_ms": 38.84740085163685,
      "p95_itl_ms": 89.64608870010125,
      "p99_itl_ms": 130.673776192707,
      "avg_batch_size": 31.538126361655774
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.3805163345608442,
      "energy_per_request_joules": 564.3238002452682,
      "avg_output_len": 408.77734375,
      "avg_power_watts": 1903.6019819129544,
      "median_itl_ms": 36.27335201599635,
      "output_throughput_tokens_per_sec": 1378.9058008636378,
      "p90_itl_ms": 84.0469573973678,
      "p95_itl_ms": 110.52508921296821,
      "p99_itl_ms": 159.6563160396181,
      "avg_batch_size": 62.40875912408759
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 4.230019377115634,
      "energy_per_request_joules": 1719.9242263838978,
      "avg_output_len": 406.599609375,
      "avg_power_watts": 1382.3928378179262,
      "median_itl_ms": 23.129582492401823,
      "output_throughput_tokens_per_sec": 326.805320395613,
      "p90_itl_ms": 23.99192040320486,
      "p95_itl_ms": 26.31573881226359,
      "p99_itl_ms": 94.72584523988165,
      "avg_batch_size": 7.976837060702875
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.1078809519849786,
      "energy_per_request_joules": 455.59548511897117,
      "avg_output_len": 411.2314453125,
      "avg_power_watts": 1980.6188840735792,
      "median_itl_ms": 39.267880987608805,
      "output_throughput_tokens_per_sec": 1787.7542533111753,
      "p90_itl_ms": 99.16396539774725,
      "p95_itl_ms": 129.01164519716988,
      "p99_itl_ms": 192.87134192651138,
      "avg_batch_size": 95.825
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.161993172535125,
      "energy_per_request_joules": 473.9082486842497,
      "avg_output_len": 407.8408203125,
      "avg_power_watts": 3055.065338331681,
      "median_itl_ms": 45.452832244336605,
      "output_throughput_tokens_per_sec": 2629.159456820588,
      "p90_itl_ms": 76.5809990298837,
      "p95_itl_ms": 102.86983847618103,
      "p99_itl_ms": 225.83621269091964,
      "avg_batch_size": 121.776
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.617113861192852,
      "energy_per_request_joules": 1481.2823052513293,
      "avg_output_len": 409.5205078125,
      "avg_power_watts": 2411.633108666854,
      "median_itl_ms": 21.673783659934998,
      "output_throughput_tokens_per_sec": 666.7285579645937,
      "p90_itl_ms": 25.560926273465157,
      "p95_itl_ms": 31.004633549379093,
      "p99_itl_ms": 101.67430721223353,
      "avg_batch_size": 15.958609271523178
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.3941867684061084,
      "energy_per_request_joules": 1003.3980632637616,
      "avg_output_len": 419.09765625,
      "avg_power_watts": 2664.3445904506298,
      "median_itl_ms": 24.103584699332714,
      "output_throughput_tokens_per_sec": 1112.8390757185475,
      "p90_itl_ms": 31.8779747314214,
      "p95_itl_ms": 77.69179092720148,
      "p99_itl_ms": 108.54324989020827,
      "avg_batch_size": 31.883152173913043
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.607282698741784,
      "energy_per_request_joules": 671.1551084014607,
      "avg_output_len": 417.5712890625,
      "avg_power_watts": 2882.2170588005565,
      "median_itl_ms": 29.209882020950317,
      "output_throughput_tokens_per_sec": 1793.2234703060133,
      "p90_itl_ms": 61.05066396209389,
      "p95_itl_ms": 88.93941731416975,
      "p99_itl_ms": 137.4761435027058,
      "avg_batch_size": 63.8110599078341
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 5.593487203207131,
      "energy_per_request_joules": 2339.852927640817,
      "avg_output_len": 418.3173828125,
      "avg_power_watts": 2079.1018293619672,
      "median_itl_ms": 20.225130021572113,
      "output_throughput_tokens_per_sec": 371.700471249827,
      "p90_itl_ms": 20.53598314523697,
      "p95_itl_ms": 22.856755182147026,
      "p99_itl_ms": 83.06298591196537,
      "avg_batch_size": 7.973521624007061
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "nickname": "Llama 4 Scout 17B 16E Instruct",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 109.0,
      "activated_params_billions": 17.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.318756313190108,
      "energy_per_request_joules": 534.1053217777285,
      "avg_output_len": 405.0068359375,
      "avg_power_watts": 2963.0487087326956,
      "median_itl_ms": 33.3363250770335,
      "output_throughput_tokens_per_sec": 2246.8508238379522,
      "p90_itl_ms": 83.30430090427396,
      "p95_itl_ms": 107.25816274061795,
      "p99_itl_ms": 198.80743138492107,
      "avg_batch_size": 95.75155279503106
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16",
      "nickname": "NVIDIA Nemotron Nano 12B V2 VL",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6202413249489864,
      "energy_per_request_joules": 182.3945602531625,
      "avg_output_len": 294.0703125,
      "avg_power_watts": 477.4265437690641,
      "median_itl_ms": 12.896094471216202,
      "output_throughput_tokens_per_sec": 769.7432024677354,
      "p90_itl_ms": 41.36547502130269,
      "p95_itl_ms": 78.98902645419267,
      "p99_itl_ms": 146.13901338961028,
      "avg_batch_size": 15.700280112044817
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16",
      "nickname": "NVIDIA Nemotron Nano 12B V2 VL",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.49362933565250244,
      "energy_per_request_joules": 132.42571048674574,
      "avg_output_len": 268.26953125,
      "avg_power_watts": 478.53790592335764,
      "median_itl_ms": 20.10738359143337,
      "output_throughput_tokens_per_sec": 969.4276076416807,
      "p90_itl_ms": 82.64031568272175,
      "p95_itl_ms": 123.95818683359286,
      "p99_itl_ms": 326.9735071118231,
      "avg_batch_size": 30.945833333333333
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16",
      "nickname": "NVIDIA Nemotron Nano 12B V2 VL",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8311646357137796,
      "energy_per_request_joules": 236.6887403353609,
      "avg_output_len": 284.767578125,
      "avg_power_watts": 482.5863367851252,
      "median_itl_ms": 11.504797264933586,
      "output_throughput_tokens_per_sec": 580.6146171879585,
      "p90_itl_ms": 21.919015794992447,
      "p95_itl_ms": 48.092668457098284,
      "p99_itl_ms": 137.56485022604468,
      "avg_batch_size": 7.75764192139738
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 8.821869510657029,
      "energy_per_request_joules": 8201.978105608381,
      "avg_output_len": 929.732421875,
      "avg_power_watts": 3936.415295392636,
      "median_itl_ms": 16.99093749630265,
      "output_throughput_tokens_per_sec": 446.2110089746116,
      "p90_itl_ms": 17.36446830618661,
      "p95_itl_ms": 17.49838084942894,
      "p99_itl_ms": 23.04213037714363,
      "avg_batch_size": 7.995256166982922
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 5.880019860711525,
      "energy_per_request_joules": 5464.163495152356,
      "avg_output_len": 929.2763671875,
      "avg_power_watts": 4506.532286176022,
      "median_itl_ms": 19.29430599557236,
      "output_throughput_tokens_per_sec": 766.4144667754064,
      "p90_itl_ms": 19.747296592686325,
      "p95_itl_ms": 20.096971286693588,
      "p99_itl_ms": 108.61843928229064,
      "avg_batch_size": 15.984310487200661
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.6756257296287536,
      "energy_per_request_joules": 1571.46857245851,
      "avg_output_len": 937.83984375,
      "avg_power_watts": 4602.197618907625,
      "median_itl_ms": 35.95125699939672,
      "output_throughput_tokens_per_sec": 2746.5546377873256,
      "p90_itl_ms": 111.60590850922745,
      "p95_itl_ms": 120.82438318611821,
      "p99_itl_ms": 130.99571911472597,
      "avg_batch_size": 127.89180327868853
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.295307244518345,
      "energy_per_request_joules": 1206.955652916169,
      "avg_output_len": 931.791015625,
      "avg_power_watts": 4544.812262104229,
      "median_itl_ms": 40.00539449043572,
      "output_throughput_tokens_per_sec": 3508.6750895106748,
      "p90_itl_ms": 122.15834460803308,
      "p95_itl_ms": 128.3428728493163,
      "p99_itl_ms": 142.38776387501272,
      "avg_batch_size": 191.86036036036037
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.0990031522849555,
      "energy_per_request_joules": 1016.1089076823841,
      "avg_output_len": 924.5732421875,
      "avg_power_watts": 4591.892931926612,
      "median_itl_ms": 41.779246006626636,
      "output_throughput_tokens_per_sec": 4178.23454134734,
      "p90_itl_ms": 121.19652560213581,
      "p95_itl_ms": 127.00805901840795,
      "p99_itl_ms": 143.83263605413956,
      "avg_batch_size": 255.6890243902439
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 4.477502861265936,
      "energy_per_request_joules": 4188.891946853965,
      "avg_output_len": 935.5419921875,
      "avg_power_watts": 4404.813243177252,
      "median_itl_ms": 29.476814001100138,
      "output_throughput_tokens_per_sec": 983.7655898073211,
      "p90_itl_ms": 30.27793500223197,
      "p95_itl_ms": 32.82099700300023,
      "p99_itl_ms": 123.44734409998648,
      "avg_batch_size": 31.972132904608788
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8997684670856395,
      "energy_per_request_joules": 821.5808718642709,
      "avg_output_len": 913.1025390625,
      "avg_power_watts": 4597.270460150431,
      "median_itl_ms": 48.13392701908015,
      "output_throughput_tokens_per_sec": 5109.392725265249,
      "p90_itl_ms": 125.17640480073169,
      "p95_itl_ms": 131.71685921261087,
      "p99_itl_ms": 171.68920587049797,
      "avg_batch_size": 383.62608695652176
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.7363435163185645,
      "energy_per_request_joules": 2525.4606830399393,
      "avg_output_len": 922.9326171875,
      "avg_power_watts": 4512.516335117868,
      "median_itl_ms": 33.10224000597373,
      "output_throughput_tokens_per_sec": 1649.1044739839315,
      "p90_itl_ms": 36.258085584267974,
      "p95_itl_ms": 112.15054059866814,
      "p99_itl_ms": 121.87398519134149,
      "avg_batch_size": 63.91198501872659
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.076049221453903,
      "energy_per_request_joules": 1908.598821652376,
      "avg_output_len": 919.341796875,
      "avg_power_watts": 4501.354952678083,
      "median_itl_ms": 35.891598992748186,
      "output_throughput_tokens_per_sec": 2168.231324267777,
      "p90_itl_ms": 42.54712139954791,
      "p95_itl_ms": 121.36377985443687,
      "p99_itl_ms": 129.03118076006646,
      "avg_batch_size": 95.91071428571429
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7504557408324712,
      "energy_per_request_joules": 698.9886946298913,
      "avg_output_len": 931.4189453125,
      "avg_power_watts": 4524.148184437653,
      "median_itl_ms": 56.52425248990767,
      "output_throughput_tokens_per_sec": 6028.534313587996,
      "p90_itl_ms": 134.6198219951475,
      "p95_itl_ms": 141.90061084664194,
      "p99_itl_ms": 183.10376408393495,
      "avg_batch_size": 511.47639484978544
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6120116241876551,
      "energy_per_request_joules": 569.9830407652917,
      "avg_output_len": 931.3271484375,
      "avg_power_watts": 4241.050385162986,
      "median_itl_ms": 120.08048950519878,
      "output_throughput_tokens_per_sec": 6929.68926986033,
      "p90_itl_ms": 176.6882411000552,
      "p95_itl_ms": 194.07242584275082,
      "p99_itl_ms": 433.33343841979513,
      "avg_batch_size": 1022.8076923076923
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5169772522422859,
      "energy_per_request_joules": 485.28378677523193,
      "avg_output_len": 938.6946614583334,
      "avg_power_watts": 4613.620521349179,
      "median_itl_ms": 153.5743064887356,
      "output_throughput_tokens_per_sec": 8924.223457296273,
      "p90_itl_ms": 199.3606451083906,
      "p95_itl_ms": 223.73212852398834,
      "p99_itl_ms": 396.8008841716783,
      "avg_batch_size": 1534.25786163522
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4586514455672989,
      "energy_per_request_joules": 430.78657864187625,
      "avg_output_len": 939.24609375,
      "avg_power_watts": 4983.629472159795,
      "median_itl_ms": 149.0010855050059,
      "output_throughput_tokens_per_sec": 10865.831821364089,
      "p90_itl_ms": 216.64371179940642,
      "p95_itl_ms": 258.1615651433822,
      "p99_itl_ms": 477.82679484749644,
      "avg_batch_size": 2046.0729166666667
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.2737332890054938,
      "energy_per_request_joules": 1185.4712841344362,
      "avg_output_len": 930.7060546875,
      "avg_power_watts": 2981.9836753767026,
      "median_itl_ms": 45.112803985830396,
      "output_throughput_tokens_per_sec": 2341.1366422753836,
      "p90_itl_ms": 110.95497500500642,
      "p95_itl_ms": 122.4943128763698,
      "p99_itl_ms": 129.4628916517831,
      "avg_batch_size": 127.87252124645893
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 4.799211874874819,
      "energy_per_request_joules": 4456.035418708844,
      "avg_output_len": 928.4931640625,
      "avg_power_watts": 2847.570793571764,
      "median_itl_ms": 25.563647999661043,
      "output_throughput_tokens_per_sec": 593.341337664122,
      "p90_itl_ms": 26.401526003610343,
      "p95_itl_ms": 26.797347993124276,
      "p99_itl_ms": 109.2353199783247,
      "avg_batch_size": 15.98706338939198
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.96723112554252,
      "energy_per_request_joules": 885.9213699283098,
      "avg_output_len": 915.935546875,
      "avg_power_watts": 2903.7468142816138,
      "median_itl_ms": 51.21387599501759,
      "output_throughput_tokens_per_sec": 3002.123006176938,
      "p90_itl_ms": 118.81735629285686,
      "p95_itl_ms": 123.9791058047558,
      "p99_itl_ms": 138.8368956191696,
      "avg_batch_size": 191.7976653696498
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.790051709096917,
      "energy_per_request_joules": 739.1365798130071,
      "avg_output_len": 935.5546875,
      "avg_power_watts": 2943.0818396445216,
      "median_itl_ms": 52.3127780033974,
      "output_throughput_tokens_per_sec": 3725.1762204383617,
      "p90_itl_ms": 118.49325870280154,
      "p95_itl_ms": 125.10159990342798,
      "p99_itl_ms": 153.7854100301047,
      "avg_batch_size": 255.68947368421053
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 3.1684523472083437,
      "energy_per_request_joules": 2908.5804650940986,
      "avg_output_len": 917.9814453125,
      "avg_power_watts": 3115.937407652115,
      "median_itl_ms": 29.54949499689974,
      "output_throughput_tokens_per_sec": 983.4256811207848,
      "p90_itl_ms": 30.968836398096755,
      "p95_itl_ms": 34.28403029683977,
      "p99_itl_ms": 115.02110118337441,
      "avg_batch_size": 31.974780701754387
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6347152758815502,
      "energy_per_request_joules": 594.8689169850214,
      "avg_output_len": 937.2216796875,
      "avg_power_watts": 2939.309063919983,
      "median_itl_ms": 58.47321602050215,
      "output_throughput_tokens_per_sec": 4630.909599327988,
      "p90_itl_ms": 123.84586001280695,
      "p95_itl_ms": 131.2282260041684,
      "p99_itl_ms": 187.34306048718253,
      "avg_batch_size": 383.632
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 2.1371219955693976,
      "energy_per_request_joules": 1993.8680368038865,
      "avg_output_len": 932.96875,
      "avg_power_watts": 3007.630659692327,
      "median_itl_ms": 40.43372950400226,
      "output_throughput_tokens_per_sec": 1407.3275488847316,
      "p90_itl_ms": 43.84741949616,
      "p95_itl_ms": 108.865691749088,
      "p99_itl_ms": 117.17617660469841,
      "avg_batch_size": 63.940988835725676
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 6.632630906751159,
      "energy_per_request_joules": 6115.480011383165,
      "avg_output_len": 922.029296875,
      "avg_power_watts": 2564.5780145630083,
      "median_itl_ms": 19.990801491076127,
      "output_throughput_tokens_per_sec": 386.6607460325585,
      "p90_itl_ms": 20.715421496424824,
      "p95_itl_ms": 20.928950459347107,
      "p99_itl_ms": 26.84810380858835,
      "avg_batch_size": 7.995852343425964
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.5920491209975816,
      "energy_per_request_joules": 1477.3158622738144,
      "avg_output_len": 927.93359375,
      "avg_power_watts": 3004.159586840488,
      "median_itl_ms": 43.27604698482901,
      "output_throughput_tokens_per_sec": 1886.976693883713,
      "p90_itl_ms": 52.07954239740502,
      "p95_itl_ms": 118.1745307345409,
      "p99_itl_ms": 129.1171749445493,
      "avg_batch_size": 95.90687361419069
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3697245746225884,
      "energy_per_request_joules": 344.85788903555755,
      "avg_output_len": 932.74267578125,
      "avg_power_watts": 2984.615710020861,
      "median_itl_ms": 107.58416299358942,
      "output_throughput_tokens_per_sec": 8072.538086134878,
      "p90_itl_ms": 187.95034061186016,
      "p95_itl_ms": 229.09402041113918,
      "p99_itl_ms": 592.8801333950832,
      "avg_batch_size": 951.9222222222222
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5238025833335942,
      "energy_per_request_joules": 485.0097333203506,
      "avg_output_len": 925.93994140625,
      "avg_power_watts": 2696.776465629277,
      "median_itl_ms": 66.81747701077256,
      "output_throughput_tokens_per_sec": 5148.459651470984,
      "p90_itl_ms": 139.47950389410835,
      "p95_itl_ms": 153.37277690123298,
      "p99_itl_ms": 319.21800266223727,
      "avg_batch_size": 511.4792452830189
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.1385063161325453,
      "energy_per_request_joules": 1058.5684966820593,
      "avg_output_len": 929.787109375,
      "avg_power_watts": 2762.331751111958,
      "median_itl_ms": 37.42286299529951,
      "output_throughput_tokens_per_sec": 2426.277054391296,
      "p90_itl_ms": 142.3698814905947,
      "p95_itl_ms": 157.26155174343148,
      "p99_itl_ms": 177.2529069363372,
      "avg_batch_size": 127.85285285285285
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 5.431774134828368,
      "energy_per_request_joules": 4947.158036236649,
      "avg_output_len": 910.78125,
      "avg_power_watts": 2949.30104393696,
      "median_itl_ms": 27.266580000286922,
      "output_throughput_tokens_per_sec": 542.971959203188,
      "p90_itl_ms": 27.729119989089668,
      "p95_itl_ms": 28.083234479709063,
      "p99_itl_ms": 149.1699473859626,
      "avg_batch_size": 15.983253588516746
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8835661977881729,
      "energy_per_request_joules": 807.0842245073643,
      "avg_output_len": 913.439453125,
      "avg_power_watts": 2668.5488976730885,
      "median_itl_ms": 42.7578709932277,
      "output_throughput_tokens_per_sec": 3020.2025658668863,
      "p90_itl_ms": 157.74796539044476,
      "p95_itl_ms": 166.01086678856518,
      "p99_itl_ms": 179.7327079603565,
      "avg_batch_size": 191.76706827309238
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 3.12133061381664,
      "energy_per_request_joules": 2899.774055549782,
      "avg_output_len": 929.0185546875,
      "avg_power_watts": 3029.7111216030894,
      "median_itl_ms": 28.61866500461474,
      "output_throughput_tokens_per_sec": 970.6472964421022,
      "p90_itl_ms": 29.437012283597145,
      "p95_itl_ms": 32.419078261591494,
      "p99_itl_ms": 165.3744545954396,
      "avg_batch_size": 31.964401294498384
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5804466603404967,
      "energy_per_request_joules": 532.0224442276374,
      "avg_output_len": 916.57421875,
      "avg_power_watts": 2681.428690712584,
      "median_itl_ms": 51.08402599580586,
      "output_throughput_tokens_per_sec": 4619.595346004105,
      "p90_itl_ms": 157.95656121335924,
      "p95_itl_ms": 162.8703500085976,
      "p99_itl_ms": 183.61759079271,
      "avg_batch_size": 383.4878048780488
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.8703528444800777,
      "energy_per_request_joules": 1713.1664918528643,
      "avg_output_len": 915.958984375,
      "avg_power_watts": 2878.4556719831503,
      "median_itl_ms": 32.84370149776805,
      "output_throughput_tokens_per_sec": 1538.9907206430378,
      "p90_itl_ms": 37.08334251132328,
      "p95_itl_ms": 147.15252452151617,
      "p99_itl_ms": 170.2822776933317,
      "avg_batch_size": 63.91531531531532
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 9.709842420901362,
      "energy_per_request_joules": 8987.81512486666,
      "avg_output_len": 925.6396484375,
      "avg_power_watts": 2903.988650713749,
      "median_itl_ms": 25.865551986498758,
      "output_throughput_tokens_per_sec": 299.07680524893345,
      "p90_itl_ms": 26.278491783887148,
      "p95_itl_ms": 26.427289107232355,
      "p99_itl_ms": 32.38997953361831,
      "avg_batch_size": 7.991997439180538
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.3757002982006254,
      "energy_per_request_joules": 1265.3728959654381,
      "avg_output_len": 919.802734375,
      "avg_power_watts": 2823.1009216037037,
      "median_itl_ms": 35.343625000678,
      "output_throughput_tokens_per_sec": 2052.119146369478,
      "p90_itl_ms": 42.992464898270576,
      "p95_itl_ms": 149.71589140186552,
      "p99_itl_ms": 158.0951226624893,
      "avg_batch_size": 95.89646464646465
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6739794352285546,
      "energy_per_request_joules": 621.7835454317479,
      "avg_output_len": 922.5556640625,
      "avg_power_watts": 2947.579975801328,
      "median_itl_ms": 45.945856982143596,
      "output_throughput_tokens_per_sec": 4373.397498102843,
      "p90_itl_ms": 75.03020999138243,
      "p95_itl_ms": 154.28496199456276,
      "p99_itl_ms": 169.897924317047,
      "avg_batch_size": 255.74864864864864
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5051435245223389,
      "energy_per_request_joules": 468.3654748162835,
      "avg_output_len": 927.19287109375,
      "avg_power_watts": 2570.52858328408,
      "median_itl_ms": 58.53327197837643,
      "output_throughput_tokens_per_sec": 5088.709363768958,
      "p90_itl_ms": 177.04453327460214,
      "p95_itl_ms": 187.55832169554196,
      "p99_itl_ms": 214.49589497351647,
      "avg_batch_size": 511.4375
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4196753544832558,
      "energy_per_request_joules": 390.9485969608376,
      "avg_output_len": 931.550048828125,
      "avg_power_watts": 2254.9937345051994,
      "median_itl_ms": 184.00014750659466,
      "output_throughput_tokens_per_sec": 5373.185988683472,
      "p90_itl_ms": 231.9906999007799,
      "p95_itl_ms": 248.69464874791444,
      "p99_itl_ms": 316.3154187117469,
      "avg_batch_size": 1022.9409523809524
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.36085144226807253,
      "energy_per_request_joules": 331.07225628354684,
      "avg_output_len": 917.4752197265625,
      "avg_power_watts": 2386.1732018707626,
      "median_itl_ms": 269.74317702115513,
      "output_throughput_tokens_per_sec": 6612.619273108242,
      "p90_itl_ms": 359.82781240018085,
      "p95_itl_ms": 438.7185664410935,
      "p99_itl_ms": 889.0299589326523,
      "avg_batch_size": 1889.631704410012
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 4.803888939901894,
      "energy_per_request_joules": 4362.526952250614,
      "avg_output_len": 908.1240234375,
      "avg_power_watts": 1801.824747293195,
      "median_itl_ms": 40.48846900695935,
      "output_throughput_tokens_per_sec": 375.0762704622377,
      "p90_itl_ms": 41.85686380369589,
      "p95_itl_ms": 46.39439826369106,
      "p99_itl_ms": 144.68876982689835,
      "avg_batch_size": 15.982271000422118
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 2.689980644895184,
      "energy_per_request_joules": 2449.4821897967477,
      "avg_output_len": 910.5947265625,
      "avg_power_watts": 1814.6034297441763,
      "median_itl_ms": 43.31289301626384,
      "output_throughput_tokens_per_sec": 674.5786194364543,
      "p90_itl_ms": 45.95667341491208,
      "p95_itl_ms": 75.99624953952363,
      "p99_itl_ms": 146.22084551723677,
      "avg_batch_size": 31.972178060413356
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 1.5120302538041,
      "energy_per_request_joules": 1411.2055958058074,
      "avg_output_len": 933.318359375,
      "avg_power_watts": 1809.5805092317958,
      "median_itl_ms": 47.72696498548612,
      "output_throughput_tokens_per_sec": 1196.7885594081813,
      "p90_itl_ms": 55.85271940799436,
      "p95_itl_ms": 136.06376760290004,
      "p99_itl_ms": 153.46030232612975,
      "avg_batch_size": 63.93707250341997
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 8.444336265699711,
      "energy_per_request_joules": 7592.142755901202,
      "avg_output_len": 899.0810546875,
      "avg_power_watts": 1763.3573231438659,
      "median_itl_ms": 36.84750897809863,
      "output_throughput_tokens_per_sec": 208.82130550704107,
      "p90_itl_ms": 38.14277398632839,
      "p95_itl_ms": 38.450214895419776,
      "p99_itl_ms": 47.359769062604734,
      "avg_batch_size": 7.9930571626938205
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8863511007056551,
      "energy_per_request_joules": 816.4929578495504,
      "avg_output_len": 921.1845703125,
      "avg_power_watts": 1763.8358216459405,
      "median_itl_ms": 52.68382799113169,
      "output_throughput_tokens_per_sec": 1989.996763406385,
      "p90_itl_ms": 135.5588772217743,
      "p95_itl_ms": 147.40529558621347,
      "p99_itl_ms": 155.2641791733913,
      "avg_batch_size": 127.8661800486618
    },
    {
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.544306370677898,
      "energy_per_request_joules": 495.936723250396,
      "avg_output_len": 911.13525390625,
      "avg_power_watts": 1717.462544968228,
      "median_itl_ms": 62.87448646617122,
      "output_throughput_tokens_per_sec": 3155.323247143407,
      "p90_itl_ms": 155.99705999484286,
      "p95_itl_ms": 161.03158805926796,
      "p99_itl_ms": 174.60385213722478,
      "avg_batch_size": 255.73540856031127
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.29291550382544385,
      "energy_per_request_joules": 276.31972376153686,
      "avg_output_len": 943.3427734375,
      "avg_power_watts": 349.3652682537472,
      "median_itl_ms": 75.68522856391247,
      "output_throughput_tokens_per_sec": 1192.7168882871536,
      "p90_itl_ms": 181.82858923930635,
      "p95_itl_ms": 235.20944229676388,
      "p99_itl_ms": 441.75925878051174,
      "avg_batch_size": 115.13333333333334
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5808823722496946,
      "energy_per_request_joules": 540.1014799244695,
      "avg_output_len": 929.794921875,
      "avg_power_watts": 365.5120916253695,
      "median_itl_ms": 37.49177895952016,
      "output_throughput_tokens_per_sec": 629.2359849202873,
      "p90_itl_ms": 111.26450257143017,
      "p95_itl_ms": 148.1922325852792,
      "p99_itl_ms": 211.26691145589567,
      "avg_batch_size": 31.86051502145923
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.37281582656602974,
      "energy_per_request_joules": 343.8668960799509,
      "avg_output_len": 922.3505859375,
      "avg_power_watts": 402.6522837668964,
      "median_itl_ms": 33.155431505292654,
      "output_throughput_tokens_per_sec": 1080.030017705223,
      "p90_itl_ms": 136.0602586332243,
      "p95_itl_ms": 178.18821781838778,
      "p99_itl_ms": 303.02614579667824,
      "avg_batch_size": 63.81059602649007
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7444943727755426,
      "energy_per_request_joules": 698.5116666226501,
      "avg_output_len": 938.236328125,
      "avg_power_watts": 583.5827138575717,
      "median_itl_ms": 8.75678300508298,
      "output_throughput_tokens_per_sec": 783.8645061639919,
      "p90_itl_ms": 14.508500334341079,
      "p95_itl_ms": 20.06250974577148,
      "p99_itl_ms": 92.16907136328985,
      "avg_batch_size": 7.752
    },
    {
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8905973522452655,
      "energy_per_request_joules": 828.2311853167464,
      "avg_output_len": 929.97265625,
      "avg_power_watts": 362.8790673150578,
      "median_itl_ms": 31.96836798451841,
      "output_throughput_tokens_per_sec": 407.45581198979687,
      "p90_itl_ms": 61.09153580619024,
      "p95_itl_ms": 94.7185157623606,
      "p99_itl_ms": 178.08760315235887,
      "avg_batch_size": 15.923994038748138
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8843523336570842,
      "energy_per_request_joules": 921.8207184185223,
      "avg_output_len": 1042.3681640625,
      "avg_power_watts": 373.61796458663866,
      "median_itl_ms": 35.412486002314836,
      "output_throughput_tokens_per_sec": 422.4763709749111,
      "p90_itl_ms": 64.79799599619584,
      "p95_itl_ms": 78.63202681764959,
      "p99_itl_ms": 133.62513931235293,
      "avg_batch_size": 15.937810945273633
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5855414926458951,
      "energy_per_request_joules": 593.6435799596643,
      "avg_output_len": 1013.8369140625,
      "avg_power_watts": 389.31239533438804,
      "median_itl_ms": 38.937741017434746,
      "output_throughput_tokens_per_sec": 664.8758460740268,
      "p90_itl_ms": 73.93663408001886,
      "p95_itl_ms": 150.58579514734421,
      "p99_itl_ms": 186.11241560896178,
      "avg_batch_size": 31.899912203687446
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.39710655886099444,
      "energy_per_request_joules": 407.5984709215259,
      "avg_output_len": 1026.4208984375,
      "avg_power_watts": 379.4859601860645,
      "median_itl_ms": 39.11626449553296,
      "output_throughput_tokens_per_sec": 955.6275304908828,
      "p90_itl_ms": 147.24846940371208,
      "p95_itl_ms": 200.79434259994804,
      "p99_itl_ms": 292.5229976265315,
      "avg_batch_size": 63.775796178343946
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.752436665193873,
      "energy_per_request_joules": 757.1518859756592,
      "avg_output_len": 1006.2666015625,
      "avg_power_watts": 633.7356631514658,
      "median_itl_ms": 8.567289041820914,
      "output_throughput_tokens_per_sec": 842.244526970489,
      "p90_itl_ms": 13.08484982000664,
      "p95_itl_ms": 15.3731202124618,
      "p99_itl_ms": 71.3137840470051,
      "avg_batch_size": 7.873563218390805
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.13960377581632355,
      "energy_per_request_joules": 141.99599012711363,
      "avg_output_len": 1017.1357421875,
      "avg_power_watts": 273.9520375931237,
      "median_itl_ms": 73.44447732315835,
      "output_throughput_tokens_per_sec": 1962.3540695171594,
      "p90_itl_ms": 228.88869919115672,
      "p95_itl_ms": 352.4147561547574,
      "p99_itl_ms": 886.7587612516942,
      "avg_batch_size": 905.6147540983607
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2264458717796994,
      "energy_per_request_joules": 229.78727521972993,
      "avg_output_len": 1014.755859375,
      "avg_power_watts": 393.62063259990026,
      "median_itl_ms": 40.147010498913005,
      "output_throughput_tokens_per_sec": 1738.2548399152925,
      "p90_itl_ms": 158.91336062340986,
      "p95_itl_ms": 217.4280136773583,
      "p99_itl_ms": 326.81138605345046,
      "avg_batch_size": 127.68376068376068
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1594627766077716,
      "energy_per_request_joules": 162.77162922238287,
      "avg_output_len": 1020.75,
      "avg_power_watts": 371.0366595224079,
      "median_itl_ms": 64.63808799162507,
      "output_throughput_tokens_per_sec": 2326.7916652112585,
      "p90_itl_ms": 216.8264600981704,
      "p95_itl_ms": 253.01631601083184,
      "p99_itl_ms": 381.7646652203771,
      "avg_batch_size": 255.40740740740742
    },
    {
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.10512774994708114,
      "energy_per_request_joules": 107.68356570385124,
      "avg_output_len": 1024.3115234375,
      "avg_power_watts": 431.62074074674746,
      "median_itl_ms": 31.075525505002588,
      "output_throughput_tokens_per_sec": 4105.678481314546,
      "p90_itl_ms": 118.70149661620658,
      "p95_itl_ms": 159.9860067254471,
      "p99_itl_ms": 315.72676807991235,
      "avg_batch_size": 472.0657894736842
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3039736660976454,
      "energy_per_request_joules": 285.82815995745915,
      "avg_output_len": 940.3056640625,
      "avg_power_watts": 494.0674554434824,
      "median_itl_ms": 46.02685500867665,
      "output_throughput_tokens_per_sec": 1625.362689427094,
      "p90_itl_ms": 171.5484309158045,
      "p95_itl_ms": 197.95149791803098,
      "p99_itl_ms": 307.2732544349894,
      "avg_batch_size": 127.69252873563218
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.1089305049525482,
      "energy_per_request_joules": 1052.0599136756116,
      "avg_output_len": 948.7158203125,
      "avg_power_watts": 453.81672114261124,
      "median_itl_ms": 33.1301020050887,
      "output_throughput_tokens_per_sec": 409.23819762901223,
      "p90_itl_ms": 56.114267796510845,
      "p95_itl_ms": 74.53642699401824,
      "p99_itl_ms": 191.50130887886897,
      "avg_batch_size": 15.94634402945818
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2655381340391102,
      "energy_per_request_joules": 249.39748672850146,
      "avg_output_len": 939.21533203125,
      "avg_power_watts": 536.9409252696726,
      "median_itl_ms": 49.05475600389764,
      "output_throughput_tokens_per_sec": 2022.085932074029,
      "p90_itl_ms": 197.47916582186343,
      "p95_itl_ms": 276.6291006210898,
      "p99_itl_ms": 527.1454999962591,
      "avg_batch_size": 250.8042328042328
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6636057247465799,
      "energy_per_request_joules": 624.531401334866,
      "avg_output_len": 941.1181640625,
      "avg_power_watts": 496.95639710530776,
      "median_itl_ms": 30.23387599387206,
      "output_throughput_tokens_per_sec": 748.872980707162,
      "p90_itl_ms": 83.05273210545155,
      "p95_itl_ms": 108.44035920454186,
      "p99_itl_ms": 159.32730629183627,
      "avg_batch_size": 31.887394957983194
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.44962406735738364,
      "energy_per_request_joules": 421.52256314754715,
      "avg_output_len": 937.5,
      "avg_power_watts": 488.28703654608444,
      "median_itl_ms": 42.69243701128289,
      "output_throughput_tokens_per_sec": 1085.9895454794896,
      "p90_itl_ms": 117.21614279085792,
      "p95_itl_ms": 182.3936978937126,
      "p99_itl_ms": 255.83262700019986,
      "avg_batch_size": 63.7801724137931
    },
    {
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.5158183051415683,
      "energy_per_request_joules": 1421.1255501009423,
      "avg_output_len": 937.5302734375,
      "avg_power_watts": 752.7204611715797,
      "median_itl_ms": 14.732362993527204,
      "output_throughput_tokens_per_sec": 496.57697008829837,
      "p90_itl_ms": 20.12159880832769,
      "p95_itl_ms": 23.313267764751792,
      "p99_itl_ms": 79.94683048862485,
      "avg_batch_size": 7.936046511627907
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.20695072724694275,
      "energy_per_request_joules": 194.98638832797886,
      "avg_output_len": 942.1875,
      "avg_power_watts": 289.62053499686857,
      "median_itl_ms": 52.228585991542786,
      "output_throughput_tokens_per_sec": 1399.4661379047996,
      "p90_itl_ms": 166.74661838915205,
      "p95_itl_ms": 253.4637969334047,
      "p99_itl_ms": 780.0225611645146,
      "avg_batch_size": 127.55732484076434
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6312353189470197,
      "energy_per_request_joules": 603.0023330019284,
      "avg_output_len": 955.2734375,
      "avg_power_watts": 282.68819477699634,
      "median_itl_ms": 32.089781016111374,
      "output_throughput_tokens_per_sec": 447.83329812494645,
      "p90_itl_ms": 55.76749548781663,
      "p95_itl_ms": 68.35664511309004,
      "p99_itl_ms": 180.88082516624175,
      "avg_batch_size": 15.94021164021164
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.16829500544768744,
      "energy_per_request_joules": 155.78003662461077,
      "avg_output_len": 925.63671875,
      "avg_power_watts": 325.2725089918981,
      "median_itl_ms": 60.518994490848854,
      "output_throughput_tokens_per_sec": 1932.7520037010568,
      "p90_itl_ms": 277.7092106840236,
      "p95_itl_ms": 364.32525917189196,
      "p99_itl_ms": 626.9177863393414,
      "avg_batch_size": 255.29516994633275
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.383054083653863,
      "energy_per_request_joules": 357.36065617752945,
      "avg_output_len": 932.9248046875,
      "avg_power_watts": 290.63163915638285,
      "median_itl_ms": 34.897213510703295,
      "output_throughput_tokens_per_sec": 758.7222054497262,
      "p90_itl_ms": 57.76914777816273,
      "p95_itl_ms": 98.44404962786906,
      "p99_itl_ms": 182.92072181850241,
      "avg_batch_size": 31.91122448979592
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.14135040160728374,
      "energy_per_request_joules": 132.25863058515196,
      "avg_output_len": 935.67919921875,
      "avg_power_watts": 325.28807295011046,
      "median_itl_ms": 14.800973003730178,
      "output_throughput_tokens_per_sec": 2301.288636263404,
      "p90_itl_ms": 172.52519720889032,
      "p95_itl_ms": 232.79822722128907,
      "p99_itl_ms": 434.6160585987789,
      "avg_batch_size": 463.2475247524753
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.24435960446654412,
      "energy_per_request_joules": 231.4701125957864,
      "avg_output_len": 947.251953125,
      "avg_power_watts": 311.19105204501153,
      "median_itl_ms": 41.61818098509684,
      "output_throughput_tokens_per_sec": 1273.4962995392207,
      "p90_itl_ms": 91.15315251983702,
      "p95_itl_ms": 112.03772376211879,
      "p99_itl_ms": 203.1401294048528,
      "avg_batch_size": 63.674698795180724
    },
    {
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.45809503674383617,
      "energy_per_request_joules": 424.10429554575666,
      "avg_output_len": 925.7998046875,
      "avg_power_watts": 512.5639130511224,
      "median_itl_ms": 5.299770040437579,
      "output_throughput_tokens_per_sec": 1118.903004700627,
      "p90_itl_ms": 11.079268972389407,
      "p95_itl_ms": 21.11090809957474,
      "p99_itl_ms": 74.37362268799912,
      "avg_batch_size": 7.859649122807017
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.19137708306363999,
      "energy_per_request_joules": 101.35715315916693,
      "avg_output_len": 529.6201171875,
      "avg_power_watts": 525.802704106066,
      "median_itl_ms": 35.87140850140713,
      "output_throughput_tokens_per_sec": 2747.4695281629783,
      "p90_itl_ms": 79.39596714318863,
      "p95_itl_ms": 92.9053347179433,
      "p99_itl_ms": 142.6742428046417,
      "avg_batch_size": 127.47590361445783
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4514933452273493,
      "energy_per_request_joules": 240.49560219492471,
      "avg_output_len": 532.6669921875,
      "avg_power_watts": 554.4509143279543,
      "median_itl_ms": 8.84280147147365,
      "output_throughput_tokens_per_sec": 1228.0378441652572,
      "p90_itl_ms": 28.82431148318574,
      "p95_itl_ms": 40.124990956974216,
      "p99_itl_ms": 59.95463541534264,
      "avg_batch_size": 15.857142857142858
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1463149048699786,
      "energy_per_request_joules": 78.8644481531649,
      "avg_output_len": 539.0048828125,
      "avg_power_watts": 649.0231079348919,
      "median_itl_ms": 41.645514516858384,
      "output_throughput_tokens_per_sec": 4435.796260891125,
      "p90_itl_ms": 88.72921792208217,
      "p95_itl_ms": 113.44818952202326,
      "p99_itl_ms": 162.08382075768864,
      "avg_batch_size": 255.31521739130434
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.34969035375233337,
      "energy_per_request_joules": 187.92714764915925,
      "avg_output_len": 537.41015625,
      "avg_power_watts": 398.7460900266329,
      "median_itl_ms": 25.237522029783577,
      "output_throughput_tokens_per_sec": 1140.283355682848,
      "p90_itl_ms": 44.42424979060888,
      "p95_itl_ms": 57.06101502291857,
      "p99_itl_ms": 82.33455836307249,
      "avg_batch_size": 31.8641425389755
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.12297747167278943,
      "energy_per_request_joules": 65.18958912454772,
      "avg_output_len": 530.09375,
      "avg_power_watts": 691.2295518481587,
      "median_itl_ms": 49.38627599040046,
      "output_throughput_tokens_per_sec": 5620.7819403487,
      "p90_itl_ms": 131.07796298572794,
      "p95_itl_ms": 161.44461400108412,
      "p99_itl_ms": 610.4729225859047,
      "avg_batch_size": 510.5217391304348
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2317180019997705,
      "energy_per_request_joules": 121.23445132947953,
      "avg_output_len": 523.1982421875,
      "avg_power_watts": 468.1481972713291,
      "median_itl_ms": 25.61959798913449,
      "output_throughput_tokens_per_sec": 2020.335896352985,
      "p90_itl_ms": 57.429234974551946,
      "p95_itl_ms": 69.77384284837171,
      "p99_itl_ms": 91.80671799753323,
      "avg_batch_size": 63.71729957805907
    },
    {
      "model_id": "google/gemma-3-12b-it",
      "nickname": "Gemma 3 12B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6860563192459176,
      "energy_per_request_joules": 363.59979954722235,
      "avg_output_len": 529.9853515625,
      "avg_power_watts": 640.0422817127618,
      "median_itl_ms": 7.752049015834928,
      "output_throughput_tokens_per_sec": 932.9296498810297,
      "p90_itl_ms": 11.765619774814697,
      "p95_itl_ms": 13.347673311363904,
      "p99_itl_ms": 46.99876549420879,
      "avg_batch_size": 7.919499105545617
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.26803995607851805,
      "energy_per_request_joules": 138.31254370305942,
      "avg_output_len": 516.0146484375,
      "avg_power_watts": 772.126155148733,
      "median_itl_ms": 35.068084951490164,
      "output_throughput_tokens_per_sec": 2880.6382691786107,
      "p90_itl_ms": 80.87856239872053,
      "p95_itl_ms": 90.52900400711222,
      "p99_itl_ms": 134.94752123486245,
      "avg_batch_size": 127.48936170212765
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7408962056580775,
      "energy_per_request_joules": 377.62408775844966,
      "avg_output_len": 509.685546875,
      "avg_power_watts": 797.189881233601,
      "median_itl_ms": 13.289485999848694,
      "output_throughput_tokens_per_sec": 1075.9805154158166,
      "p90_itl_ms": 18.81131682312116,
      "p95_itl_ms": 24.482827031170004,
      "p99_itl_ms": 59.25326385011432,
      "avg_batch_size": 15.895744680851063
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2140819868417665,
      "energy_per_request_joules": 110.19807553347847,
      "avg_output_len": 514.7470703125,
      "avg_power_watts": 753.8349470899001,
      "median_itl_ms": 49.42485201172531,
      "output_throughput_tokens_per_sec": 3521.2441654284485,
      "p90_itl_ms": 113.15136163630673,
      "p95_itl_ms": 144.33703138492987,
      "p99_itl_ms": 205.0018311175519,
      "avg_batch_size": 255.2314814814815
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.48832389780253654,
      "energy_per_request_joules": 250.1625149228008,
      "avg_output_len": 512.2880859375,
      "avg_power_watts": 707.7855841819114,
      "median_itl_ms": 16.96080350666307,
      "output_throughput_tokens_per_sec": 1449.418280299111,
      "p90_itl_ms": 36.71236502123065,
      "p95_itl_ms": 54.692690770025365,
      "p99_itl_ms": 73.95493055228144,
      "avg_batch_size": 31.777126099706745
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3443395784298752,
      "energy_per_request_joules": 177.1569965271383,
      "avg_output_len": 514.4833984375,
      "avg_power_watts": 745.6030049821956,
      "median_itl_ms": 24.24428501399234,
      "output_throughput_tokens_per_sec": 2165.3131144029603,
      "p90_itl_ms": 56.331105006393045,
      "p95_itl_ms": 68.00306850345805,
      "p99_itl_ms": 94.64244400151088,
      "avg_batch_size": 63.694063926940636
    },
    {
      "model_id": "google/gemma-3-27b-it",
      "nickname": "Gemma 3 27B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 27.0,
      "activated_params_billions": 27.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.3714456993468844,
      "energy_per_request_joules": 707.6258017897693,
      "avg_output_len": 515.970703125,
      "avg_power_watts": 800.2625626611331,
      "median_itl_ms": 13.052733964286745,
      "output_throughput_tokens_per_sec": 583.5174976612179,
      "p90_itl_ms": 16.709388990420848,
      "p95_itl_ms": 18.76976602943614,
      "p99_itl_ms": 56.04544321540737,
      "avg_batch_size": 7.9344632768361585
    }
  ]
}