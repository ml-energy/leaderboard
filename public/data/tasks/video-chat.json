{
  "configurations": [
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 7.601918465227818,
      "avg_output_len": 524.3671875,
      "avg_power_watts": 596.0779255810396,
      "data_parallel": 1,
      "energy_per_request_joules": 643.8487155239341,
      "energy_per_token_joules": 1.227858513789889,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 8.85124399792403,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 485.4614101597055,
      "p90_itl_ms": 14.391375216655431,
      "p95_itl_ms": 23.084642214234872,
      "p99_itl_ms": 248.34474463308433,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 15.662691652470187,
      "avg_output_len": 529.984375,
      "avg_power_watts": 401.28209756546823,
      "data_parallel": 1,
      "energy_per_request_joules": 674.647675944918,
      "energy_per_token_joules": 1.2729576715255388,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 31.6273290081881,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 315.23601023163906,
      "p90_itl_ms": 58.86483901413158,
      "p95_itl_ms": 111.91137990301367,
      "p99_itl_ms": 560.5852410336933,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 31.522935779816514,
      "avg_output_len": 548.5546875,
      "avg_power_watts": 499.8666448861053,
      "data_parallel": 1,
      "energy_per_request_joules": 529.110449536752,
      "energy_per_token_joules": 0.9645536928107136,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 32.24240301642567,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 518.2362045906349,
      "p90_itl_ms": 115.5510469921868,
      "p95_itl_ms": 224.49670447385856,
      "p99_itl_ms": 650.0244709663092,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 63.41152263374486,
      "avg_output_len": 571.009765625,
      "avg_power_watts": 613.4992334563216,
      "data_parallel": 1,
      "energy_per_request_joules": 476.21005908073886,
      "energy_per_token_joules": 0.8339788349495251,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 30.170794489094988,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 735.6292602958592,
      "p90_itl_ms": 150.04531070007945,
      "p95_itl_ms": 434.9756326526378,
      "p99_itl_ms": 602.7392916404641,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 120.96517412935323,
      "avg_output_len": 564.33203125,
      "avg_power_watts": 582.6223383249582,
      "data_parallel": 1,
      "energy_per_request_joules": 503.82444633849826,
      "energy_per_token_joules": 0.8927801691896223,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 128,
      "median_itl_ms": 49.99590094666928,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 652.5932793218349,
      "p90_itl_ms": 417.4146403791382,
      "p95_itl_ms": 474.75402420968743,
      "p99_itl_ms": 790.5360910121806,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 7.925496688741722,
      "avg_output_len": 538.5546875,
      "avg_power_watts": 679.0102683266322,
      "data_parallel": 1,
      "energy_per_request_joules": 830.3354325942282,
      "energy_per_token_joules": 1.5417848026700691,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 10.46493835747242,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 440.40534525357845,
      "p90_itl_ms": 11.183231323957445,
      "p95_itl_ms": 34.193546036785506,
      "p99_itl_ms": 224.5547804608941,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 15.942913385826772,
      "avg_output_len": 625.158203125,
      "avg_power_watts": 722.0384877777277,
      "data_parallel": 1,
      "energy_per_request_joules": 757.6091620558154,
      "energy_per_token_joules": 1.2118679052257944,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 13.432415202260017,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 595.8062629302804,
      "p90_itl_ms": 16.05837270617485,
      "p95_itl_ms": 76.11353322863555,
      "p99_itl_ms": 513.2346887513994,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 31.824797843665767,
      "avg_output_len": 501.97265625,
      "avg_power_watts": 733.6933703843687,
      "data_parallel": 1,
      "energy_per_request_joules": 606.6865928418816,
      "energy_per_token_joules": 1.2086048618148841,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 32,
      "median_itl_ms": 19.38694342970848,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 607.058099437585,
      "p90_itl_ms": 95.565502345562,
      "p95_itl_ms": 209.19484533369538,
      "p99_itl_ms": 648.4532910771669,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 63.81,
      "avg_output_len": 518.1015625,
      "avg_power_watts": 752.1417882120411,
      "data_parallel": 1,
      "energy_per_request_joules": 579.2939367681322,
      "energy_per_token_joules": 1.1181088394577698,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 64,
      "median_itl_ms": 26.110410690307617,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 672.691031203004,
      "p90_itl_ms": 219.68999318778515,
      "p95_itl_ms": 390.18275309354067,
      "p99_itl_ms": 672.8929236531258,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 91.028,
      "avg_output_len": 517.541015625,
      "avg_power_watts": 768.9023712708045,
      "data_parallel": 1,
      "energy_per_request_joules": 524.6241033542124,
      "energy_per_token_joules": 1.0136860413288376,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 96,
      "median_itl_ms": 32.201096415519714,
      "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "nickname": "Qwen 3 Omni 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 758.5212185252674,
      "p90_itl_ms": 265.41058365255594,
      "p95_itl_ms": 400.1459080725908,
      "p99_itl_ms": 685.993788857013,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 7.985915492957746,
      "avg_output_len": 377.298828125,
      "avg_power_watts": 2334.7732537119155,
      "data_parallel": 1,
      "energy_per_request_joules": 2310.5693556495808,
      "energy_per_token_joules": 6.123977026729814,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 17.790863508707844,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 381.2511450518419,
      "p90_itl_ms": 18.695308396127075,
      "p95_itl_ms": 19.285486543958537,
      "p99_itl_ms": 117.93712268437957,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 15.942307692307692,
      "avg_output_len": 380.716796875,
      "avg_power_watts": 2543.4343872570234,
      "data_parallel": 1,
      "energy_per_request_joules": 1608.1970127636039,
      "energy_per_token_joules": 4.224129394773249,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 20.764724002219737,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 602.1203778473634,
      "p90_itl_ms": 22.50534738996066,
      "p95_itl_ms": 29.094049299601462,
      "p99_itl_ms": 155.66525868431194,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 31.946859903381643,
      "avg_output_len": 381.71875,
      "avg_power_watts": 2631.460354624241,
      "data_parallel": 1,
      "energy_per_request_joules": 1119.7535792416243,
      "energy_per_token_joules": 2.9334518653894373,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 24.52437998726964,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 897.0525085724886,
      "p90_itl_ms": 38.93663820344955,
      "p95_itl_ms": 114.47994060872578,
      "p99_itl_ms": 182.4846230726689,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 63.81578947368421,
      "avg_output_len": 379.662109375,
      "avg_power_watts": 2566.607405140285,
      "data_parallel": 1,
      "energy_per_request_joules": 841.4352981433595,
      "energy_per_token_joules": 2.2162740957440574,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 35.89041100349277,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 1158.0730966756223,
      "p90_itl_ms": 114.96271319920199,
      "p95_itl_ms": 154.0225620003184,
      "p99_itl_ms": 350.97230984422043,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 95.6864406779661,
      "avg_output_len": 378.927734375,
      "avg_power_watts": 2628.620540654103,
      "data_parallel": 1,
      "energy_per_request_joules": 697.2744968528215,
      "energy_per_token_joules": 1.8401252629420217,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 96,
      "median_itl_ms": 38.49873199942522,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 1428.5008708871387,
      "p90_itl_ms": 135.10058599640618,
      "p95_itl_ms": 161.8967929156497,
      "p99_itl_ms": 415.910369126359,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 127.65656565656566,
      "avg_output_len": 386.529296875,
      "avg_power_watts": 2642.485649524207,
      "data_parallel": 1,
      "energy_per_request_joules": 610.2373446948034,
      "energy_per_token_joules": 1.578760910565981,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 128,
      "median_itl_ms": 42.33424799167551,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 1673.7719003803331,
      "p90_itl_ms": 138.36632898892276,
      "p95_itl_ms": 160.04082400468178,
      "p99_itl_ms": 488.0457924009534,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 191.64,
      "avg_output_len": 376.333984375,
      "avg_power_watts": 2611.451734501111,
      "data_parallel": 1,
      "energy_per_request_joules": 517.108091776864,
      "energy_per_token_joules": 1.3740669544783626,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 192,
      "median_itl_ms": 47.39055599202402,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 1900.5272821603494,
      "p90_itl_ms": 164.87261801376007,
      "p95_itl_ms": 328.074534991174,
      "p99_itl_ms": 572.6914688129909,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 255.4406779661017,
      "avg_output_len": 387.73828125,
      "avg_power_watts": 2832.2705843905715,
      "data_parallel": 1,
      "energy_per_request_joules": 494.62189406825917,
      "energy_per_token_joules": 1.2756591700816469,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 256,
      "median_itl_ms": 50.479355006245896,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 2220.2408376912276,
      "p90_itl_ms": 184.21908398740928,
      "p95_itl_ms": 395.87657145020785,
      "p99_itl_ms": 589.7295008591027,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 383.3333333333333,
      "avg_output_len": 378.291015625,
      "avg_power_watts": 2753.86572841724,
      "data_parallel": 1,
      "energy_per_request_joules": 351.10548386076545,
      "energy_per_token_joules": 0.9281359306952625,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 384,
      "median_itl_ms": 55.93450050218962,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 2967.093113564014,
      "p90_itl_ms": 368.79379790043447,
      "p95_itl_ms": 500.52490580274025,
      "p99_itl_ms": 720.0335611097398,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 510.79487179487177,
      "avg_output_len": 381.4130859375,
      "avg_power_watts": 2549.9441998567413,
      "data_parallel": 1,
      "energy_per_request_joules": 297.4158093483731,
      "energy_per_token_joules": 0.7797734800245132,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 512,
      "median_itl_ms": 67.05479801166803,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 3270.108903647993,
      "p90_itl_ms": 317.218457988929,
      "p95_itl_ms": 464.75054702023044,
      "p99_itl_ms": 680.9233905223664,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 1020.5972222222222,
      "avg_output_len": 385.2236328125,
      "avg_power_watts": 2262.71695478055,
      "data_parallel": 1,
      "energy_per_request_joules": 181.51268977156283,
      "energy_per_token_joules": 0.4711878356121275,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 1024,
      "median_itl_ms": 112.58713295683265,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 4802.154860048581,
      "p90_itl_ms": 350.7800048217178,
      "p95_itl_ms": 528.5258024116048,
      "p99_itl_ms": 1369.0475731645731,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 7.984581497797357,
      "avg_output_len": 383.91796875,
      "avg_power_watts": 3638.287375858578,
      "data_parallel": 1,
      "energy_per_request_joules": 3300.287054288703,
      "energy_per_token_joules": 8.596333912252454,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 15.9017514961306,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 423.2370930441504,
      "p90_itl_ms": 16.456768504576758,
      "p95_itl_ms": 16.894307141774338,
      "p99_itl_ms": 115.30485481023788,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 15.96376811594203,
      "avg_output_len": 383.869140625,
      "avg_power_watts": 3931.4243366014994,
      "data_parallel": 1,
      "energy_per_request_joules": 2185.570524178384,
      "energy_per_token_joules": 5.693530145767715,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 17.387792991939932,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 690.5073365641039,
      "p90_itl_ms": 18.34036159561947,
      "p95_itl_ms": 28.351925598690315,
      "p99_itl_ms": 156.8107694061473,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 31.934272300469484,
      "avg_output_len": 380.48046875,
      "avg_power_watts": 3862.4839769127148,
      "data_parallel": 1,
      "energy_per_request_joules": 1688.3175483782704,
      "energy_per_token_joules": 4.437330394185366,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 26.174415004788898,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 870.4521939529398,
      "p90_itl_ms": 39.08818598429232,
      "p95_itl_ms": 115.72142304648878,
      "p99_itl_ms": 161.62300022318965,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 63.89855072463768,
      "avg_output_len": 386.029296875,
      "avg_power_watts": 3990.2588090399813,
      "data_parallel": 1,
      "energy_per_request_joules": 1181.608433372022,
      "energy_per_token_joules": 3.0609294241069955,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 29.142113984562457,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1303.6101968290598,
      "p90_itl_ms": 116.9084300112445,
      "p95_itl_ms": 144.06362499285024,
      "p99_itl_ms": 366.8051133886911,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 95.78181818181818,
      "avg_output_len": 380.8515625,
      "avg_power_watts": 4009.1341285456188,
      "data_parallel": 1,
      "energy_per_request_joules": 981.9112085363067,
      "energy_per_token_joules": 2.5781992388079193,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 96,
      "median_itl_ms": 32.29318099329248,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1555.0133085910459,
      "p90_itl_ms": 136.0518129862613,
      "p95_itl_ms": 157.83089731121436,
      "p99_itl_ms": 399.1331200784771,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 127.6,
      "avg_output_len": 381.615234375,
      "avg_power_watts": 4156.92028483182,
      "data_parallel": 1,
      "energy_per_request_joules": 839.9749163177703,
      "energy_per_token_joules": 2.2011042554248665,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 128,
      "median_itl_ms": 32.79231599299237,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1888.5612867208024,
      "p90_itl_ms": 138.19999402039684,
      "p95_itl_ms": 156.66199699626304,
      "p99_itl_ms": 408.85872680228204,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 191.57746478873239,
      "avg_output_len": 385.212890625,
      "avg_power_watts": 4110.865766820854,
      "data_parallel": 1,
      "energy_per_request_joules": 747.0639665427764,
      "energy_per_token_joules": 1.9393534970511512,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 192,
      "median_itl_ms": 37.95323500526138,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 2119.7093634922962,
      "p90_itl_ms": 149.6630776033271,
      "p95_itl_ms": 324.183666810859,
      "p99_itl_ms": 563.5357807204126,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 255.44827586206895,
      "avg_output_len": 385.59375,
      "avg_power_watts": 4115.575081117097,
      "data_parallel": 1,
      "energy_per_request_joules": 690.4652871343021,
      "energy_per_token_joules": 1.7906547684818597,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 256,
      "median_itl_ms": 40.394861993263476,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 2298.3632320183838,
      "p90_itl_ms": 191.38873530027922,
      "p95_itl_ms": 374.5236397124244,
      "p99_itl_ms": 659.4017398840515,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 383.4375,
      "avg_output_len": 390.234375,
      "avg_power_watts": 4437.74039058493,
      "data_parallel": 1,
      "energy_per_request_joules": 513.1163293831296,
      "energy_per_token_joules": 1.3148926959167284,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 384,
      "median_itl_ms": 48.79362949577626,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 3374.982920177366,
      "p90_itl_ms": 312.4677020008676,
      "p95_itl_ms": 456.29502620286064,
      "p99_itl_ms": 671.3844672380947,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 510.76,
      "avg_output_len": 377.8095703125,
      "avg_power_watts": 3965.3273351227085,
      "data_parallel": 1,
      "energy_per_request_joules": 442.9635749592199,
      "energy_per_token_joules": 1.1724519698980327,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 512,
      "median_itl_ms": 58.57918749097735,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 3382.0808331002,
      "p90_itl_ms": 312.3044540116098,
      "p95_itl_ms": 408.9348109846469,
      "p99_itl_ms": 728.4172431624028,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 1021.7027027027027,
      "avg_output_len": 389.8645833333333,
      "avg_power_watts": 3692.4743032518077,
      "data_parallel": 1,
      "energy_per_request_joules": 323.20716590874054,
      "energy_per_token_joules": 0.8290241784604455,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 1024,
      "median_itl_ms": 104.58883398678154,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 4454.000738686517,
      "p90_itl_ms": 479.853661172092,
      "p95_itl_ms": 726.7398947733454,
      "p99_itl_ms": 1147.3410804755981,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 2045.0365853658536,
      "avg_output_len": 385.885546875,
      "avg_power_watts": 3842.146900235733,
      "data_parallel": 1,
      "energy_per_request_joules": 238.96796250255068,
      "energy_per_token_joules": 0.6192716064070667,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 2048,
      "median_itl_ms": 152.1009660209529,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 6204.30011724156,
      "p90_itl_ms": 742.624689085642,
      "p95_itl_ms": 1126.9983186939498,
      "p99_itl_ms": 3059.327720644651,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 3066.1472868217056,
      "avg_output_len": 384.25,
      "avg_power_watts": 3642.064878615327,
      "data_parallel": 1,
      "energy_per_request_joules": 217.96766957808012,
      "energy_per_token_joules": 0.567254832994353,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 3072,
      "median_itl_ms": 222.42623998317868,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 6420.50920816321,
      "p90_itl_ms": 973.2442178064956,
      "p95_itl_ms": 1762.237764778546,
      "p99_itl_ms": 4433.708593406479,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 4089.5833333333335,
      "avg_output_len": 384.7779296875,
      "avg_power_watts": 3545.8220560345835,
      "data_parallel": 1,
      "energy_per_request_joules": 221.2742035478133,
      "energy_per_token_joules": 0.5750698948027572,
      "expert_parallel": 8,
      "gpu_model": "B200",
      "max_num_seqs": 4096,
      "median_itl_ms": 286.641601996962,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 6165.89755102858,
      "p90_itl_ms": 1346.9895740272477,
      "p95_itl_ms": 2237.4394919606857,
      "p99_itl_ms": 6889.903472375573,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 7.989208633093525,
      "avg_output_len": 382.75390625,
      "avg_power_watts": 2423.122327007602,
      "data_parallel": 1,
      "energy_per_request_joules": 2680.186538249968,
      "energy_per_token_joules": 7.002375402275775,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 19.916090182960033,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 346.04290512903464,
      "p90_itl_ms": 20.717543549835682,
      "p95_itl_ms": 21.187858935445544,
      "p99_itl_ms": 115.17341531813143,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 15.94,
      "avg_output_len": 392.939453125,
      "avg_power_watts": 2650.8178916515485,
      "data_parallel": 1,
      "energy_per_request_joules": 1903.0491021543146,
      "energy_per_token_joules": 4.843110273146651,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 23.27077742666006,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 547.3379176083197,
      "p90_itl_ms": 27.516807056963447,
      "p95_itl_ms": 39.34421110898256,
      "p99_itl_ms": 176.18074720725414,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 31.85169491525424,
      "avg_output_len": 382.3046875,
      "avg_power_watts": 2818.807446824767,
      "data_parallel": 1,
      "energy_per_request_joules": 1380.5728261319587,
      "energy_per_token_joules": 3.6111846683333138,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 32,
      "median_itl_ms": 30.75464814901352,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 780.5769313164878,
      "p90_itl_ms": 44.30460461622311,
      "p95_itl_ms": 111.96136474609375,
      "p99_itl_ms": 189.18913180326544,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 58.20666666666666,
      "avg_output_len": 379.5546875,
      "avg_power_watts": 2973.054572810144,
      "data_parallel": 1,
      "energy_per_request_joules": 1008.6497601593793,
      "energy_per_token_joules": 2.6574556799786047,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 64,
      "median_itl_ms": 36.77103668451309,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "nickname": "Qwen 3 VL 235B A22B Instruct",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1118.7597953972577,
      "p90_itl_ms": 85.20809523761272,
      "p95_itl_ms": 149.49215855449438,
      "p99_itl_ms": 378.4795222617686,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 7.976112920738328,
      "avg_output_len": 377.830078125,
      "avg_power_watts": 1714.6205549598012,
      "data_parallel": 1,
      "energy_per_request_joules": 3186.6725360015303,
      "energy_per_token_joules": 8.434142013826815,
      "expert_parallel": 2,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 36.07554896734655,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 203.2951961383714,
      "p90_itl_ms": 37.120166793465614,
      "p95_itl_ms": 38.67349200882017,
      "p99_itl_ms": 152.07633308134973,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 15.970817120622568,
      "avg_output_len": 369.8203125,
      "avg_power_watts": 1679.341785321032,
      "data_parallel": 1,
      "energy_per_request_joules": 1756.205754253806,
      "energy_per_token_joules": 4.748808258750811,
      "expert_parallel": 2,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 39.50015996815637,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 353.6343633639965,
      "p90_itl_ms": 41.228650393895805,
      "p95_itl_ms": 56.1849737889133,
      "p99_itl_ms": 158.6276483815163,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 31.918727915194346,
      "avg_output_len": 379.265625,
      "avg_power_watts": 1681.0892386257613,
      "data_parallel": 1,
      "energy_per_request_joules": 1021.4163959658256,
      "energy_per_token_joules": 2.6931425592968665,
      "expert_parallel": 2,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 40.278069471241906,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 624.211010598958,
      "p90_itl_ms": 57.06962830061505,
      "p95_itl_ms": 146.47187076043335,
      "p99_itl_ms": 214.82953566766818,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 63.80952380952381,
      "avg_output_len": 373.529296875,
      "avg_power_watts": 1645.0282379288471,
      "data_parallel": 1,
      "energy_per_request_joules": 617.9284737975834,
      "energy_per_token_joules": 1.654297210331993,
      "expert_parallel": 2,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 43.56203551287763,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 994.3970331659535,
      "p90_itl_ms": 154.49412477319126,
      "p95_itl_ms": 163.9798221149249,
      "p99_itl_ms": 349.46412386139855,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 127.58620689655173,
      "avg_output_len": 380.03125,
      "avg_power_watts": 1489.8101870747066,
      "data_parallel": 1,
      "energy_per_request_joules": 436.8374688733865,
      "energy_per_token_joules": 1.1494777570880987,
      "expert_parallel": 2,
      "gpu_model": "B200",
      "max_num_seqs": 128,
      "median_itl_ms": 52.49525350518525,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 1296.0756986274803,
      "p90_itl_ms": 209.12953052902594,
      "p95_itl_ms": 249.40899024659302,
      "p99_itl_ms": 463.4768351446837,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 255.16964285714286,
      "avg_output_len": 374.583984375,
      "avg_power_watts": 1560.8126682714665,
      "data_parallel": 1,
      "energy_per_request_joules": 241.99007032916535,
      "energy_per_token_joules": 0.6460235365719922,
      "expert_parallel": 2,
      "gpu_model": "B200",
      "max_num_seqs": 256,
      "median_itl_ms": 64.65166801353917,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 2416.030655096002,
      "p90_itl_ms": 183.48222348140553,
      "p95_itl_ms": 265.11616799689364,
      "p99_itl_ms": 488.3435902651399,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 7.984423676012461,
      "avg_output_len": 375.41796875,
      "avg_power_watts": 2776.7481754618007,
      "data_parallel": 1,
      "energy_per_request_joules": 3632.0802964345007,
      "energy_per_token_joules": 9.674764126309553,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 24.20118250302039,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 287.00939260221463,
      "p90_itl_ms": 25.337959406897426,
      "p95_itl_ms": 26.597454940201725,
      "p99_itl_ms": 157.5687032879796,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 15.96524064171123,
      "avg_output_len": 386.0,
      "avg_power_watts": 2725.6522080905324,
      "data_parallel": 1,
      "energy_per_request_joules": 2131.9774357472193,
      "energy_per_token_joules": 5.523257605562744,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 26.079473027493805,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 493.4863449688449,
      "p90_itl_ms": 27.346700022462755,
      "p95_itl_ms": 42.2866714943666,
      "p99_itl_ms": 188.50841210223734,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 31.937219730941703,
      "avg_output_len": 378.22265625,
      "avg_power_watts": 2646.1417748364524,
      "data_parallel": 1,
      "energy_per_request_joules": 1260.578666529162,
      "energy_per_token_joules": 3.3329009928372373,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 27.396665507694706,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 793.9455088894916,
      "p90_itl_ms": 41.6842607728375,
      "p95_itl_ms": 152.85091531986825,
      "p99_itl_ms": 241.70232362637762,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 63.83916083916084,
      "avg_output_len": 379.560546875,
      "avg_power_watts": 2557.2638186207205,
      "data_parallel": 1,
      "energy_per_request_joules": 849.3988942847766,
      "energy_per_token_joules": 2.2378482202063736,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 31.425428460352123,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 1142.733361239705,
      "p90_itl_ms": 153.67510789074004,
      "p95_itl_ms": 174.7840708616422,
      "p99_itl_ms": 354.7604245168621,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 127.65979381443299,
      "avg_output_len": 383.33984375,
      "avg_power_watts": 2537.4147022279444,
      "data_parallel": 1,
      "energy_per_request_joules": 606.1292633483552,
      "energy_per_token_joules": 1.5811799196737037,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 128,
      "median_itl_ms": 36.71877449960448,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 1604.7602620399907,
      "p90_itl_ms": 172.84294190467335,
      "p95_itl_ms": 210.44911423523442,
      "p99_itl_ms": 390.733182936674,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 255.38738738738738,
      "avg_output_len": 385.5693359375,
      "avg_power_watts": 2541.7998031413263,
      "data_parallel": 1,
      "energy_per_request_joules": 348.5630384594555,
      "energy_per_token_joules": 0.9040216790371444,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 256,
      "median_itl_ms": 46.32795200450346,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 2811.6580189189126,
      "p90_itl_ms": 185.54557461757219,
      "p95_itl_ms": 257.9906574799679,
      "p99_itl_ms": 438.60532706952665,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 510.52054794520546,
      "avg_output_len": 378.5595703125,
      "avg_power_watts": 2347.1924261831723,
      "data_parallel": 1,
      "energy_per_request_joules": 302.1846570531004,
      "energy_per_token_joules": 0.7982486265071774,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 512,
      "median_itl_ms": 59.35815899283625,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 2940.4277667893584,
      "p90_itl_ms": 308.25426237424847,
      "p95_itl_ms": 446.11791768693365,
      "p99_itl_ms": 722.9064582136925,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 1022.0952380952381,
      "avg_output_len": 375.1985677083333,
      "avg_power_watts": 2249.9275998580074,
      "data_parallel": 1,
      "energy_per_request_joules": 179.68768755797885,
      "energy_per_token_joules": 0.47891357543150853,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 1024,
      "median_itl_ms": 141.6950699640438,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 4697.982507242122,
      "p90_itl_ms": 389.6163507946767,
      "p95_itl_ms": 569.8060530005024,
      "p99_itl_ms": 1226.056873924099,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 2043.5157894736842,
      "avg_output_len": 374.6832682291667,
      "avg_power_watts": 2379.8911352858463,
      "data_parallel": 1,
      "energy_per_request_joules": 135.80425215384392,
      "energy_per_token_joules": 0.3624508049043233,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 2048,
      "median_itl_ms": 179.37046545557678,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 6566.1080154424535,
      "p90_itl_ms": 541.8307184765581,
      "p95_itl_ms": 920.4468832118437,
      "p99_itl_ms": 2398.490423830808,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 3066.4444444444443,
      "avg_output_len": 381.69970703125,
      "avg_power_watts": 2208.4837873582583,
      "data_parallel": 1,
      "energy_per_request_joules": 113.11860021724095,
      "energy_per_token_joules": 0.2963549568770821,
      "expert_parallel": 4,
      "gpu_model": "B200",
      "max_num_seqs": 3072,
      "median_itl_ms": 227.6028159831185,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 7452.157408233473,
      "p90_itl_ms": 782.4693614966236,
      "p95_itl_ms": 1136.1283359728986,
      "p99_itl_ms": 5576.130479585845,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 7.9820426487093155,
      "avg_output_len": 382.16796875,
      "avg_power_watts": 1992.5007149586218,
      "data_parallel": 1,
      "energy_per_request_joules": 3559.4395544657687,
      "energy_per_token_joules": 9.313809229245534,
      "expert_parallel": 4,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 34.07779149711132,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 213.92973228420146,
      "p90_itl_ms": 34.90799479186535,
      "p95_itl_ms": 35.836057644337416,
      "p99_itl_ms": 136.02780075743794,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 15.936863543788187,
      "avg_output_len": 377.783203125,
      "avg_power_watts": 1985.122179572372,
      "data_parallel": 1,
      "energy_per_request_joules": 1976.92410407938,
      "energy_per_token_joules": 5.232959241507781,
      "expert_parallel": 4,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 36.76975890994072,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 379.34982635186657,
      "p90_itl_ms": 43.09194751083851,
      "p95_itl_ms": 55.546410858284595,
      "p99_itl_ms": 182.07989819347858,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 31.838028169014084,
      "avg_output_len": 379.693359375,
      "avg_power_watts": 1989.4243020912847,
      "data_parallel": 1,
      "energy_per_request_joules": 1207.052701498068,
      "energy_per_token_joules": 3.17901978450441,
      "expert_parallel": 4,
      "gpu_model": "H100",
      "max_num_seqs": 32,
      "median_itl_ms": 40.01897946000099,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 625.7980248466506,
      "p90_itl_ms": 52.40809717743667,
      "p95_itl_ms": 132.86319999024272,
      "p99_itl_ms": 186.0312667302787,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 57.38418079096045,
      "avg_output_len": 376.904296875,
      "avg_power_watts": 2002.7624392567664,
      "data_parallel": 1,
      "energy_per_request_joules": 801.1069306256851,
      "energy_per_token_joules": 2.125491636120486,
      "expert_parallel": 4,
      "gpu_model": "H100",
      "max_num_seqs": 64,
      "median_itl_ms": 44.87311467528343,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 4,
      "output_throughput_tokens_per_sec": 942.2584428100932,
      "p90_itl_ms": 131.11179694533348,
      "p95_itl_ms": 175.74319522827864,
      "p99_itl_ms": 384.2548999935389,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 7.97029702970297,
      "avg_output_len": 369.474609375,
      "avg_power_watts": 3938.821390295262,
      "data_parallel": 1,
      "energy_per_request_joules": 4772.160668264905,
      "energy_per_token_joules": 12.916072030869593,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 22.791130002588034,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 304.955049869761,
      "p90_itl_ms": 23.267324588960037,
      "p95_itl_ms": 24.086906996672038,
      "p99_itl_ms": 146.29811371676624,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 15.958217270194986,
      "avg_output_len": 375.01171875,
      "avg_power_watts": 3872.650562333286,
      "data_parallel": 1,
      "energy_per_request_joules": 2836.6784483513784,
      "energy_per_token_joules": 7.5642394797865995,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 24.48645350523293,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 511.96826497652614,
      "p90_itl_ms": 29.196973011130478,
      "p95_itl_ms": 43.00626154022842,
      "p99_itl_ms": 177.86712085013278,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 31.87280701754386,
      "avg_output_len": 381.791015625,
      "avg_power_watts": 3826.8868956366355,
      "data_parallel": 1,
      "energy_per_request_joules": 1817.7574419514463,
      "energy_per_token_joules": 4.761132052769075,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 32,
      "median_itl_ms": 27.342385496012866,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 803.7766760556278,
      "p90_itl_ms": 47.012226496008225,
      "p95_itl_ms": 138.66247000987642,
      "p99_itl_ms": 224.028975291003,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 63.72549019607843,
      "avg_output_len": 376.998046875,
      "avg_power_watts": 3673.453153464131,
      "data_parallel": 1,
      "energy_per_request_joules": 1240.906892822889,
      "energy_per_token_joules": 3.2915472722179175,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 64,
      "median_itl_ms": 32.267368500470184,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1116.0262483451672,
      "p90_itl_ms": 108.48435974109853,
      "p95_itl_ms": 184.32328656053866,
      "p99_itl_ms": 461.3881696315366,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 95.82075471698113,
      "avg_output_len": 376.4140625,
      "avg_power_watts": 3891.7841452215234,
      "data_parallel": 1,
      "energy_per_request_joules": 1050.9133649876023,
      "energy_per_token_joules": 2.791907820892325,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 96,
      "median_itl_ms": 50.61563328950127,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1393.9515180618196,
      "p90_itl_ms": 118.64986675047679,
      "p95_itl_ms": 176.5194347462966,
      "p99_itl_ms": 422.1740821405547,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 127.68181818181819,
      "avg_output_len": 378.3828125,
      "avg_power_watts": 3855.05976062876,
      "data_parallel": 1,
      "energy_per_request_joules": 948.793052054295,
      "energy_per_token_joules": 2.507495110006602,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 128,
      "median_itl_ms": 39.5264090038836,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1537.414667428249,
      "p90_itl_ms": 161.75384360249154,
      "p95_itl_ms": 179.47819950204575,
      "p99_itl_ms": 495.5615121612209,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 187.19354838709677,
      "avg_output_len": 379.373046875,
      "avg_power_watts": 4028.589662271705,
      "data_parallel": 1,
      "energy_per_request_joules": 918.114354505937,
      "energy_per_token_joules": 2.4200832454195074,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 192,
      "median_itl_ms": 46.08554449805524,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 1664.6492098553297,
      "p90_itl_ms": 182.10384249687195,
      "p95_itl_ms": 349.426127744664,
      "p99_itl_ms": 705.0064471419319,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 230.02803738317758,
      "avg_output_len": 382.8916015625,
      "avg_power_watts": 3983.21236538479,
      "data_parallel": 1,
      "energy_per_request_joules": 593.9988793758291,
      "energy_per_token_joules": 1.5513499824802757,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 256,
      "median_itl_ms": 35.91454900742974,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 2567.5781805318284,
      "p90_itl_ms": 122.54275285401188,
      "p95_itl_ms": 190.39224099833518,
      "p99_itl_ms": 639.5702984265517,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 383.1029411764706,
      "avg_output_len": 378.953125,
      "avg_power_watts": 3821.6396145523586,
      "data_parallel": 1,
      "energy_per_request_joules": 445.9328204360638,
      "energy_per_token_joules": 1.17674928907385,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 384,
      "median_itl_ms": 18.848668492864817,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 3247.6243240904323,
      "p90_itl_ms": 119.55537149333395,
      "p95_itl_ms": 265.4446899978211,
      "p99_itl_ms": 2217.8897917474387,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "avg_batch_size": 510.35555555555555,
      "avg_output_len": 377.8255208333333,
      "avg_power_watts": 3569.0293766264836,
      "data_parallel": 1,
      "energy_per_request_joules": 176.19949027685772,
      "energy_per_token_joules": 0.46635147855611103,
      "expert_parallel": 8,
      "gpu_model": "H100",
      "max_num_seqs": 512,
      "median_itl_ms": 25.09614799055271,
      "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
      "nickname": "Qwen 3 VL 235B A22B Instruct FP8",
      "num_gpus": 8,
      "output_throughput_tokens_per_sec": 7653.089012769285,
      "p90_itl_ms": 162.8137339954266,
      "p95_itl_ms": 346.56513879599515,
      "p99_itl_ms": 1000.355607625679,
      "tensor_parallel": 1,
      "total_params_billions": 235.0,
      "weight_precision": "fp8"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 7.609523809523809,
      "avg_output_len": 218.7890625,
      "avg_power_watts": 506.06007493852144,
      "data_parallel": 1,
      "energy_per_request_joules": 181.2870370266285,
      "energy_per_token_joules": 0.8285927776971415,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 7.392533007077873,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 610.7464228025062,
      "p90_itl_ms": 11.96726281195879,
      "p95_itl_ms": 14.665227523073563,
      "p99_itl_ms": 124.33421035180803,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 15.248322147651006,
      "avg_output_len": 219.794921875,
      "avg_power_watts": 434.2615505236335,
      "data_parallel": 1,
      "energy_per_request_joules": 164.74981124726136,
      "energy_per_token_joules": 0.7495614996098797,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 9.403578995261341,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 579.3541300475696,
      "p90_itl_ms": 35.554844012949616,
      "p95_itl_ms": 127.22542467527073,
      "p99_itl_ms": 430.40842173737457,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 30.660377358490567,
      "avg_output_len": 219.462890625,
      "avg_power_watts": 381.5894568893671,
      "data_parallel": 1,
      "energy_per_request_joules": 142.79957164719028,
      "energy_per_token_joules": 0.6506775302217009,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 11.856373981572688,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 586.4494149034941,
      "p90_itl_ms": 129.52548118773848,
      "p95_itl_ms": 194.84978060936527,
      "p99_itl_ms": 444.0002342988737,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 60.325581395348834,
      "avg_output_len": 213.578125,
      "avg_power_watts": 480.26767374069954,
      "data_parallel": 1,
      "energy_per_request_joules": 91.12719122898575,
      "energy_per_token_joules": 0.4266691227342957,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 15.48803152400069,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1125.6208807961523,
      "p90_itl_ms": 161.51323600206524,
      "p95_itl_ms": 308.2753854832845,
      "p99_itl_ms": 583.61055025307,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 115.65714285714286,
      "avg_output_len": 215.392578125,
      "avg_power_watts": 555.2359988070676,
      "data_parallel": 1,
      "energy_per_request_joules": 80.20828907377387,
      "energy_per_token_joules": 0.3723818609349953,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 128,
      "median_itl_ms": 21.690961031708866,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1491.039325634586,
      "p90_itl_ms": 184.6425370022189,
      "p95_itl_ms": 250.6722886658584,
      "p99_itl_ms": 482.7739372558426,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 7.660465116279069,
      "avg_output_len": 247.576171875,
      "avg_power_watts": 471.7227248029198,
      "data_parallel": 1,
      "energy_per_request_joules": 204.1055975349236,
      "energy_per_token_joules": 0.8244153546326562,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 11.37150451540947,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 572.1906101725998,
      "p90_itl_ms": 12.870858609676368,
      "p95_itl_ms": 36.26904245465985,
      "p99_itl_ms": 99.05797149986036,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 14.0,
      "avg_output_len": 231.3984375,
      "avg_power_watts": 510.4226798387782,
      "data_parallel": 1,
      "energy_per_request_joules": 143.51511282296627,
      "energy_per_token_joules": 0.6202077869387785,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 13.435496017336845,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 822.9865709331422,
      "p90_itl_ms": 36.625515669584274,
      "p95_itl_ms": 69.81052346527575,
      "p99_itl_ms": 115.5448380112646,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 7.91764705882353,
      "avg_output_len": 230.42578125,
      "avg_power_watts": 645.8111106548201,
      "data_parallel": 1,
      "energy_per_request_joules": 221.4448859915499,
      "energy_per_token_joules": 0.961024781125918,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 8.532490581274033,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 672.0025574139726,
      "p90_itl_ms": 15.269845910370357,
      "p95_itl_ms": 33.87246084629848,
      "p99_itl_ms": 98.22231514379384,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 15.790909090909091,
      "avg_output_len": 238.26171875,
      "avg_power_watts": 698.7881909277581,
      "data_parallel": 1,
      "energy_per_request_joules": 161.29367349764985,
      "energy_per_token_joules": 0.6769600855053424,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 10.982874780893326,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 1032.2443019755312,
      "p90_itl_ms": 30.895667150616646,
      "p95_itl_ms": 70.33993507196244,
      "p99_itl_ms": 115.23135565221314,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "avg_batch_size": 29.465753424657535,
      "avg_output_len": 228.009765625,
      "avg_power_watts": 740.3049772032729,
      "data_parallel": 1,
      "energy_per_request_joules": 118.30234356706146,
      "energy_per_token_joules": 0.5188477048023871,
      "expert_parallel": 2,
      "gpu_model": "H100",
      "max_num_seqs": 32,
      "median_itl_ms": 13.912167400121689,
      "model_id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "nickname": "Qwen 3 VL 30B A3B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 1426.8251942739769,
      "p90_itl_ms": 68.14190106732505,
      "p95_itl_ms": 92.25716124978159,
      "p99_itl_ms": 256.4157932624221,
      "tensor_parallel": 1,
      "total_params_billions": 30.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 7.856812933025404,
      "avg_output_len": 541.435546875,
      "avg_power_watts": 724.1076953512859,
      "data_parallel": 1,
      "energy_per_request_joules": 890.1379908073397,
      "energy_per_token_joules": 1.6440331558297998,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 14.690289972350001,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 440.44591970884187,
      "p90_itl_ms": 19.487789401318878,
      "p95_itl_ms": 29.804065299977083,
      "p99_itl_ms": 167.5371374860384,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 15.853061224489796,
      "avg_output_len": 563.41796875,
      "avg_power_watts": 738.2140680879263,
      "data_parallel": 1,
      "energy_per_request_joules": 545.9364568711705,
      "energy_per_token_joules": 0.9689723919923713,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 16.14251799765043,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 761.8525297403295,
      "p90_itl_ms": 25.244791992008686,
      "p95_itl_ms": 92.04532120324713,
      "p99_itl_ms": 249.56298170066003,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 31.746913580246915,
      "avg_output_len": 557.384765625,
      "avg_power_watts": 695.8087540314312,
      "data_parallel": 1,
      "energy_per_request_joules": 374.8044291375198,
      "energy_per_token_joules": 0.6724339311951746,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 18.568344006780535,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1034.761515967391,
      "p90_itl_ms": 76.21222508392768,
      "p95_itl_ms": 116.3685409585013,
      "p99_itl_ms": 343.1883310682183,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 59.36413043478261,
      "avg_output_len": 549.76953125,
      "avg_power_watts": 632.5443443532026,
      "data_parallel": 1,
      "energy_per_request_joules": 281.6843506965832,
      "energy_per_token_joules": 0.5123680645890344,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 30.81964879337053,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1234.5506835219335,
      "p90_itl_ms": 110.79544887616066,
      "p95_itl_ms": 157.07996977725998,
      "p99_itl_ms": 277.4554721754976,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 127.4074074074074,
      "avg_output_len": 544.515625,
      "avg_power_watts": 679.7152581574318,
      "data_parallel": 1,
      "energy_per_request_joules": 223.0369143342522,
      "energy_per_token_joules": 0.4096060867569268,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 128,
      "median_itl_ms": 36.18477898999117,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1659.4364198518278,
      "p90_itl_ms": 168.07252722723172,
      "p95_itl_ms": 210.02805782482025,
      "p99_itl_ms": 355.73217409430174,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 230.82222222222222,
      "avg_output_len": 551.6181640625,
      "avg_power_watts": 784.5775072619831,
      "data_parallel": 1,
      "energy_per_request_joules": 146.43854209319298,
      "energy_per_token_joules": 0.26547084855712083,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 256,
      "median_itl_ms": 45.03516899421811,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 2955.4186891942945,
      "p90_itl_ms": 184.01581941314205,
      "p95_itl_ms": 232.17442500172172,
      "p99_itl_ms": 403.3729909267277,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 7.972602739726027,
      "avg_output_len": 546.822265625,
      "avg_power_watts": 902.149699476649,
      "data_parallel": 1,
      "energy_per_request_joules": 1061.1992185271383,
      "energy_per_token_joules": 1.9406657066427648,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 15.507552772760391,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 464.8661005286241,
      "p90_itl_ms": 15.988637879490852,
      "p95_itl_ms": 16.577761806547638,
      "p99_itl_ms": 56.785087734460845,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 15.970414201183432,
      "avg_output_len": 556.76953125,
      "avg_power_watts": 939.7724713231439,
      "data_parallel": 1,
      "energy_per_request_joules": 649.9898525294856,
      "energy_per_token_joules": 1.1674307160275046,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 16.921130940318108,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 804.9920722670132,
      "p90_itl_ms": 19.05963569879532,
      "p95_itl_ms": 21.863837353885167,
      "p99_itl_ms": 144.55379690974948,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 31.90954773869347,
      "avg_output_len": 546.16015625,
      "avg_power_watts": 990.1701150300204,
      "data_parallel": 1,
      "energy_per_request_joules": 416.90696200824766,
      "energy_per_token_joules": 0.7633419560862513,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 32,
      "median_itl_ms": 19.27599497139454,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 1297.15143669915,
      "p90_itl_ms": 25.1510828910839,
      "p95_itl_ms": 58.33889506757258,
      "p99_itl_ms": 156.63298651576045,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 63.87313432835821,
      "avg_output_len": 551.37890625,
      "avg_power_watts": 1064.0998246495255,
      "data_parallel": 1,
      "energy_per_request_joules": 321.04023651236645,
      "energy_per_token_joules": 0.582249761231896,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 64,
      "median_itl_ms": 23.043915629386902,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 1827.5659270313042,
      "p90_itl_ms": 50.025426477721304,
      "p95_itl_ms": 85.70460369810459,
      "p99_itl_ms": 214.18161656707528,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 95.74757281553399,
      "avg_output_len": 548.19140625,
      "avg_power_watts": 1101.6228355988967,
      "data_parallel": 1,
      "energy_per_request_joules": 292.1989650819706,
      "energy_per_token_joules": 0.5330236150194494,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 96,
      "median_itl_ms": 27.98934280872345,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 2066.743019554021,
      "p90_itl_ms": 76.34959444403648,
      "p95_itl_ms": 160.15007263049483,
      "p99_itl_ms": 436.40216583386075,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 125.47126436781609,
      "avg_output_len": 542.61328125,
      "avg_power_watts": 1138.0928693915967,
      "data_parallel": 1,
      "energy_per_request_joules": 265.1404162582648,
      "energy_per_token_joules": 0.4886360607456377,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 128,
      "median_itl_ms": 31.083492562174797,
      "model_id": "Qwen/Qwen3-VL-32B-Instruct",
      "nickname": "Qwen 3 VL 32B Instruct",
      "num_gpus": 2,
      "output_throughput_tokens_per_sec": 2329.1217345991936,
      "p90_itl_ms": 96.4976491308526,
      "p95_itl_ms": 163.92031125724316,
      "p99_itl_ms": 445.9056684374809,
      "tensor_parallel": 1,
      "total_params_billions": 32.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 7.693069306930693,
      "avg_output_len": 277.013671875,
      "avg_power_watts": 508.2938792062627,
      "data_parallel": 1,
      "energy_per_request_joules": 166.82286227648356,
      "energy_per_token_joules": 0.6022188765894592,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 8,
      "median_itl_ms": 5.2635789616033435,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 844.0351157454228,
      "p90_itl_ms": 9.356255806051191,
      "p95_itl_ms": 12.581073126057158,
      "p99_itl_ms": 95.48633036552745,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 15.455882352941176,
      "avg_output_len": 272.01171875,
      "avg_power_watts": 506.1073147247259,
      "data_parallel": 1,
      "energy_per_request_joules": 109.73156108387914,
      "energy_per_token_joules": 0.403407476663647,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 16,
      "median_itl_ms": 5.6986364943441,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1254.5808989720533,
      "p90_itl_ms": 13.608912489144128,
      "p95_itl_ms": 77.89892376749765,
      "p99_itl_ms": 193.65812528468223,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 31.28125,
      "avg_output_len": 270.134765625,
      "avg_power_watts": 406.20859933933605,
      "data_parallel": 1,
      "energy_per_request_joules": 104.03156978595366,
      "energy_per_token_joules": 0.385109889670291,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 32,
      "median_itl_ms": 7.90211049024947,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1054.7862057946852,
      "p90_itl_ms": 70.08795000001555,
      "p95_itl_ms": 113.02798815595452,
      "p99_itl_ms": 257.5960953545291,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 60.735849056603776,
      "avg_output_len": 268.07421875,
      "avg_power_watts": 432.01253478772577,
      "data_parallel": 1,
      "energy_per_request_joules": 81.86678600765819,
      "energy_per_token_joules": 0.30538850915762744,
      "expert_parallel": 1,
      "gpu_model": "B200",
      "max_num_seqs": 64,
      "median_itl_ms": 17.593100492376834,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1414.6325805753904,
      "p90_itl_ms": 129.1069425933529,
      "p95_itl_ms": 182.59058917756184,
      "p99_itl_ms": 343.95189686329076,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 7.716666666666667,
      "avg_output_len": 272.11328125,
      "avg_power_watts": 411.22373412421507,
      "data_parallel": 1,
      "energy_per_request_joules": 150.1658904218461,
      "energy_per_token_joules": 0.5518506473922654,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 8,
      "median_itl_ms": 8.593200705945492,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 745.1721513192497,
      "p90_itl_ms": 10.402792133390903,
      "p95_itl_ms": 22.461171443145023,
      "p99_itl_ms": 63.579225447028875,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 15.588235294117647,
      "avg_output_len": 272.080078125,
      "avg_power_watts": 422.7708829014515,
      "data_parallel": 1,
      "energy_per_request_joules": 104.97330698126711,
      "energy_per_token_joules": 0.38581768905932134,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 16,
      "median_itl_ms": 10.228879749774933,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1095.7788999571983,
      "p90_itl_ms": 42.54213571548463,
      "p95_itl_ms": 55.5897245183587,
      "p99_itl_ms": 129.88572999835014,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 29.410958904109588,
      "avg_output_len": 269.25390625,
      "avg_power_watts": 466.5809244285249,
      "data_parallel": 1,
      "energy_per_request_joules": 75.35644338059359,
      "energy_per_token_joules": 0.2798713096872428,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 32,
      "median_itl_ms": 12.523715384304523,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1667.1266695751372,
      "p90_itl_ms": 52.421468682587154,
      "p95_itl_ms": 70.54465562105176,
      "p99_itl_ms": 174.2780347727239,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 63.30357142857143,
      "avg_output_len": 269.556640625,
      "avg_power_watts": 479.6928450792039,
      "data_parallel": 1,
      "energy_per_request_joules": 66.22566115555489,
      "energy_per_token_joules": 0.24568365669642792,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 64,
      "median_itl_ms": 20.17329167574644,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 1952.48170565909,
      "p90_itl_ms": 68.84652877075446,
      "p95_itl_ms": 95.53584620130783,
      "p99_itl_ms": 254.4894211366775,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    },
    {
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "avg_batch_size": 93.0,
      "avg_output_len": 269.845703125,
      "avg_power_watts": 482.6184517543638,
      "data_parallel": 1,
      "energy_per_request_joules": 62.06019446577808,
      "energy_per_token_joules": 0.22998400103124889,
      "expert_parallel": 1,
      "gpu_model": "H100",
      "max_num_seqs": 96,
      "median_itl_ms": 25.45191454334875,
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "nickname": "Qwen 3 VL 8B Instruct",
      "num_gpus": 1,
      "output_throughput_tokens_per_sec": 2098.4870668842236,
      "p90_itl_ms": 80.8964941650629,
      "p95_itl_ms": 129.90304883569476,
      "p99_itl_ms": 276.39712223783135,
      "tensor_parallel": 1,
      "total_params_billions": 8.0,
      "weight_precision": "bfloat16"
    }
  ],
  "task": "video-chat",
  "task_display_name": "Video Chat"
}