{
  "task": "gpqa",
  "task_display_name": "GPQA Diamond",
  "configurations": [
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5349135597314698,
      "energy_per_request_joules": 3975.491083842459,
      "avg_power_watts": 494.269463945933,
      "median_itl_ms": 17.340729013085365,
      "output_throughput_tokens_per_sec": 832.4595554753186,
      "p90_itl_ms": 18.916429951786995,
      "p95_itl_ms": 19.361893832683563,
      "p99_itl_ms": 21.631541699171073,
      "avg_batch_size": 15.997258396161754
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3538632583868544,
      "energy_per_request_joules": 2455.5661684249762,
      "avg_power_watts": 525.7126515077016,
      "median_itl_ms": 21.54853194952011,
      "output_throughput_tokens_per_sec": 1339.6645533265064,
      "p90_itl_ms": 24.447074532508854,
      "p95_itl_ms": 25.796907395124435,
      "p99_itl_ms": 28.142292946577065,
      "avg_batch_size": 31.998768472906406
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.279562069098521,
      "energy_per_request_joules": 1876.0888043234238,
      "avg_power_watts": 600.0061181329069,
      "median_itl_ms": 28.065836057066917,
      "output_throughput_tokens_per_sec": 1692.9600591950748,
      "p90_itl_ms": 29.982031136751175,
      "p95_itl_ms": 31.135702878236774,
      "p99_itl_ms": 34.547596350312254,
      "avg_batch_size": 59.014256619144604
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8740947126500942,
      "energy_per_request_joules": 6057.803040527457,
      "avg_power_watts": 483.6227004443375,
      "median_itl_ms": 14.42334707826376,
      "output_throughput_tokens_per_sec": 538.6458070082973,
      "p90_itl_ms": 15.312102250754833,
      "p95_itl_ms": 15.615710522979498,
      "p99_itl_ms": 18.57272390276194,
      "avg_batch_size": 7.998330550918197
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 4.996622477686305,
      "energy_per_request_joules": 44642.247820487115,
      "avg_power_watts": 2085.004197227219,
      "median_itl_ms": 38.23172394186258,
      "output_throughput_tokens_per_sec": 396.95094568510143,
      "p90_itl_ms": 39.07731380313635,
      "p95_itl_ms": 39.27069362252951,
      "p99_itl_ms": 39.93051193654537,
      "avg_batch_size": 15.99846508058327
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 2.8915271187756044,
      "energy_per_request_joules": 26093.681055706787,
      "avg_power_watts": 2122.508904401888,
      "median_itl_ms": 43.307825922966,
      "output_throughput_tokens_per_sec": 623.9547772926142,
      "p90_itl_ms": 44.745996594429016,
      "p95_itl_ms": 45.16365844756365,
      "p99_itl_ms": 46.947318501770496,
      "avg_batch_size": 31.994897959183675
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 9.022118624670423,
      "energy_per_request_joules": 81621.46681218882,
      "avg_power_watts": 2051.764438968017,
      "median_itl_ms": 35.106019116938114,
      "output_throughput_tokens_per_sec": 221.22387193701712,
      "p90_itl_ms": 35.68514231592417,
      "p95_itl_ms": 35.84449077025056,
      "p99_itl_ms": 36.17498764768243,
      "avg_batch_size": 7.998431987455899
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.3846291846315368,
      "energy_per_request_joules": 12872.757667985596,
      "avg_power_watts": 3918.0969655339563,
      "median_itl_ms": 45.91882973909378,
      "output_throughput_tokens_per_sec": 1400.6097388442286,
      "p90_itl_ms": 49.58171360194683,
      "p95_itl_ms": 50.07552541792393,
      "p99_itl_ms": 50.85372041910886,
      "avg_batch_size": 127.97604790419162
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 6.436207110187748,
      "energy_per_request_joules": 61469.32106681325,
      "avg_power_watts": 3695.911597906651,
      "median_itl_ms": 27.76678465306759,
      "output_throughput_tokens_per_sec": 501.73025112793005,
      "p90_itl_ms": 28.44787947833538,
      "p95_itl_ms": 28.704164549708366,
      "p99_itl_ms": 29.101931862533092,
      "avg_batch_size": 15.999335327351279
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.8447779951844017,
      "energy_per_request_joules": 36646.28786232262,
      "avg_power_watts": 3799.1154640536115,
      "median_itl_ms": 32.201044261455536,
      "output_throughput_tokens_per_sec": 764.479611840213,
      "p90_itl_ms": 33.301991969347,
      "p95_itl_ms": 33.67263386026025,
      "p99_itl_ms": 34.3761639483273,
      "avg_batch_size": 31.998797354179196
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.310804732236074,
      "energy_per_request_joules": 20843.423672576475,
      "avg_power_watts": 3778.026163898068,
      "median_itl_ms": 39.5278912037611,
      "output_throughput_tokens_per_sec": 1155.8435180117092,
      "p90_itl_ms": 41.83093644678593,
      "p95_itl_ms": 42.2195203602314,
      "p99_itl_ms": 43.016559258103364,
      "avg_batch_size": 63.99409681227863
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 11.589075296954064,
      "energy_per_request_joules": 107647.70124582382,
      "avg_power_watts": 3626.973377804078,
      "median_itl_ms": 25.474630296230316,
      "output_throughput_tokens_per_sec": 295.5236461650536,
      "p90_itl_ms": 25.978809222579002,
      "p95_itl_ms": 26.115630939602852,
      "p99_itl_ms": 26.377523317933083,
      "avg_batch_size": 7.999106504646176
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.7269749044931488,
      "energy_per_request_joules": 15943.04854607975,
      "avg_power_watts": 3860.946487305547,
      "median_itl_ms": 43.42041350901127,
      "output_throughput_tokens_per_sec": 1272.8269719389236,
      "p90_itl_ms": 46.97277583181858,
      "p95_itl_ms": 47.311057057231665,
      "p99_itl_ms": 48.420037776231766,
      "avg_batch_size": 95.98238747553816
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 4.955265135500029,
      "energy_per_request_joules": 45582.05746574394,
      "avg_power_watts": 3181.8895714164837,
      "median_itl_ms": 24.881263001589105,
      "output_throughput_tokens_per_sec": 612.6116861085251,
      "p90_itl_ms": 25.91734299858217,
      "p95_itl_ms": 26.224371401258395,
      "p99_itl_ms": 26.813625257709646,
      "avg_batch_size": 15.99850355405911
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.609420754986378,
      "energy_per_request_joules": 32322.508696085035,
      "avg_power_watts": 3445.3851031286467,
      "median_itl_ms": 33.39150100509869,
      "output_throughput_tokens_per_sec": 840.77847347155,
      "p90_itl_ms": 34.738079097587615,
      "p95_itl_ms": 35.09773920013686,
      "p99_itl_ms": 35.91120338824112,
      "avg_batch_size": 31.99690785405071
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "H100",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 7.195367136475786,
      "energy_per_request_joules": 66158.021177755,
      "avg_power_watts": 2837.254751044061,
      "median_itl_ms": 20.23592299883603,
      "output_throughput_tokens_per_sec": 380.63122456374924,
      "p90_itl_ms": 20.987010200769873,
      "p95_itl_ms": 21.200230199610814,
      "p99_itl_ms": 21.644799660352877,
      "avg_batch_size": 7.99954233409611
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5914881665808681,
      "energy_per_request_joules": 4875.6130586143145,
      "avg_power_watts": 564.8065033526215,
      "median_itl_ms": 16.748839057981968,
      "output_throughput_tokens_per_sec": 924.808799907507,
      "p90_itl_ms": 18.053930439054966,
      "p95_itl_ms": 18.540182430297136,
      "p99_itl_ms": 21.3086342997849,
      "avg_batch_size": 15.995015576323988
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8011522660693712,
      "energy_per_request_joules": 6539.15450593015,
      "avg_power_watts": 519.22159254518,
      "median_itl_ms": 12.309283018112183,
      "output_throughput_tokens_per_sec": 632.9125162348574,
      "p90_itl_ms": 13.100481033325195,
      "p95_itl_ms": 13.35893217474222,
      "p99_itl_ms": 16.339488066732873,
      "avg_batch_size": 7.997072354663321
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.19860518070462557,
      "energy_per_request_joules": 1600.3505155531907,
      "avg_power_watts": 926.3172382702305,
      "median_itl_ms": 28.594817966222763,
      "output_throughput_tokens_per_sec": 2816.968000561452,
      "p90_itl_ms": 32.3397321626544,
      "p95_itl_ms": 32.74561371654272,
      "p99_itl_ms": 33.72602770105004,
      "avg_batch_size": 127.98863636363636
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5928453764785513,
      "energy_per_request_joules": 4713.210568061525,
      "avg_power_watts": 787.4286318346727,
      "median_itl_ms": 11.967048048973083,
      "output_throughput_tokens_per_sec": 1248.549483964826,
      "p90_itl_ms": 12.794099375605585,
      "p95_itl_ms": 13.057692814618349,
      "p99_itl_ms": 13.601342476904392,
      "avg_batch_size": 15.999084249084248
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4291973367276949,
      "energy_per_request_joules": 3480.96381392695,
      "avg_power_watts": 843.5222415723906,
      "median_itl_ms": 16.395246610045433,
      "output_throughput_tokens_per_sec": 1780.3378962907657,
      "p90_itl_ms": 17.110166512429714,
      "p95_itl_ms": 17.271547671407458,
      "p99_itl_ms": 17.595617100596428,
      "avg_batch_size": 31.99586206896552
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.30312186679783765,
      "energy_per_request_joules": 2460.302410131322,
      "avg_power_watts": 910.0537943622338,
      "median_itl_ms": 21.53947949409485,
      "output_throughput_tokens_per_sec": 2482.019395422607,
      "p90_itl_ms": 22.987710312008858,
      "p95_itl_ms": 23.289293609559536,
      "p99_itl_ms": 23.904349207878113,
      "avg_batch_size": 63.997518610421835
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8358966354324942,
      "energy_per_request_joules": 6945.579129713426,
      "avg_power_watts": 710.2988788848096,
      "median_itl_ms": 9.367374703288078,
      "output_throughput_tokens_per_sec": 832.3275512517333,
      "p90_itl_ms": 9.84083116054535,
      "p95_itl_ms": 9.986687451601028,
      "p99_itl_ms": 10.294333472847937,
      "avg_batch_size": 7.999461206896552
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2574851684497885,
      "energy_per_request_joules": 2132.7951653246278,
      "avg_power_watts": 915.6778884394571,
      "median_itl_ms": 27.714597061276436,
      "output_throughput_tokens_per_sec": 2542.1307504135607,
      "p90_itl_ms": 30.28995543718338,
      "p95_itl_ms": 30.615631490945816,
      "p99_itl_ms": 31.410065293312076,
      "avg_batch_size": 95.99350649350649
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.1832850157821015,
      "energy_per_request_joules": 8171.951580786593,
      "avg_power_watts": 978.9116740889593,
      "median_itl_ms": 19.323566928505898,
      "output_throughput_tokens_per_sec": 770.3850104905985,
      "p90_itl_ms": 20.279159024357796,
      "p95_itl_ms": 20.528793334960938,
      "p99_itl_ms": 20.97995974123478,
      "avg_batch_size": 15.996761658031089
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8017427481346298,
      "energy_per_request_joules": 5753.694684370774,
      "avg_power_watts": 1037.5940118925419,
      "median_itl_ms": 25.267704389989376,
      "output_throughput_tokens_per_sec": 954.0119010493911,
      "p90_itl_ms": 27.05940790474415,
      "p95_itl_ms": 27.408520970493555,
      "p99_itl_ms": 27.905541099607944,
      "avg_batch_size": 31.993795243019648
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5360033410262823,
      "energy_per_request_joules": 3783.3146125320714,
      "avg_power_watts": 1114.2135931343146,
      "median_itl_ms": 32.28148818016052,
      "output_throughput_tokens_per_sec": 1346.0716579894292,
      "p90_itl_ms": 33.90912599861622,
      "p95_itl_ms": 34.28855501115322,
      "p99_itl_ms": 35.215739868581295,
      "avg_batch_size": 63.83198380566802
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 2.008134134519289,
      "energy_per_request_joules": 13928.469067483733,
      "avg_power_watts": 954.4093289456731,
      "median_itl_ms": 16.724804416298866,
      "output_throughput_tokens_per_sec": 458.10347389793264,
      "p90_itl_ms": 17.58667640388012,
      "p95_itl_ms": 18.03741231560707,
      "p99_itl_ms": 18.79562646150588,
      "avg_batch_size": 7.998529411764705
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4027363632843381,
      "energy_per_request_joules": 3166.0488652766835,
      "avg_power_watts": 541.5961996991196,
      "median_itl_ms": 11.912006884813309,
      "output_throughput_tokens_per_sec": 1276.1930022460344,
      "p90_itl_ms": 13.004309311509132,
      "p95_itl_ms": 13.24793053790927,
      "p99_itl_ms": 15.970821734517815,
      "avg_batch_size": 15.999079189686924
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3172961910278235,
      "energy_per_request_joules": 2592.4300686484653,
      "avg_power_watts": 608.3187488855558,
      "median_itl_ms": 16.870860010385513,
      "output_throughput_tokens_per_sec": 1734.8047797325785,
      "p90_itl_ms": 19.108358770608902,
      "p95_itl_ms": 19.719145260751247,
      "p99_itl_ms": 22.33844097703693,
      "avg_batch_size": 31.99470198675497
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2668081081627998,
      "energy_per_request_joules": 2232.270249679532,
      "avg_power_watts": 669.7547370127364,
      "median_itl_ms": 26.641509495675564,
      "output_throughput_tokens_per_sec": 2134.3774547262824,
      "p90_itl_ms": 29.318027198314667,
      "p95_itl_ms": 30.49532836303115,
      "p99_itl_ms": 34.10156220197677,
      "avg_batch_size": 63.284351145038165
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6035629391030177,
      "energy_per_request_joules": 4740.496110728974,
      "avg_power_watts": 493.66104975802074,
      "median_itl_ms": 9.703529998660088,
      "output_throughput_tokens_per_sec": 804.1386780626508,
      "p90_itl_ms": 10.597483068704605,
      "p95_itl_ms": 10.925905779004097,
      "p99_itl_ms": 14.275360405445092,
      "avg_batch_size": 7.998910081743869
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.22106406919235558,
      "energy_per_request_joules": 1780.0938544970886,
      "avg_power_watts": 689.1496984712461,
      "median_itl_ms": 27.875522151589394,
      "output_throughput_tokens_per_sec": 2101.490365318892,
      "p90_itl_ms": 29.844370484352112,
      "p95_itl_ms": 30.95055818557739,
      "p99_itl_ms": 36.87678739428518,
      "avg_batch_size": 81.98511904761905
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.14425290253296774,
      "energy_per_request_joules": 821.5363080255328,
      "avg_power_watts": 578.9337210252614,
      "median_itl_ms": 30.360515229403973,
      "output_throughput_tokens_per_sec": 1934.771145807373,
      "p90_itl_ms": 32.88780227303505,
      "p95_itl_ms": 34.272380080074065,
      "p99_itl_ms": 38.53832149878139,
      "avg_batch_size": 127.98540145985402
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.39098008652963545,
      "energy_per_request_joules": 2112.0013654977292,
      "avg_power_watts": 472.11801599143433,
      "median_itl_ms": 13.13377171754837,
      "output_throughput_tokens_per_sec": 1133.5387911877804,
      "p90_itl_ms": 13.455495238304138,
      "p95_itl_ms": 13.61302100121975,
      "p99_itl_ms": 17.528010904788967,
      "avg_batch_size": 15.99030303030303
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.12537365876229262,
      "energy_per_request_joules": 723.1375341325939,
      "avg_power_watts": 605.4664177961711,
      "median_itl_ms": 36.748494021594524,
      "output_throughput_tokens_per_sec": 2056.0234432246884,
      "p90_itl_ms": 40.24399183690548,
      "p95_itl_ms": 40.85724940523505,
      "p99_itl_ms": 44.18877232819786,
      "avg_batch_size": 192.0
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.25003690647211935,
      "energy_per_request_joules": 1350.1045840000231,
      "avg_power_watts": 502.2718035856321,
      "median_itl_ms": 15.695895999670029,
      "output_throughput_tokens_per_sec": 1531.0583214974092,
      "p90_itl_ms": 16.001389920711517,
      "p95_itl_ms": 16.2830812856555,
      "p99_itl_ms": 20.27042657136917,
      "avg_batch_size": 31.975717439293597
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1852214746681974,
      "energy_per_request_joules": 1034.3796153664746,
      "avg_power_watts": 549.5660860110509,
      "median_itl_ms": 20.89649997651577,
      "output_throughput_tokens_per_sec": 1701.8714361375362,
      "p90_itl_ms": 21.905543468892574,
      "p95_itl_ms": 22.470758948475122,
      "p99_itl_ms": 26.676567345857627,
      "avg_batch_size": 63.957692307692305
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6590546477489686,
      "energy_per_request_joules": 3535.0226739370787,
      "avg_power_watts": 446.0593128436694,
      "median_itl_ms": 11.661284603178501,
      "output_throughput_tokens_per_sec": 633.3780557558546,
      "p90_itl_ms": 12.108508683741093,
      "p95_itl_ms": 12.212002836167812,
      "p99_itl_ms": 15.957467816770075,
      "avg_batch_size": 7.988474576271186
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1592476994472846,
      "energy_per_request_joules": 837.5962507767173,
      "avg_power_watts": 578.6646866567021,
      "median_itl_ms": 24.93886649608612,
      "output_throughput_tokens_per_sec": 1910.5427899931112,
      "p90_itl_ms": 27.007137052714825,
      "p95_itl_ms": 28.28009370714426,
      "p99_itl_ms": 34.73140273243189,
      "avg_batch_size": 95.94252873563218
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1217189164071414,
      "energy_per_request_joules": 648.2202367462521,
      "avg_power_watts": 549.1126313203853,
      "median_itl_ms": 27.26638689637184,
      "output_throughput_tokens_per_sec": 2978.0058495393,
      "p90_itl_ms": 28.777630999684334,
      "p95_itl_ms": 29.215967282652855,
      "p99_itl_ms": 34.23901721835138,
      "avg_batch_size": 127.97674418604652
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.29249840943351546,
      "energy_per_request_joules": 1588.1984090480598,
      "avg_power_watts": 434.988344426694,
      "median_itl_ms": 10.604096576571465,
      "output_throughput_tokens_per_sec": 1341.080504088954,
      "p90_itl_ms": 10.849873535335064,
      "p95_itl_ms": 10.94916881993413,
      "p99_itl_ms": 15.016931947320701,
      "avg_batch_size": 15.986666666666666
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.11555187175691262,
      "energy_per_request_joules": 635.8095844596141,
      "avg_power_watts": 555.1837410340161,
      "median_itl_ms": 38.75891678035259,
      "output_throughput_tokens_per_sec": 3388.506510207436,
      "p90_itl_ms": 49.0272868424654,
      "p95_itl_ms": 51.12214758992195,
      "p99_itl_ms": 82.37348513677712,
      "avg_batch_size": 191.9486301369863
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.10892531500222859,
      "energy_per_request_joules": 602.4472129303057,
      "avg_power_watts": 585.6974121900956,
      "median_itl_ms": 47.55112063139677,
      "output_throughput_tokens_per_sec": 3489.9358666609482,
      "p90_itl_ms": 56.970587000250816,
      "p95_itl_ms": 60.44964473694563,
      "p99_itl_ms": 84.74351633340126,
      "avg_batch_size": 255.94372294372295
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.19800835601455186,
      "energy_per_request_joules": 1091.6850694513605,
      "avg_power_watts": 475.5057491661098,
      "median_itl_ms": 13.077691197395325,
      "output_throughput_tokens_per_sec": 1842.0657810442435,
      "p90_itl_ms": 13.414505869150162,
      "p95_itl_ms": 13.77813145518303,
      "p99_itl_ms": 17.646052315831202,
      "avg_batch_size": 31.977272727272727
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1509581841694076,
      "energy_per_request_joules": 812.9753894484143,
      "avg_power_watts": 518.0810079474549,
      "median_itl_ms": 18.010043539106846,
      "output_throughput_tokens_per_sec": 2547.8471542022003,
      "p90_itl_ms": 19.111029617488384,
      "p95_itl_ms": 20.565940439701077,
      "p99_itl_ms": 23.601431734860018,
      "avg_batch_size": 63.97899159663866
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.48337250937519677,
      "energy_per_request_joules": 2616.031550940964,
      "avg_power_watts": 401.99450485610333,
      "median_itl_ms": 9.505512192845345,
      "output_throughput_tokens_per_sec": 793.991265878723,
      "p90_itl_ms": 9.730427525937557,
      "p95_itl_ms": 9.785777889192104,
      "p99_itl_ms": 13.753928616642943,
      "avg_batch_size": 7.986334405144695
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.13321027691362877,
      "energy_per_request_joules": 740.2723833010303,
      "avg_power_watts": 549.4045287832402,
      "median_itl_ms": 22.324533201754093,
      "output_throughput_tokens_per_sec": 3009.0244592198114,
      "p90_itl_ms": 23.706649988889694,
      "p95_itl_ms": 24.716751277446747,
      "p99_itl_ms": 30.508321672678008,
      "avg_batch_size": 95.94827586206897
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5118758675585872,
      "energy_per_request_joules": 859.9462870351178,
      "avg_power_watts": 609.8622051217071,
      "median_itl_ms": 13.226334936916828,
      "output_throughput_tokens_per_sec": 1138.052559030488,
      "p90_itl_ms": 13.8166768476367,
      "p95_itl_ms": 14.032936654984951,
      "p99_itl_ms": 18.462037704885013,
      "avg_batch_size": 15.99622641509434
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3759124523566032,
      "energy_per_request_joules": 660.8237144790817,
      "avg_power_watts": 655.9374048511457,
      "median_itl_ms": 17.96223595738411,
      "output_throughput_tokens_per_sec": 1564.094860003497,
      "p90_itl_ms": 18.692253343760967,
      "p95_itl_ms": 19.1040492306153,
      "p99_itl_ms": 35.42223773896699,
      "avg_batch_size": 31.98857142857143
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.26757106007777065,
      "energy_per_request_joules": 465.2560728226024,
      "avg_power_watts": 688.1701637002966,
      "median_itl_ms": 24.15146678686142,
      "output_throughput_tokens_per_sec": 2060.9974791902346,
      "p90_itl_ms": 25.258196517825127,
      "p95_itl_ms": 26.005130261182785,
      "p99_itl_ms": 42.64888353645794,
      "avg_batch_size": 64.0
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6840787562079539,
      "energy_per_request_joules": 1218.1369682135755,
      "avg_power_watts": 549.9648189244016,
      "median_itl_ms": 9.85749065876007,
      "output_throughput_tokens_per_sec": 781.6704139623178,
      "p90_itl_ms": 10.23793164640665,
      "p95_itl_ms": 10.347421746701002,
      "p99_itl_ms": 10.778715033084152,
      "avg_batch_size": 7.992840095465394
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.09540020046199459,
      "energy_per_request_joules": 169.35816192856834,
      "avg_power_watts": 1138.9522207481266,
      "median_itl_ms": 79.71355800691526,
      "output_throughput_tokens_per_sec": 5100.4950896012515,
      "p90_itl_ms": 87.2380607004743,
      "p95_itl_ms": 91.536516979977,
      "p99_itl_ms": 114.61825579055589,
      "avg_batch_size": 1023.7627118644068
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.22263135796809058,
      "energy_per_request_joules": 391.0497314693555,
      "avg_power_watts": 1208.3604693401549,
      "median_itl_ms": 22.496696561574936,
      "output_throughput_tokens_per_sec": 3632.419970252483,
      "p90_itl_ms": 23.41281995177269,
      "p95_itl_ms": 23.590007796883583,
      "p99_itl_ms": 30.726888962089998,
      "avg_batch_size": 127.96666666666667
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5779632719590391,
      "energy_per_request_joules": 991.4288558979787,
      "avg_power_watts": 992.4357622410904,
      "median_itl_ms": 9.206450544297695,
      "output_throughput_tokens_per_sec": 1642.15681715759,
      "p90_itl_ms": 9.507095068693161,
      "p95_itl_ms": 9.606552217155695,
      "p99_itl_ms": 10.510198529809712,
      "avg_batch_size": 15.983783783783784
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.19604752504783104,
      "energy_per_request_joules": 339.77115382721445,
      "avg_power_watts": 1264.511861931454,
      "median_itl_ms": 29.22416350338608,
      "output_throughput_tokens_per_sec": 4525.079789849335,
      "p90_itl_ms": 30.091804104449693,
      "p95_itl_ms": 30.722570798388915,
      "p99_itl_ms": 34.1212665657804,
      "avg_batch_size": 191.87692307692308
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1505766036416854,
      "energy_per_request_joules": 254.57142236133882,
      "avg_power_watts": 1238.1363237302414,
      "median_itl_ms": 30.520553002133965,
      "output_throughput_tokens_per_sec": 5386.746334938468,
      "p90_itl_ms": 31.859954996616576,
      "p95_itl_ms": 32.78333039197605,
      "p99_itl_ms": 38.00529548199845,
      "avg_batch_size": 255.8139534883721
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4168421449297778,
      "energy_per_request_joules": 739.2842808764685,
      "avg_power_watts": 1086.5274011846657,
      "median_itl_ms": 12.075122445821762,
      "output_throughput_tokens_per_sec": 2386.058456337645,
      "p90_itl_ms": 12.440547347068787,
      "p95_itl_ms": 12.622483540326357,
      "p99_itl_ms": 21.764685586094853,
      "avg_batch_size": 31.99145299145299
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.13547640806695457,
      "energy_per_request_joules": 234.53566288665868,
      "avg_power_watts": 1258.8980713979674,
      "median_itl_ms": 40.18088299926603,
      "output_throughput_tokens_per_sec": 6336.107976750837,
      "p90_itl_ms": 42.15094749815762,
      "p95_itl_ms": 43.16567475325428,
      "p99_itl_ms": 45.19459044677207,
      "avg_batch_size": 383.9056603773585
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.11474400457038335,
      "energy_per_request_joules": 200.53267832077648,
      "avg_power_watts": 1163.858988838859,
      "median_itl_ms": 48.84157798369415,
      "output_throughput_tokens_per_sec": 4376.796622165065,
      "p90_itl_ms": 51.67187621118501,
      "p95_itl_ms": 53.012487810337916,
      "p99_itl_ms": 60.52728712093086,
      "avg_batch_size": 511.72058823529414
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2979923785007381,
      "energy_per_request_joules": 500.85595770715975,
      "avg_power_watts": 1164.007045700212,
      "median_itl_ms": 16.037579625844955,
      "output_throughput_tokens_per_sec": 3249.6954281426697,
      "p90_itl_ms": 16.466877050697803,
      "p95_itl_ms": 16.68805722147226,
      "p99_itl_ms": 25.734602697193623,
      "avg_batch_size": 63.92537313432836
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.10304731168896487,
      "energy_per_request_joules": 177.10918409911557,
      "avg_power_watts": 1169.4075889437233,
      "median_itl_ms": 65.03442699613515,
      "output_throughput_tokens_per_sec": 7698.13360347091,
      "p90_itl_ms": 69.38796988979448,
      "p95_itl_ms": 71.45622423995519,
      "p99_itl_ms": 96.55798725638303,
      "avg_batch_size": 767.75
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7819241402752495,
      "energy_per_request_joules": 1376.3286549099437,
      "avg_power_watts": 864.1739530037215,
      "median_itl_ms": 7.176676765084267,
      "output_throughput_tokens_per_sec": 1040.2404279649768,
      "p90_itl_ms": 7.405425980687141,
      "p95_itl_ms": 7.466542534530163,
      "p99_itl_ms": 7.698871921747921,
      "avg_batch_size": 7.996644295302014
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.24997276391736417,
      "energy_per_request_joules": 451.8964701482083,
      "avg_power_watts": 1212.7099843565145,
      "median_itl_ms": 19.24681104719639,
      "output_throughput_tokens_per_sec": 1614.127329065653,
      "p90_itl_ms": 19.789204001426697,
      "p95_itl_ms": 20.003909431397915,
      "p99_itl_ms": 27.672958895564076,
      "avg_batch_size": 95.93023255813954
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.08807920440292867,
      "energy_per_request_joules": 151.16576156145595,
      "avg_power_watts": 973.2574856315339,
      "median_itl_ms": 126.29272416234016,
      "output_throughput_tokens_per_sec": 7688.455701973553,
      "p90_itl_ms": 142.54298806190496,
      "p95_itl_ms": 152.40283245220778,
      "p99_itl_ms": 196.24773861840376,
      "avg_batch_size": 1535.6063829787233
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "H100",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.08603986209171981,
      "energy_per_request_joules": 148.07166948273303,
      "avg_power_watts": 925.9872288388464,
      "median_itl_ms": 122.57824651896954,
      "output_throughput_tokens_per_sec": 6613.830638884705,
      "p90_itl_ms": 174.04294423758984,
      "p95_itl_ms": 190.80506693571806,
      "p99_itl_ms": 271.0348512977364,
      "avg_batch_size": 1915.4583333333333
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.044663547029782834,
      "energy_per_request_joules": 93.86348932493158,
      "avg_power_watts": 590.7200429077185,
      "median_itl_ms": 65.82066099508666,
      "output_throughput_tokens_per_sec": 6840.454219700608,
      "p90_itl_ms": 79.74796341150069,
      "p95_itl_ms": 82.23776889790315,
      "p99_itl_ms": 100.62445269781165,
      "avg_batch_size": 1023.8571428571429
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.07835704096786583,
      "energy_per_request_joules": 190.23467002210106,
      "avg_power_watts": 571.5198821995349,
      "median_itl_ms": 17.091874964535236,
      "output_throughput_tokens_per_sec": 4525.633269203074,
      "p90_itl_ms": 18.270541727542877,
      "p95_itl_ms": 19.189599715173234,
      "p99_itl_ms": 22.79142644256353,
      "avg_batch_size": 127.95505617977528
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.04421621295946752,
      "energy_per_request_joules": 96.84387808550831,
      "avg_power_watts": 597.8349061797795,
      "median_itl_ms": 102.49504250532482,
      "output_throughput_tokens_per_sec": 6978.015984835363,
      "p90_itl_ms": 119.3194648833014,
      "p95_itl_ms": 124.81068421184317,
      "p99_itl_ms": 155.6544672956806,
      "avg_batch_size": 1535.567901234568
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2301432340727128,
      "energy_per_request_joules": 493.62585391768636,
      "avg_power_watts": 472.01389388968306,
      "median_itl_ms": 8.021378991543315,
      "output_throughput_tokens_per_sec": 1865.839206048826,
      "p90_itl_ms": 8.339498200803064,
      "p95_itl_ms": 8.485308394301683,
      "p99_itl_ms": 12.094341671327124,
      "avg_batch_size": 15.989473684210527
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.06671761396240401,
      "energy_per_request_joules": 144.9583370332894,
      "avg_power_watts": 586.2491029119586,
      "median_itl_ms": 20.807377994060516,
      "output_throughput_tokens_per_sec": 5340.538480326368,
      "p90_itl_ms": 22.97214157879353,
      "p95_itl_ms": 24.080638960003853,
      "p99_itl_ms": 27.716139070689596,
      "avg_batch_size": 191.94444444444446
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.04494386842673256,
      "energy_per_request_joules": 106.92206829182203,
      "avg_power_watts": 607.1288191082168,
      "median_itl_ms": 140.31523650919553,
      "output_throughput_tokens_per_sec": 5645.49741756018,
      "p90_itl_ms": 162.23554299212992,
      "p95_itl_ms": 167.05090280593137,
      "p99_itl_ms": 223.2124011302948,
      "avg_batch_size": 2047.322033898305
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.05939785815916732,
      "energy_per_request_joules": 125.37717899587997,
      "avg_power_watts": 595.805656956448,
      "median_itl_ms": 24.282067082822323,
      "output_throughput_tokens_per_sec": 4903.871175605715,
      "p90_itl_ms": 26.272324286401272,
      "p95_itl_ms": 26.88558818772435,
      "p99_itl_ms": 30.299605559557666,
      "avg_batch_size": 255.86111111111111
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.15624365155984618,
      "energy_per_request_joules": 341.1485438687084,
      "avg_power_watts": 530.8482485818803,
      "median_itl_ms": 9.244729997590184,
      "output_throughput_tokens_per_sec": 2675.6915325798027,
      "p90_itl_ms": 9.749028403894044,
      "p95_itl_ms": 10.465670099074487,
      "p99_itl_ms": 14.680375504831316,
      "avg_batch_size": 31.97222222222222
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.05329504970265962,
      "energy_per_request_joules": 118.72531044477012,
      "avg_power_watts": 563.9737742939677,
      "median_itl_ms": 34.59671100426931,
      "output_throughput_tokens_per_sec": 5533.078235654174,
      "p90_itl_ms": 37.844318998395465,
      "p95_itl_ms": 39.02042949630413,
      "p99_itl_ms": 42.281922802794746,
      "avg_batch_size": 383.8909090909091
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.04857689717550075,
      "energy_per_request_joules": 108.58662061704894,
      "avg_power_watts": 579.2002271854865,
      "median_itl_ms": 36.22605300915893,
      "output_throughput_tokens_per_sec": 6231.675352923967,
      "p90_itl_ms": 43.71156719571445,
      "p95_itl_ms": 44.61976600141497,
      "p99_itl_ms": 47.697860816842876,
      "avg_batch_size": 511.88235294117646
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.10234282857565034,
      "energy_per_request_joules": 214.0293506470685,
      "avg_power_watts": 564.1989287815686,
      "median_itl_ms": 11.219836000236683,
      "output_throughput_tokens_per_sec": 3322.5295130226827,
      "p90_itl_ms": 12.259755798731929,
      "p95_itl_ms": 13.49427009699866,
      "p99_itl_ms": 19.031764687388197,
      "avg_batch_size": 63.94444444444444
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.045799622614758256,
      "energy_per_request_joules": 99.5761978839005,
      "avg_power_watts": 575.119645979908,
      "median_itl_ms": 57.05505100195296,
      "output_throughput_tokens_per_sec": 6209.001533076224,
      "p90_itl_ms": 64.27263838704675,
      "p95_itl_ms": 66.42261650122236,
      "p99_itl_ms": 75.26780993386625,
      "avg_batch_size": 767.7258064516129
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.35647683548831655,
      "energy_per_request_joules": 763.7174126606158,
      "avg_power_watts": 436.8165428008319,
      "median_itl_ms": 6.6473519982537255,
      "output_throughput_tokens_per_sec": 1161.5178113784875,
      "p90_itl_ms": 7.106321495666634,
      "p95_itl_ms": 7.344038711016764,
      "p99_itl_ms": 8.563895427942033,
      "avg_batch_size": 7.993808049535604
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.08762510145959024,
      "energy_per_request_joules": 227.7106430814092,
      "avg_power_watts": 587.9965155217465,
      "median_itl_ms": 13.522330002160743,
      "output_throughput_tokens_per_sec": 3631.4467793012923,
      "p90_itl_ms": 14.995950201409869,
      "p95_itl_ms": 16.484720296284646,
      "p99_itl_ms": 21.25071637565269,
      "avg_batch_size": 95.95238095238095
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "H100",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.09217403713356308,
      "energy_per_request_joules": 210.6784259201206,
      "avg_power_watts": 605.0788525244425,
      "median_itl_ms": 14.309395104646683,
      "output_throughput_tokens_per_sec": 4292.704228236275,
      "p90_itl_ms": 15.341871604323387,
      "p95_itl_ms": 16.327757388353348,
      "p99_itl_ms": 20.299079716205593,
      "avg_batch_size": 95.98076923076923
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.3816286549956407,
      "energy_per_request_joules": 12582.1711766103,
      "avg_power_watts": 5107.914367077919,
      "median_itl_ms": 34.683529500398436,
      "output_throughput_tokens_per_sec": 1977.9964817374037,
      "p90_itl_ms": 37.60676530000637,
      "p95_itl_ms": 38.15989609975077,
      "p99_itl_ms": 40.900465580416494,
      "avg_batch_size": 128.0
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 5.29538689383246,
      "energy_per_request_joules": 49666.36973049346,
      "avg_power_watts": 4490.430254043855,
      "median_itl_ms": 18.77472799969837,
      "output_throughput_tokens_per_sec": 789.537966559013,
      "p90_itl_ms": 19.34954220050713,
      "p95_itl_ms": 19.52078710000933,
      "p99_itl_ms": 20.0685828800124,
      "avg_batch_size": 15.998505976095618
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.9654736369063941,
      "energy_per_request_joules": 8932.289025407115,
      "avg_power_watts": 5324.49080996465,
      "median_itl_ms": 47.09071849993052,
      "output_throughput_tokens_per_sec": 2915.7837005174556,
      "p90_itl_ms": 64.95665810016362,
      "p95_itl_ms": 68.05556069939483,
      "p99_itl_ms": 71.2804756193327,
      "avg_batch_size": 255.9760479041916
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.9802816029130628,
      "energy_per_request_joules": 37697.04603686624,
      "avg_power_watts": 4422.0779458838015,
      "median_itl_ms": 28.752029000315815,
      "output_throughput_tokens_per_sec": 1022.9957968420639,
      "p90_itl_ms": 29.682929000045988,
      "p95_itl_ms": 29.91489424912288,
      "p99_itl_ms": 30.604673221114354,
      "avg_batch_size": 31.996603260869566
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8620197492492466,
      "energy_per_request_joules": 8018.700718672469,
      "avg_power_watts": 5056.908262090388,
      "median_itl_ms": 83.80036599919549,
      "output_throughput_tokens_per_sec": 2495.285846529278,
      "p90_itl_ms": 127.39416920085206,
      "p95_itl_ms": 133.42911469844697,
      "p99_itl_ms": 141.98335292123383,
      "avg_batch_size": 383.97083333333336
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6335899716010652,
      "energy_per_request_joules": 5670.521447551582,
      "avg_power_watts": 5513.329773292434,
      "median_itl_ms": 81.84408800116216,
      "output_throughput_tokens_per_sec": 2951.127277155031,
      "p90_itl_ms": 108.1637857005262,
      "p95_itl_ms": 113.19406614966282,
      "p99_itl_ms": 130.75747443937868,
      "avg_batch_size": 511.95979899497485
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.4048399885084524,
      "energy_per_request_joules": 22688.389997643946,
      "avg_power_watts": 4793.243089035774,
      "median_itl_ms": 32.18659099911747,
      "output_throughput_tokens_per_sec": 1518.3024850134977,
      "p90_itl_ms": 34.790948799127364,
      "p95_itl_ms": 35.317503699843655,
      "p99_itl_ms": 36.864018660962756,
      "avg_batch_size": 63.9958217270195
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7784914242900913,
      "energy_per_request_joules": 7054.476971073819,
      "avg_power_watts": 3965.734072480003,
      "median_itl_ms": 124.03286350127019,
      "output_throughput_tokens_per_sec": 2384.335823248094,
      "p90_itl_ms": 169.87547609896868,
      "p95_itl_ms": 180.5213226496562,
      "p99_itl_ms": 262.3587538905859,
      "avg_batch_size": 695.1068580542264
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 8.164239053644332,
      "energy_per_request_joules": 75623.0372761953,
      "avg_power_watts": 3936.581511491244,
      "median_itl_ms": 16.536694999558676,
      "output_throughput_tokens_per_sec": 462.5381976750354,
      "p90_itl_ms": 17.051538100440666,
      "p95_itl_ms": 17.23856009989504,
      "p99_itl_ms": 17.91685269969094,
      "avg_batch_size": 7.998900192466318
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.0629273476933352,
      "energy_per_request_joules": 9562.915772799734,
      "avg_power_watts": 3069.47977720058,
      "median_itl_ms": 44.25876399909612,
      "output_throughput_tokens_per_sec": 1693.9475413977755,
      "p90_itl_ms": 46.3336097978754,
      "p95_itl_ms": 46.72891469672322,
      "p99_itl_ms": 51.27377211902056,
      "avg_batch_size": 127.99693251533742
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 4.120615124235518,
      "energy_per_request_joules": 36995.06988607394,
      "avg_power_watts": 2824.1708935463976,
      "median_itl_ms": 23.20527301344555,
      "output_throughput_tokens_per_sec": 648.0987661912513,
      "p90_itl_ms": 24.29299699724652,
      "p95_itl_ms": 24.595946504268795,
      "p99_itl_ms": 25.258268608304206,
      "avg_batch_size": 15.997944923962187
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 2.70010661909529,
      "energy_per_request_joules": 24284.199819156256,
      "avg_power_watts": 3023.446090891989,
      "median_itl_ms": 28.4514160011895,
      "output_throughput_tokens_per_sec": 969.1774331050214,
      "p90_itl_ms": 29.4552395993378,
      "p95_itl_ms": 29.753016802715138,
      "p99_itl_ms": 34.008353518438525,
      "avg_batch_size": 31.99716914366596
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.8109633754579388,
      "energy_per_request_joules": 16599.308592006815,
      "avg_power_watts": 2952.2148136474398,
      "median_itl_ms": 38.86479849461466,
      "output_throughput_tokens_per_sec": 1285.1636215819453,
      "p90_itl_ms": 40.81023189792177,
      "p95_itl_ms": 41.45626680547139,
      "p99_itl_ms": 45.303142155898975,
      "avg_batch_size": 63.99640287769784
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 6.0275959055736665,
      "energy_per_request_joules": 53815.86792273631,
      "avg_power_watts": 2526.5910915868817,
      "median_itl_ms": 19.00674100033939,
      "output_throughput_tokens_per_sec": 409.4708957212465,
      "p90_itl_ms": 19.77367239887826,
      "p95_itl_ms": 19.96318690071348,
      "p99_itl_ms": 20.342997779371217,
      "avg_batch_size": 7.999239543726236
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "nickname": "Qwen 3 235B A22B Thinking",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7645069992507134,
      "energy_per_request_joules": 6995.096180724975,
      "avg_power_watts": 3232.5291155315317,
      "median_itl_ms": 50.343298506049905,
      "output_throughput_tokens_per_sec": 2317.456170585075,
      "p90_itl_ms": 55.78704259096412,
      "p95_itl_ms": 61.40488509699935,
      "p99_itl_ms": 87.17403255635872,
      "avg_batch_size": 225.61234567901235
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 9.257858972529394,
      "energy_per_request_joules": 85185.34771218625,
      "avg_power_watts": 2998.178786599502,
      "median_itl_ms": 24.582963000284508,
      "output_throughput_tokens_per_sec": 307.5745853928522,
      "p90_itl_ms": 25.035851998836733,
      "p95_itl_ms": 25.361088002682664,
      "p99_itl_ms": 25.820872603799216,
      "avg_batch_size": 7.999441444796127
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 5.224895152216228,
      "energy_per_request_joules": 47960.31535984823,
      "avg_power_watts": 3046.8798948509034,
      "median_itl_ms": 27.297725500829984,
      "output_throughput_tokens_per_sec": 507.6039690964307,
      "p90_itl_ms": 27.86018500046339,
      "p95_itl_ms": 28.062492801836925,
      "p99_itl_ms": 28.684546849253817,
      "avg_batch_size": 15.998572957545488
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.9769313546756497,
      "energy_per_request_joules": 9334.732047824797,
      "avg_power_watts": 3261.0152487439477,
      "median_itl_ms": 38.30493599525653,
      "output_throughput_tokens_per_sec": 1888.5478432530301,
      "p90_itl_ms": 40.12780199991539,
      "p95_itl_ms": 40.40211579267634,
      "p99_itl_ms": 43.71592538576806,
      "avg_batch_size": 127.98625429553265
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 2.951351854423615,
      "energy_per_request_joules": 27161.36564534776,
      "avg_power_watts": 3176.8905823146624,
      "median_itl_ms": 29.477635995135643,
      "output_throughput_tokens_per_sec": 925.8045608698365,
      "p90_itl_ms": 30.720707000000402,
      "p95_itl_ms": 31.056380990776233,
      "p99_itl_ms": 31.86296799685806,
      "avg_batch_size": 31.996610169491525
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 1.6735160724022529,
      "energy_per_request_joules": 15326.558865041003,
      "avg_power_watts": 3232.0294371704854,
      "median_itl_ms": 32.73992599861231,
      "output_throughput_tokens_per_sec": 1350.4242851688207,
      "p90_itl_ms": 34.281802191981114,
      "p95_itl_ms": 34.79172960505821,
      "p99_itl_ms": 38.61007971281652,
      "avg_batch_size": 63.99706314243759
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6455360180586963,
      "energy_per_request_joules": 5884.949231700578,
      "avg_power_watts": 3316.7269159762914,
      "median_itl_ms": 52.09324599127285,
      "output_throughput_tokens_per_sec": 2451.4436300722364,
      "p90_itl_ms": 77.32075320091099,
      "p95_itl_ms": 80.39097959990613,
      "p99_itl_ms": 83.13109963550234,
      "avg_batch_size": 255.96476964769647
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5438543626850559,
      "energy_per_request_joules": 5073.685102389289,
      "avg_power_watts": 3199.2789946423736,
      "median_itl_ms": 75.13649750762852,
      "output_throughput_tokens_per_sec": 2606.797591701846,
      "p90_itl_ms": 112.37821849499596,
      "p95_itl_ms": 116.45511425376753,
      "p99_itl_ms": 137.63553394092014,
      "avg_batch_size": 383.96559139784944
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4478728908416165,
      "energy_per_request_joules": 4006.406229306331,
      "avg_power_watts": 2102.6552402763327,
      "median_itl_ms": 120.10393649688922,
      "output_throughput_tokens_per_sec": 2356.3405450284527,
      "p90_itl_ms": 226.39649560005637,
      "p95_itl_ms": 243.23586514874478,
      "p99_itl_ms": 320.6806679388682,
      "avg_batch_size": 896.6826783114992
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 4,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 4,
      "data_parallel": 1,
      "energy_per_token_joules": 0.41771484182826857,
      "energy_per_request_joules": 3810.7485086481047,
      "avg_power_watts": 3316.7081131846653,
      "median_itl_ms": 82.01268799894024,
      "output_throughput_tokens_per_sec": 2783.3850695926,
      "p90_itl_ms": 108.26113479852211,
      "p95_itl_ms": 113.80948220321443,
      "p99_itl_ms": 154.2814498289954,
      "avg_batch_size": 511.97630331753555
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 4.691849616774552,
      "energy_per_request_joules": 44012.5351278287,
      "avg_power_watts": 1820.7289620274892,
      "median_itl_ms": 41.16085100395139,
      "output_throughput_tokens_per_sec": 358.53802426931895,
      "p90_itl_ms": 42.12684288795572,
      "p95_itl_ms": 42.44355245900805,
      "p99_itl_ms": 44.02511074236828,
      "avg_batch_size": 15.998467265163127
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 2.638276790717898,
      "energy_per_request_joules": 24466.939244319336,
      "avg_power_watts": 1856.0364945924946,
      "median_itl_ms": 45.45507000875659,
      "output_throughput_tokens_per_sec": 541.4350072560725,
      "p90_itl_ms": 47.16949100838974,
      "p95_itl_ms": 47.4936029931996,
      "p99_itl_ms": 48.10486939968541,
      "avg_batch_size": 31.998218262806237
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 1.4970100717403316,
      "energy_per_request_joules": 13801.170231738884,
      "avg_power_watts": 1896.0118684277618,
      "median_itl_ms": 50.621745991520584,
      "output_throughput_tokens_per_sec": 828.965655336553,
      "p90_itl_ms": 54.89455460337922,
      "p95_itl_ms": 55.2146983158309,
      "p99_itl_ms": 56.01393941906281,
      "avg_batch_size": 63.99279279279279
    },
    {
      "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
      "nickname": "Qwen 3 235B A22B Thinking FP8",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 235.0,
      "activated_params_billions": 22.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 2,
      "data_parallel": 1,
      "energy_per_token_joules": 8.284947018712542,
      "energy_per_request_joules": 78914.32956907076,
      "avg_power_watts": 1789.5539496614217,
      "median_itl_ms": 36.865409987512976,
      "output_throughput_tokens_per_sec": 206.98272735644366,
      "p90_itl_ms": 38.00415920559317,
      "p95_itl_ms": 38.25340419425629,
      "p99_itl_ms": 38.73853085213341,
      "avg_batch_size": 7.999640890591333
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.18257543199465798,
      "energy_per_request_joules": 1337.7320344211416,
      "avg_power_watts": 511.25871623968027,
      "median_itl_ms": 48.83954499382526,
      "output_throughput_tokens_per_sec": 1554.6331910113556,
      "p90_itl_ms": 68.44392910425087,
      "p95_itl_ms": 74.06184781284536,
      "p99_itl_ms": 86.26595737849128,
      "avg_batch_size": 127.98625429553265
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7806428816365977,
      "energy_per_request_joules": 5701.949657261465,
      "avg_power_watts": 360.8975244155932,
      "median_itl_ms": 34.790393998264335,
      "output_throughput_tokens_per_sec": 439.81940048209407,
      "p90_itl_ms": 50.95546791271772,
      "p95_itl_ms": 56.04782736045309,
      "p99_itl_ms": 66.4822291364544,
      "avg_batch_size": 15.99621081639683
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4180568400086617,
      "energy_per_request_joules": 2887.6262752471016,
      "avg_power_watts": 422.34231413670085,
      "median_itl_ms": 30.597431992646307,
      "output_throughput_tokens_per_sec": 872.7406971524213,
      "p90_itl_ms": 46.504846977768466,
      "p95_itl_ms": 51.50576701271348,
      "p99_itl_ms": 61.93683718447574,
      "avg_batch_size": 31.990549828178693
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.2911752428941126,
      "energy_per_request_joules": 2035.1590661341565,
      "avg_power_watts": 507.16354556998795,
      "median_itl_ms": 36.26766199886333,
      "output_throughput_tokens_per_sec": 1286.0334124034891,
      "p90_itl_ms": 53.20127041486558,
      "p95_itl_ms": 58.62280293949878,
      "p99_itl_ms": 70.55523046030432,
      "avg_batch_size": 63.985365853658536
    },
    {
      "model_id": "Qwen/Qwen3-14B",
      "nickname": "Qwen 3 14B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 14.0,
      "activated_params_billions": 14.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.3662634337367148,
      "energy_per_request_joules": 9599.698100812033,
      "avg_power_watts": 319.7883095908309,
      "median_itl_ms": 33.62808651581872,
      "output_throughput_tokens_per_sec": 227.7323240084629,
      "p90_itl_ms": 51.68297459313183,
      "p95_itl_ms": 57.232036642381004,
      "p99_itl_ms": 68.6399259546306,
      "avg_batch_size": 7.997300215982722
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1934264294192746,
      "energy_per_request_joules": 1631.7971343424108,
      "avg_power_watts": 477.13867767070093,
      "median_itl_ms": 56.67889100732282,
      "output_throughput_tokens_per_sec": 1290.8783076062641,
      "p90_itl_ms": 75.91897319653073,
      "p95_itl_ms": 82.61979750532187,
      "p99_itl_ms": 98.56466554396317,
      "avg_batch_size": 127.97109826589596
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7911158535301838,
      "energy_per_request_joules": 6413.084773811704,
      "avg_power_watts": 389.82085814005154,
      "median_itl_ms": 32.46195850078948,
      "output_throughput_tokens_per_sec": 474.48717906077445,
      "p90_itl_ms": 47.92680539540015,
      "p95_itl_ms": 52.92729524662718,
      "p99_itl_ms": 64.06189499393804,
      "avg_batch_size": 15.994067237969677
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.14587475427987087,
      "energy_per_request_joules": 1205.2448476546642,
      "avg_power_watts": 541.0238473628527,
      "median_itl_ms": 70.95763701363467,
      "output_throughput_tokens_per_sec": 1685.2777206984842,
      "p90_itl_ms": 100.13763199094683,
      "p95_itl_ms": 108.37734199594706,
      "p99_itl_ms": 130.12055170838727,
      "avg_batch_size": 241.4622222222222
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.49353726549342825,
      "energy_per_request_joules": 3950.743376762825,
      "avg_power_watts": 437.99892250325576,
      "median_itl_ms": 35.12723097810522,
      "output_throughput_tokens_per_sec": 820.9256648631948,
      "p90_itl_ms": 51.04164220392704,
      "p95_itl_ms": 56.551950084394775,
      "p99_itl_ms": 69.769805209944,
      "avg_batch_size": 31.989911727616647
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.08764893013466918,
      "energy_per_request_joules": 713.6920377342874,
      "avg_power_watts": 544.5395244066468,
      "median_itl_ms": 86.69960199040361,
      "output_throughput_tokens_per_sec": 1782.5590356250043,
      "p90_itl_ms": 110.86475100019015,
      "p95_itl_ms": 120.47574820753644,
      "p99_itl_ms": 168.23538968281358,
      "avg_batch_size": 459.52244897959184
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3046892441657647,
      "energy_per_request_joules": 2528.322119929481,
      "avg_power_watts": 470.6360547173012,
      "median_itl_ms": 40.632746007759124,
      "output_throughput_tokens_per_sec": 1115.6082732354787,
      "p90_itl_ms": 55.97567781805993,
      "p95_itl_ms": 61.806749395327614,
      "p99_itl_ms": 78.25580780045065,
      "avg_batch_size": 63.98337595907928
    },
    {
      "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "nickname": "Qwen 3 30B A3B Thinking",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 30.0,
      "activated_params_billions": 3.0,
      "architecture": "MoE",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.3199246936016353,
      "energy_per_request_joules": 10522.292999092948,
      "avg_power_watts": 304.76387398824545,
      "median_itl_ms": 35.00107250874862,
      "output_throughput_tokens_per_sec": 230.31277418592592,
      "p90_itl_ms": 49.47978199925274,
      "p95_itl_ms": 54.143508736160584,
      "p99_itl_ms": 64.42524934682295,
      "avg_batch_size": 7.994999242309441
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.31164114644078567,
      "energy_per_request_joules": 2192.2789932673077,
      "avg_power_watts": 773.7225635974955,
      "median_itl_ms": 44.815598492277786,
      "output_throughput_tokens_per_sec": 1117.615947092638,
      "p90_itl_ms": 66.26662090129686,
      "p95_itl_ms": 73.40900139533916,
      "p99_itl_ms": 93.98568142205445,
      "avg_batch_size": 110.90272373540856
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.2036432446524274,
      "energy_per_request_joules": 8475.344485106918,
      "avg_power_watts": 535.4159160187783,
      "median_itl_ms": 36.031765514053404,
      "output_throughput_tokens_per_sec": 402.20755022348277,
      "p90_itl_ms": 51.31638528255281,
      "p95_itl_ms": 56.57351335103158,
      "p99_itl_ms": 67.58948457922088,
      "avg_batch_size": 15.992758620689655
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6966952041094245,
      "energy_per_request_joules": 4777.615511481555,
      "avg_power_watts": 598.9941425870634,
      "median_itl_ms": 36.58818898838945,
      "output_throughput_tokens_per_sec": 718.4786013251795,
      "p90_itl_ms": 53.038106992607936,
      "p95_itl_ms": 58.64172961446455,
      "p99_itl_ms": 71.60381401889029,
      "avg_batch_size": 31.99245283018868
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.4672388908079148,
      "energy_per_request_joules": 3311.581596317252,
      "avg_power_watts": 707.0546636922346,
      "median_itl_ms": 41.3123504986288,
      "output_throughput_tokens_per_sec": 892.2088996163772,
      "p90_itl_ms": 61.044121911982074,
      "p95_itl_ms": 67.52462244767236,
      "p99_itl_ms": 82.44491031626241,
      "avg_batch_size": 63.98082595870206
    },
    {
      "model_id": "Qwen/Qwen3-32B",
      "nickname": "Qwen 3 32B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 32.0,
      "activated_params_billions": 32.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 2.353087353866999,
      "energy_per_request_joules": 17258.600354141854,
      "avg_power_watts": 423.00286890341283,
      "median_itl_ms": 44.14068500045687,
      "output_throughput_tokens_per_sec": 176.5952742588803,
      "p90_itl_ms": 60.802932805381715,
      "p95_itl_ms": 66.05900719296187,
      "p99_itl_ms": 76.88396901357919,
      "avg_batch_size": 7.997000130429112
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.17316993503795244,
      "energy_per_request_joules": 1398.175804687691,
      "avg_power_watts": 472.58146393316656,
      "median_itl_ms": 47.579443009453826,
      "output_throughput_tokens_per_sec": 1555.2819110617604,
      "p90_itl_ms": 64.1358269873308,
      "p95_itl_ms": 70.02033341268543,
      "p99_itl_ms": 83.70254459936403,
      "avg_batch_size": 127.98022598870057
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7138391593500603,
      "energy_per_request_joules": 5854.724917326937,
      "avg_power_watts": 304.31011132656556,
      "median_itl_ms": 37.66740398714319,
      "output_throughput_tokens_per_sec": 403.9025267193931,
      "p90_itl_ms": 52.25049519212916,
      "p95_itl_ms": 57.20704859122633,
      "p99_itl_ms": 67.45306412107313,
      "avg_batch_size": 15.995779403489026
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.3946668428150449,
      "energy_per_request_joules": 3122.321016455263,
      "avg_power_watts": 326.6393169560532,
      "median_itl_ms": 38.1577279913472,
      "output_throughput_tokens_per_sec": 671.2354008235865,
      "p90_itl_ms": 54.285689402604476,
      "p95_itl_ms": 59.819998107559506,
      "p99_itl_ms": 71.81604661076557,
      "avg_batch_size": 31.992588017294626
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.26219436527337686,
      "energy_per_request_joules": 2194.0490696774477,
      "avg_power_watts": 399.953480739732,
      "median_itl_ms": 41.416758991545066,
      "output_throughput_tokens_per_sec": 1034.28317292298,
      "p90_itl_ms": 57.11176401237026,
      "p95_itl_ms": 62.85961919347753,
      "p99_itl_ms": 74.74726952263156,
      "avg_batch_size": 63.989285714285714
    },
    {
      "model_id": "Qwen/Qwen3-8B",
      "nickname": "Qwen 3 8B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 8.0,
      "activated_params_billions": 8.0,
      "architecture": "Dense Transformer",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.1709007963039468,
      "energy_per_request_joules": 9706.6138467097,
      "avg_power_watts": 293.91033781272114,
      "median_itl_ms": 32.49889700964559,
      "output_throughput_tokens_per_sec": 249.53360925766617,
      "p90_itl_ms": 47.97513481462374,
      "p95_itl_ms": 52.595734488568255,
      "p99_itl_ms": 61.82553002727218,
      "avg_batch_size": 7.998084596967279
    },
    {
      "model_id": "deepseek-ai/DeepSeek-R1-0528",
      "nickname": "DeepSeek R1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 2.3761518703101916,
      "energy_per_request_joules": 26819.638160958155,
      "avg_power_watts": 7126.160762314122,
      "median_itl_ms": 44.80024399526883,
      "output_throughput_tokens_per_sec": 1855.8661317485244,
      "p90_itl_ms": 55.71015099849319,
      "p95_itl_ms": 57.22191849781666,
      "p99_itl_ms": 70.27125449895033,
      "avg_batch_size": 127.98820754716981
    },
    {
      "model_id": "deepseek-ai/DeepSeek-R1-0528",
      "nickname": "DeepSeek R1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 7.121823518199807,
      "energy_per_request_joules": 81506.39266134499,
      "avg_power_watts": 4911.310683149415,
      "median_itl_ms": 23.074202499628882,
      "output_throughput_tokens_per_sec": 658.6502395696727,
      "p90_itl_ms": 24.405937698247726,
      "p95_itl_ms": 24.694001998250315,
      "p99_itl_ms": 25.37768642858282,
      "avg_batch_size": 15.998377676833226
    },
    {
      "model_id": "deepseek-ai/DeepSeek-R1-0528",
      "nickname": "DeepSeek R1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 5.325354212945934,
      "energy_per_request_joules": 59106.24088812866,
      "avg_power_watts": 5398.11355380596,
      "median_itl_ms": 31.792588000826072,
      "output_throughput_tokens_per_sec": 929.9000266372047,
      "p90_itl_ms": 33.83861699694535,
      "p95_itl_ms": 34.92035549788852,
      "p99_itl_ms": 36.30347400103346,
      "avg_batch_size": 31.99740529320187
    },
    {
      "model_id": "deepseek-ai/DeepSeek-R1-0528",
      "nickname": "DeepSeek R1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.8585186465566834,
      "energy_per_request_joules": 44599.83753683223,
      "avg_power_watts": 6156.141760730251,
      "median_itl_ms": 40.92244700223091,
      "output_throughput_tokens_per_sec": 1318.587007841042,
      "p90_itl_ms": 46.50866350129945,
      "p95_itl_ms": 47.99175275002199,
      "p99_itl_ms": 49.16423429895076,
      "avg_batch_size": 63.99813953488372
    },
    {
      "model_id": "deepseek-ai/DeepSeek-R1-0528",
      "nickname": "DeepSeek R1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 9.873897137623922,
      "energy_per_request_joules": 117113.0472451733,
      "avg_power_watts": 4277.775202157113,
      "median_itl_ms": 18.35748300072737,
      "output_throughput_tokens_per_sec": 427.1691672970253,
      "p90_itl_ms": 19.096106800134294,
      "p95_itl_ms": 19.433520199527266,
      "p99_itl_ms": 20.211977198632663,
      "avg_batch_size": 7.998855180309102
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.8015998979948604,
      "energy_per_request_joules": 16274.998351249935,
      "avg_power_watts": 6159.417027277624,
      "median_itl_ms": 39.19294099978288,
      "output_throughput_tokens_per_sec": 1506.8565536135932,
      "p90_itl_ms": 43.72462259925669,
      "p95_itl_ms": 45.05074470034742,
      "p99_itl_ms": 46.65174832058254,
      "avg_batch_size": 127.97902097902097
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 7.342813641173804,
      "energy_per_request_joules": 65303.98064629207,
      "avg_power_watts": 4907.697680581875,
      "median_itl_ms": 23.8196899954346,
      "output_throughput_tokens_per_sec": 631.053211049158,
      "p90_itl_ms": 25.742184797127265,
      "p95_itl_ms": 26.12001999950735,
      "p99_itl_ms": 26.771409560169552,
      "avg_batch_size": 15.996767676767677
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 1.335067633023306,
      "energy_per_request_joules": 11973.79343495625,
      "avg_power_watts": 6855.990889183953,
      "median_itl_ms": 55.46886500087567,
      "output_throughput_tokens_per_sec": 1818.2131600753107,
      "p90_itl_ms": 60.28186200273922,
      "p95_itl_ms": 62.36090200400213,
      "p99_itl_ms": 86.3645200006431,
      "avg_batch_size": 255.97607655502392
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 5.458517998694013,
      "energy_per_request_joules": 49442.84250807956,
      "avg_power_watts": 5364.666963511194,
      "median_itl_ms": 32.800897999550216,
      "output_throughput_tokens_per_sec": 805.9447095465853,
      "p90_itl_ms": 36.317284997494426,
      "p95_itl_ms": 37.307107500964776,
      "p99_itl_ms": 38.29792009710218,
      "avg_batch_size": 31.993279569892472
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 3.517068637654103,
      "energy_per_request_joules": 30513.483559207805,
      "avg_power_watts": 6041.29130155796,
      "median_itl_ms": 37.47100649707136,
      "output_throughput_tokens_per_sec": 1160.5857168272917,
      "p90_itl_ms": 44.22798000450712,
      "p95_itl_ms": 45.16777925164206,
      "p99_itl_ms": 46.848201301327215,
      "avg_batch_size": 63.998511904761905
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3.1",
      "nickname": "DeepSeek V3.1",
      "gpu_model": "B200",
      "num_gpus": 8,
      "total_params_billions": 671.0,
      "activated_params_billions": 37.0,
      "architecture": "MoE",
      "weight_precision": "fp8",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 8,
      "data_parallel": 1,
      "energy_per_token_joules": 10.052949516392252,
      "energy_per_request_joules": 91299.6181960668,
      "avg_power_watts": 4260.855254483721,
      "median_itl_ms": 18.759104001219384,
      "output_throughput_tokens_per_sec": 412.5740310098022,
      "p90_itl_ms": 19.818756598397158,
      "p95_itl_ms": 20.0225453969324,
      "p99_itl_ms": 20.331353237852454,
      "avg_batch_size": 7.999508720216163
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.48589007854707056,
      "energy_per_request_joules": 848.6438320368941,
      "avg_power_watts": 659.8314270319853,
      "median_itl_ms": 5.45397300447803,
      "output_throughput_tokens_per_sec": 1327.665768682751,
      "p90_itl_ms": 7.809739495860412,
      "p95_itl_ms": 10.606128258223157,
      "p99_itl_ms": 15.62396485416682,
      "avg_batch_size": 7.991869918699187
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.05527369879417791,
      "energy_per_request_joules": 101.28340004840888,
      "avg_power_watts": 893.2711214812631,
      "median_itl_ms": 30.294244992546737,
      "output_throughput_tokens_per_sec": 8764.548873110123,
      "p90_itl_ms": 39.1099724045489,
      "p95_itl_ms": 41.19197288819123,
      "p99_itl_ms": 46.34756007755641,
      "avg_batch_size": 511.8181818181818
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.04384929406737634,
      "energy_per_request_joules": 78.97161895065982,
      "avg_power_watts": 779.0159052431786,
      "median_itl_ms": 47.406072000740096,
      "output_throughput_tokens_per_sec": 7284.536862045076,
      "p90_itl_ms": 74.54672059975564,
      "p95_itl_ms": 91.96001079981212,
      "p99_itl_ms": 114.10652056219992,
      "avg_batch_size": 1023.5641025641025
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.11640061102748535,
      "energy_per_request_joules": 211.29297581733644,
      "avg_power_watts": 855.147302556861,
      "median_itl_ms": 16.48175199807156,
      "output_throughput_tokens_per_sec": 3152.0661039565425,
      "p90_itl_ms": 24.28926430293359,
      "p95_itl_ms": 27.64103554654866,
      "p99_itl_ms": 34.404707649373435,
      "avg_batch_size": 127.92647058823529
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.331038216179351,
      "energy_per_request_joules": 594.504510413729,
      "avg_power_watts": 699.6688036032991,
      "median_itl_ms": 6.901834000018425,
      "output_throughput_tokens_per_sec": 2010.2920473222252,
      "p90_itl_ms": 12.178540087188598,
      "p95_itl_ms": 13.999344779585952,
      "p99_itl_ms": 19.26879448117685,
      "avg_batch_size": 15.974358974358974
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.042068700052336,
      "energy_per_request_joules": 76.08211162305982,
      "avg_power_watts": 713.4358023979836,
      "median_itl_ms": 130.05510000220966,
      "output_throughput_tokens_per_sec": 7809.391278419233,
      "p90_itl_ms": 181.18592360115147,
      "p95_itl_ms": 191.36647525156147,
      "p99_itl_ms": 218.87476456176947,
      "avg_batch_size": 2047.3855421686746
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.0396667643642537,
      "energy_per_request_joules": 71.14999922002823,
      "avg_power_watts": 673.5046499567148,
      "median_itl_ms": 175.4405300016515,
      "output_throughput_tokens_per_sec": 6543.693795892051,
      "p90_itl_ms": 210.95160601544194,
      "p95_itl_ms": 225.76437098905444,
      "p99_itl_ms": 319.45279978972377,
      "avg_batch_size": 2885.2268907563025
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.258165017860706,
      "energy_per_request_joules": 458.5115026304264,
      "avg_power_watts": 717.9210601086755,
      "median_itl_ms": 10.07053600915242,
      "output_throughput_tokens_per_sec": 2362.8178516975754,
      "p90_itl_ms": 17.513591202441606,
      "p95_itl_ms": 20.429867868369914,
      "p99_itl_ms": 26.98967366071887,
      "avg_batch_size": 31.99074074074074
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.18062173709145077,
      "energy_per_request_joules": 314.0181877814504,
      "avg_power_watts": 762.2634694014198,
      "median_itl_ms": 13.951387998531573,
      "output_throughput_tokens_per_sec": 3171.3401107313657,
      "p90_itl_ms": 22.22058200277388,
      "p95_itl_ms": 25.4594292564434,
      "p99_itl_ms": 32.2278789491975,
      "avg_batch_size": 64.0
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.08008394787392092,
      "energy_per_request_joules": 149.05712431983224,
      "avg_power_watts": 952.0882696308249,
      "median_itl_ms": 20.717412000522017,
      "output_throughput_tokens_per_sec": 5018.360570726602,
      "p90_itl_ms": 25.696520385099575,
      "p95_itl_ms": 27.278679786832072,
      "p99_itl_ms": 31.382965607917868,
      "avg_batch_size": 255.83870967741936
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.43141800838899413,
      "energy_per_request_joules": 706.148482337234,
      "avg_power_watts": 1207.9932870816103,
      "median_itl_ms": 5.63221650372725,
      "output_throughput_tokens_per_sec": 2664.115875853775,
      "p90_itl_ms": 5.898638404323719,
      "p95_itl_ms": 6.022722747002263,
      "p99_itl_ms": 7.582832919433715,
      "avg_batch_size": 15.981481481481481
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.06570325234324967,
      "energy_per_request_joules": 108.47488054469393,
      "avg_power_watts": 1472.5107613760902,
      "median_itl_ms": 88.74269849911798,
      "output_throughput_tokens_per_sec": 9334.489462103811,
      "p90_itl_ms": 155.07174840313382,
      "p95_itl_ms": 176.24314289423634,
      "p99_itl_ms": 229.7573606693185,
      "avg_batch_size": 2047.27868852459
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.06084576786611849,
      "energy_per_request_joules": 99.88134975383628,
      "avg_power_watts": 1327.4665650816123,
      "median_itl_ms": 158.94596549333073,
      "output_throughput_tokens_per_sec": 10850.962083404595,
      "p90_itl_ms": 217.16104648658074,
      "p95_itl_ms": 261.172524507856,
      "p99_itl_ms": 430.8699949106085,
      "avg_batch_size": 3071.1685393258426
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.30024083297792514,
      "energy_per_request_joules": 497.9539705974188,
      "avg_power_watts": 1355.6628027133322,
      "median_itl_ms": 6.954117503482848,
      "output_throughput_tokens_per_sec": 3928.871669243254,
      "p90_itl_ms": 7.299648894695566,
      "p95_itl_ms": 7.457647251430899,
      "p99_itl_ms": 13.230332161183485,
      "avg_batch_size": 31.921875
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.06082515167539012,
      "energy_per_request_joules": 99.41804481833107,
      "avg_power_watts": 1301.8971482487527,
      "median_itl_ms": 208.13817699672654,
      "output_throughput_tokens_per_sec": 10552.670898858378,
      "p90_itl_ms": 291.7018283129438,
      "p95_itl_ms": 378.0616642499807,
      "p99_itl_ms": 633.2739127724216,
      "avg_batch_size": 4095.0243902439024
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.20634999001322119,
      "energy_per_request_joules": 321.8872253306239,
      "avg_power_watts": 1462.743173222873,
      "median_itl_ms": 8.798983006272465,
      "output_throughput_tokens_per_sec": 5589.325957876669,
      "p90_itl_ms": 9.287583603872918,
      "p95_itl_ms": 9.778764459770171,
      "p99_itl_ms": 16.495890735241122,
      "avg_batch_size": 63.91428571428571
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.6277227456303269,
      "energy_per_request_joules": 982.7316614532481,
      "avg_power_watts": 1067.9081734775832,
      "median_itl_ms": 4.657438985304907,
      "output_throughput_tokens_per_sec": 1656.0207832005522,
      "p90_itl_ms": 4.903670208295807,
      "p95_itl_ms": 5.0160094047896555,
      "p99_itl_ms": 5.42817416368052,
      "avg_batch_size": 8.0
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.07189915713799827,
      "energy_per_request_joules": 117.38979535944479,
      "avg_power_watts": 1512.14937374798,
      "median_itl_ms": 40.83580899168737,
      "output_throughput_tokens_per_sec": 14227.19316284115,
      "p90_itl_ms": 65.67976798978636,
      "p95_itl_ms": 75.68022679188287,
      "p99_itl_ms": 85.90234324452462,
      "avg_batch_size": 1023.6326530612245
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.14774330548433176,
      "energy_per_request_joules": 260.03008309820024,
      "avg_power_watts": 1517.7596917099556,
      "median_itl_ms": 12.117908016080037,
      "output_throughput_tokens_per_sec": 3931.7904735241655,
      "p90_itl_ms": 13.056740420870485,
      "p95_itl_ms": 14.86866000341251,
      "p99_itl_ms": 18.686776203103364,
      "avg_batch_size": 127.93877551020408
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.10590367705490719,
      "energy_per_request_joules": 177.555715877408,
      "avg_power_watts": 1658.658721130682,
      "median_itl_ms": 15.680338983656839,
      "output_throughput_tokens_per_sec": 11082.785272559733,
      "p90_itl_ms": 19.89219079259783,
      "p95_itl_ms": 21.525613620178767,
      "p99_itl_ms": 25.227223421679767,
      "avg_batch_size": 255.8409090909091
    },
    {
      "model_id": "openai/gpt-oss-120b",
      "nickname": "GPT OSS 120B",
      "gpu_model": "B200",
      "num_gpus": 2,
      "total_params_billions": 117.0,
      "activated_params_billions": 5.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.08160209861766116,
      "energy_per_request_joules": 136.5259777997511,
      "avg_power_watts": 1642.7936294692759,
      "median_itl_ms": 24.378373025683686,
      "output_throughput_tokens_per_sec": 12786.649833876525,
      "p90_itl_ms": 30.872450990136716,
      "p95_itl_ms": 32.35608909744769,
      "p99_itl_ms": 38.31311052374076,
      "avg_batch_size": 511.8787878787879
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.031751574890477696,
      "energy_per_request_joules": 68.5366296623726,
      "avg_power_watts": 583.481621181594,
      "median_itl_ms": 44.50300549797248,
      "output_throughput_tokens_per_sec": 7637.002757018188,
      "p90_itl_ms": 64.08914560161067,
      "p95_itl_ms": 73.77117075666317,
      "p99_itl_ms": 94.47647912660598,
      "avg_batch_size": 1023.675
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1855606217811399,
      "energy_per_request_joules": 384.04394767207856,
      "avg_power_watts": 513.785257446052,
      "median_itl_ms": 4.509860009420663,
      "output_throughput_tokens_per_sec": 2183.9421218089165,
      "p90_itl_ms": 10.367306612897664,
      "p95_itl_ms": 12.821885108132841,
      "p99_itl_ms": 17.887397630838677,
      "avg_batch_size": 15.984848484848484
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.029096299281516816,
      "energy_per_request_joules": 60.739727076582945,
      "avg_power_watts": 646.0116180331404,
      "median_itl_ms": 100.45418801018968,
      "output_throughput_tokens_per_sec": 7767.155605623179,
      "p90_itl_ms": 154.7147459932603,
      "p95_itl_ms": 168.74005200224929,
      "p99_itl_ms": 202.7145073952852,
      "avg_batch_size": 2047.6190476190477
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.11750739350071196,
      "energy_per_request_joules": 232.59757683107844,
      "avg_power_watts": 538.147180607641,
      "median_itl_ms": 5.727601004764438,
      "output_throughput_tokens_per_sec": 3336.873764457845,
      "p90_itl_ms": 11.368510196916759,
      "p95_itl_ms": 13.393376593012361,
      "p99_itl_ms": 18.13099972088821,
      "avg_batch_size": 31.971830985915492
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.03930383397106875,
      "energy_per_request_joules": 84.46903414526743,
      "avg_power_watts": 632.425119864397,
      "median_itl_ms": 23.48228602204472,
      "output_throughput_tokens_per_sec": 6104.409725777548,
      "p90_itl_ms": 31.958975974703208,
      "p95_itl_ms": 34.95753000606783,
      "p99_itl_ms": 42.108738009119406,
      "avg_batch_size": 383.8888888888889
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.028446538525400376,
      "energy_per_request_joules": 61.010607460662435,
      "avg_power_watts": 611.6523805816164,
      "median_itl_ms": 247.04576301155612,
      "output_throughput_tokens_per_sec": 6245.270220139028,
      "p90_itl_ms": 302.44145499309525,
      "p95_itl_ms": 320.59122440405184,
      "p99_itl_ms": 496.94883844233124,
      "avg_batch_size": 4094.6792452830186
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.07986205748417002,
      "energy_per_request_joules": 167.1883939370373,
      "avg_power_watts": 563.355340144207,
      "median_itl_ms": 7.655216002603993,
      "output_throughput_tokens_per_sec": 4107.136719788761,
      "p90_itl_ms": 14.44086320407223,
      "p95_itl_ms": 16.68027670384617,
      "p99_itl_ms": 21.58955227700063,
      "avg_batch_size": 63.926829268292686
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.29292334743035825,
      "energy_per_request_joules": 620.2208058584154,
      "avg_power_watts": 487.34635115324164,
      "median_itl_ms": 3.8020270003471524,
      "output_throughput_tokens_per_sec": 1430.7844311671633,
      "p90_itl_ms": 9.665562404552476,
      "p95_itl_ms": 13.152091996744264,
      "p99_itl_ms": 21.139187243534284,
      "avg_batch_size": 7.991379310344827
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.06576209451590981,
      "energy_per_request_joules": 142.2952229972285,
      "avg_power_watts": 503.0141640098874,
      "median_itl_ms": 16.269230996840633,
      "output_throughput_tokens_per_sec": 3767.761066495779,
      "p90_itl_ms": 25.47600100806449,
      "p95_itl_ms": 29.14400730514898,
      "p99_itl_ms": 37.37342791602716,
      "avg_batch_size": 127.92307692307692
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.05250230002078284,
      "energy_per_request_joules": 110.89749708649097,
      "avg_power_watts": 428.61381219910135,
      "median_itl_ms": 28.6903619999066,
      "output_throughput_tokens_per_sec": 4846.57431073589,
      "p90_itl_ms": 43.16039238474332,
      "p95_itl_ms": 47.189951204927624,
      "p99_itl_ms": 56.821500119985984,
      "avg_batch_size": 255.83870967741936
    },
    {
      "model_id": "openai/gpt-oss-20b",
      "nickname": "GPT OSS 20B",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 21.0,
      "activated_params_billions": 4.0,
      "architecture": "MoE",
      "weight_precision": "mxfp4",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.040652137966608944,
      "energy_per_request_joules": 87.45116663312852,
      "avg_power_watts": 466.76314556477615,
      "median_itl_ms": 39.73364799458068,
      "output_throughput_tokens_per_sec": 5055.084856060558,
      "p90_itl_ms": 55.37156941718422,
      "p95_itl_ms": 60.71473978081483,
      "p99_itl_ms": 73.14953174296534,
      "avg_batch_size": 511.796875
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.17871064102765521,
      "energy_per_request_joules": 958.3800388815604,
      "avg_power_watts": 617.5188043427743,
      "median_itl_ms": 37.741620995802805,
      "output_throughput_tokens_per_sec": 1037.5190827911192,
      "p90_itl_ms": 51.527896503102966,
      "p95_itl_ms": 56.18451876944164,
      "p99_itl_ms": 72.05681301275035,
      "avg_batch_size": 127.95172413793104
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.7851650200387422,
      "energy_per_request_joules": 4173.290873302386,
      "avg_power_watts": 294.01141412167726,
      "median_itl_ms": 42.41862602066249,
      "output_throughput_tokens_per_sec": 351.92493270925115,
      "p90_itl_ms": 57.58789060055278,
      "p95_itl_ms": 62.42287452041636,
      "p99_itl_ms": 73.43502314528448,
      "avg_batch_size": 15.990814696485623
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.14527273421099182,
      "energy_per_request_joules": 820.2135258586491,
      "avg_power_watts": 839.8617236905329,
      "median_itl_ms": 44.9442325043492,
      "output_throughput_tokens_per_sec": 2043.0748379953584,
      "p90_itl_ms": 58.51926428731531,
      "p95_itl_ms": 63.66154285351514,
      "p99_itl_ms": 88.49739996599965,
      "avg_batch_size": 255.8941798941799
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.46442364627473237,
      "energy_per_request_joules": 2543.9907644464874,
      "avg_power_watts": 341.9688762760672,
      "median_itl_ms": 43.968714991933666,
      "output_throughput_tokens_per_sec": 536.1784855021349,
      "p90_itl_ms": 58.21801437996328,
      "p95_itl_ms": 63.09183749690418,
      "p99_itl_ms": 74.71878460957672,
      "avg_batch_size": 31.988066825775658
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.24751712623101718,
      "energy_per_request_joules": 1289.311710191384,
      "avg_power_watts": 450.3250742846279,
      "median_itl_ms": 34.16159101470839,
      "output_throughput_tokens_per_sec": 921.9063664372638,
      "p90_itl_ms": 48.303987813415,
      "p95_itl_ms": 53.22484479111147,
      "p99_itl_ms": 69.65389303863041,
      "avg_batch_size": 63.959493670886076
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
      "nickname": "NVIDIA Nemotron Nano 12B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 12.0,
      "activated_params_billions": 12.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 1.2286539045913898,
      "energy_per_request_joules": 6185.8442423478655,
      "avg_power_watts": 300.8338981625736,
      "median_itl_ms": 33.29829699941911,
      "output_throughput_tokens_per_sec": 242.12625778355843,
      "p90_itl_ms": 50.403734209248796,
      "p95_itl_ms": 55.62224350869654,
      "p99_itl_ms": 66.75623906368855,
      "avg_batch_size": 7.99591211037302
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.15950403131571084,
      "energy_per_request_joules": 887.2613135915349,
      "avg_power_watts": 530.4339142801433,
      "median_itl_ms": 37.856785507756285,
      "output_throughput_tokens_per_sec": 1968.4721171436452,
      "p90_itl_ms": 53.07521491777152,
      "p95_itl_ms": 58.64271321188425,
      "p99_itl_ms": 79.10111178702209,
      "avg_batch_size": 127.93582887700535
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.5212551517096778,
      "energy_per_request_joules": 2983.29065893396,
      "avg_power_watts": 340.6810701125498,
      "median_itl_ms": 23.126269501517527,
      "output_throughput_tokens_per_sec": 606.7755575025354,
      "p90_itl_ms": 37.65707430429758,
      "p95_itl_ms": 42.44033214490628,
      "p99_itl_ms": 53.19268749764874,
      "avg_batch_size": 15.986198243412797
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.1322580585142048,
      "energy_per_request_joules": 741.1076968993503,
      "avg_power_watts": 686.8867989048252,
      "median_itl_ms": 45.075016998453066,
      "output_throughput_tokens_per_sec": 3372.802219299272,
      "p90_itl_ms": 73.60894620069303,
      "p95_itl_ms": 82.9855680058245,
      "p99_itl_ms": 105.91077668126681,
      "avg_batch_size": 255.92244897959185
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.30169388358162796,
      "energy_per_request_joules": 1610.787831930311,
      "avg_power_watts": 376.7544981082948,
      "median_itl_ms": 24.657885980559513,
      "output_throughput_tokens_per_sec": 1095.3424202295532,
      "p90_itl_ms": 38.339399400865666,
      "p95_itl_ms": 43.069945805473175,
      "p99_itl_ms": 54.09749420243314,
      "avg_batch_size": 31.986577181208055
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.11675020881368221,
      "energy_per_request_joules": 625.8982625484965,
      "avg_power_watts": 923.2141960719636,
      "median_itl_ms": 72.19255898962729,
      "output_throughput_tokens_per_sec": 3854.4665936233905,
      "p90_itl_ms": 98.27076219080482,
      "p95_itl_ms": 106.4502715220441,
      "p99_itl_ms": 129.05968089733503,
      "avg_batch_size": 511.936
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.22121150797713868,
      "energy_per_request_joules": 1229.8968813085517,
      "avg_power_watts": 454.59715473092245,
      "median_itl_ms": 29.164551000576466,
      "output_throughput_tokens_per_sec": 1301.185308148425,
      "p90_itl_ms": 45.27728440007195,
      "p95_itl_ms": 50.837154596229055,
      "p99_itl_ms": 67.88686528278053,
      "avg_batch_size": 63.9719387755102
    },
    {
      "model_id": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
      "nickname": "NVIDIA Nemotron Nano 9B V2",
      "gpu_model": "B200",
      "num_gpus": 1,
      "total_params_billions": 9.0,
      "activated_params_billions": 9.0,
      "architecture": "Mamba-Transformer Hybrid",
      "weight_precision": "bfloat16",
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "tensor_parallel": 1,
      "expert_parallel": 1,
      "data_parallel": 1,
      "energy_per_token_joules": 0.8196465956608674,
      "energy_per_request_joules": 4306.510145816889,
      "avg_power_watts": 352.67216243039917,
      "median_itl_ms": 17.254578007850796,
      "output_throughput_tokens_per_sec": 426.42680700692335,
      "p90_itl_ms": 31.70320179779082,
      "p95_itl_ms": 36.6122944978997,
      "p99_itl_ms": 46.534189914818846,
      "avg_batch_size": 7.99564649542882
    }
  ]
}