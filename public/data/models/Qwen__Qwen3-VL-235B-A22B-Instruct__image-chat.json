{
  "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
  "task": "image-chat",
  "total_params_billions": 235.0,
  "activated_params_billions": 22.0,
  "architecture": "MoE",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      3.0,
      84.86,
      166.72,
      248.57999999999998,
      330.44,
      412.3,
      494.15999999999997,
      576.02,
      657.88,
      739.74,
      821.6,
      903.46,
      985.3199999999999,
      1067.18,
      1149.04,
      1230.9,
      1312.76,
      1394.62,
      1476.48,
      1558.34,
      1640.2,
      1722.06,
      1803.92,
      1885.78,
      1967.6399999999999,
      2049.5,
      2131.36,
      2213.22,
      2295.08,
      2376.94,
      2458.8,
      2540.66,
      2622.52,
      2704.38,
      2786.24,
      2868.1,
      2949.96,
      3031.82,
      3113.68,
      3195.54,
      3277.4,
      3359.2599999999998,
      3441.12,
      3522.98,
      3604.84,
      3686.7,
      3768.56,
      3850.42,
      3932.2799999999997,
      4014.14,
      4096.0
    ],
    "counts": [
      1562,
      1518,
      2078,
      3171,
      3134,
      2979,
      2844,
      2325,
      1875,
      1590,
      1477,
      1234,
      951,
      872,
      773,
      711,
      586,
      544,
      490,
      457,
      392,
      365,
      340,
      325,
      305,
      288,
      256,
      232,
      180,
      180,
      180,
      155,
      154,
      142,
      155,
      100,
      125,
      83,
      90,
      86,
      70,
      59,
      52,
      64,
      60,
      41,
      51,
      51,
      46,
      1066
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 5.136495244410268,
      "energy_per_request_joules": 4791.030826463218,
      "avg_output_len": 932.7431640625,
      "avg_power_watts": 2841.8114988827124,
      "median_itl_ms": 27.37360540777445,
      "p90_itl_ms": 28.28204296529293,
      "p95_itl_ms": 29.233950867571615,
      "p99_itl_ms": 111.12419929355383,
      "output_throughput_tokens_per_sec": 553.2588591365447,
      "avg_batch_size": 15.982727814175105,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          46,
          36,
          58,
          79,
          102,
          82,
          71,
          52,
          63,
          57,
          42,
          31,
          32,
          24,
          18,
          19,
          14,
          19,
          9,
          16,
          7,
          9,
          8,
          11,
          7,
          7,
          7,
          9,
          3,
          6,
          6,
          5,
          4,
          5,
          1,
          0,
          4,
          2,
          4,
          5,
          2,
          3,
          1,
          0,
          2,
          1,
          1,
          4,
          3,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.8395604792118903,
      "energy_per_request_joules": 3554.608098178505,
      "avg_output_len": 925.78515625,
      "avg_power_watts": 3049.2194705464035,
      "median_itl_ms": 37.81948797404766,
      "p90_itl_ms": 39.09982144832611,
      "p95_itl_ms": 42.64666661620134,
      "p99_itl_ms": 116.63883622735739,
      "output_throughput_tokens_per_sec": 794.15846867251,
      "avg_batch_size": 31.954664341761116,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          38,
          63,
          93,
          86,
          72,
          73,
          70,
          64,
          49,
          46,
          24,
          29,
          23,
          25,
          17,
          18,
          10,
          12,
          16,
          11,
          8,
          4,
          5,
          12,
          7,
          4,
          7,
          7,
          7,
          5,
          4,
          2,
          6,
          7,
          5,
          5,
          1,
          1,
          1,
          1,
          2,
          3,
          1,
          0,
          0,
          1,
          2,
          2,
          31
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.5697371745541453,
      "energy_per_request_joules": 2425.7139458580154,
      "avg_output_len": 943.9541015625,
      "avg_power_watts": 3551.0381833591005,
      "median_itl_ms": 41.118471999652684,
      "p90_itl_ms": 46.23301705271986,
      "p95_itl_ms": 112.81313904328272,
      "p99_itl_ms": 122.29739578906447,
      "output_throughput_tokens_per_sec": 1381.8682387140284,
      "avg_batch_size": 63.635239567233384,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          42,
          44,
          58,
          83,
          75,
          93,
          77,
          68,
          58,
          34,
          35,
          36,
          30,
          32,
          13,
          28,
          15,
          17,
          17,
          15,
          9,
          8,
          12,
          8,
          8,
          9,
          8,
          4,
          1,
          2,
          8,
          2,
          2,
          3,
          3,
          9,
          6,
          0,
          4,
          3,
          2,
          2,
          1,
          2,
          2,
          0,
          0,
          2,
          0,
          34
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 7.2639104637587995,
      "energy_per_request_joules": 6681.882544187563,
      "avg_output_len": 919.8740234375,
      "avg_power_watts": 2548.7774892329094,
      "median_itl_ms": 22.06612192094326,
      "p90_itl_ms": 22.59829081594944,
      "p95_itl_ms": 22.774748411029577,
      "p99_itl_ms": 28.695954624563605,
      "output_throughput_tokens_per_sec": 350.882283303092,
      "avg_batch_size": 7.992794842624194,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          41,
          58,
          83,
          96,
          83,
          66,
          81,
          36,
          54,
          38,
          39,
          26,
          21,
          18,
          19,
          27,
          19,
          13,
          8,
          15,
          8,
          18,
          6,
          5,
          4,
          3,
          7,
          4,
          9,
          6,
          5,
          8,
          5,
          5,
          1,
          4,
          2,
          0,
          1,
          0,
          2,
          2,
          1,
          3,
          1,
          0,
          1,
          1,
          28
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 8.821869510657029,
      "energy_per_request_joules": 8201.978105608381,
      "avg_output_len": 929.732421875,
      "avg_power_watts": 3936.415295392636,
      "median_itl_ms": 16.99093749630265,
      "p90_itl_ms": 17.36446830618661,
      "p95_itl_ms": 17.49838084942894,
      "p99_itl_ms": 23.04213037714363,
      "output_throughput_tokens_per_sec": 446.2110089746116,
      "avg_batch_size": 7.995256166982922,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          40,
          53,
          92,
          83,
          81,
          88,
          78,
          52,
          31,
          42,
          34,
          29,
          25,
          17,
          21,
          16,
          16,
          9,
          14,
          8,
          13,
          7,
          11,
          7,
          10,
          6,
          7,
          7,
          3,
          2,
          7,
          4,
          5,
          5,
          4,
          1,
          1,
          0,
          4,
          4,
          2,
          5,
          1,
          0,
          4,
          2,
          0,
          3,
          26
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 5.880019860711525,
      "energy_per_request_joules": 5464.163495152356,
      "avg_output_len": 929.2763671875,
      "avg_power_watts": 4506.532286176022,
      "median_itl_ms": 19.29430599557236,
      "p90_itl_ms": 19.747296592686325,
      "p95_itl_ms": 20.096971286693588,
      "p99_itl_ms": 108.61843928229064,
      "output_throughput_tokens_per_sec": 766.4144667754064,
      "avg_batch_size": 15.984310487200661,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          45,
          41,
          51,
          95,
          90,
          78,
          69,
          62,
          53,
          57,
          40,
          38,
          28,
          15,
          23,
          21,
          17,
          12,
          16,
          13,
          14,
          9,
          10,
          10,
          9,
          10,
          9,
          5,
          3,
          2,
          6,
          3,
          6,
          8,
          4,
          3,
          2,
          3,
          0,
          0,
          0,
          4,
          1,
          5,
          2,
          1,
          1,
          0,
          3,
          27
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.6756257296287536,
      "energy_per_request_joules": 1571.46857245851,
      "avg_output_len": 937.83984375,
      "avg_power_watts": 4602.197618907625,
      "median_itl_ms": 35.95125699939672,
      "p90_itl_ms": 111.60590850922745,
      "p95_itl_ms": 120.82438318611821,
      "p99_itl_ms": 130.99571911472597,
      "output_throughput_tokens_per_sec": 2746.5546377873256,
      "avg_batch_size": 127.89180327868853,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          40,
          52,
          99,
          89,
          74,
          83,
          62,
          46,
          44,
          50,
          34,
          27,
          25,
          22,
          22,
          20,
          15,
          14,
          6,
          8,
          18,
          4,
          8,
          6,
          10,
          8,
          3,
          4,
          9,
          5,
          2,
          8,
          2,
          3,
          2,
          6,
          6,
          3,
          2,
          2,
          1,
          3,
          1,
          1,
          0,
          0,
          1,
          0,
          33
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.295307244518345,
      "energy_per_request_joules": 1206.955652916169,
      "avg_output_len": 931.791015625,
      "avg_power_watts": 4544.812262104229,
      "median_itl_ms": 40.00539449043572,
      "p90_itl_ms": 122.15834460803308,
      "p95_itl_ms": 128.3428728493163,
      "p99_itl_ms": 142.38776387501272,
      "output_throughput_tokens_per_sec": 3508.6750895106748,
      "avg_batch_size": 191.86036036036037,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          41,
          58,
          88,
          94,
          73,
          89,
          55,
          55,
          38,
          42,
          33,
          21,
          34,
          23,
          22,
          16,
          13,
          14,
          13,
          11,
          11,
          8,
          9,
          7,
          9,
          8,
          10,
          3,
          3,
          5,
          4,
          4,
          5,
          2,
          2,
          7,
          3,
          2,
          3,
          0,
          0,
          4,
          1,
          3,
          0,
          3,
          1,
          2,
          28
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.0990031522849555,
      "energy_per_request_joules": 1016.1089076823841,
      "avg_output_len": 924.5732421875,
      "avg_power_watts": 4591.892931926612,
      "median_itl_ms": 41.779246006626636,
      "p90_itl_ms": 121.19652560213581,
      "p95_itl_ms": 127.00805901840795,
      "p99_itl_ms": 143.83263605413956,
      "output_throughput_tokens_per_sec": 4178.23454134734,
      "avg_batch_size": 255.6890243902439,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          43,
          61,
          81,
          82,
          84,
          92,
          71,
          50,
          43,
          38,
          30,
          27,
          31,
          23,
          22,
          10,
          14,
          14,
          10,
          7,
          11,
          9,
          8,
          16,
          8,
          5,
          9,
          4,
          5,
          6,
          1,
          4,
          2,
          5,
          0,
          3,
          4,
          3,
          2,
          4,
          3,
          1,
          3,
          1,
          0,
          1,
          8,
          0,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 4.477502861265936,
      "energy_per_request_joules": 4188.891946853965,
      "avg_output_len": 935.5419921875,
      "avg_power_watts": 4404.813243177252,
      "median_itl_ms": 29.476814001100138,
      "p90_itl_ms": 30.27793500223197,
      "p95_itl_ms": 32.82099700300023,
      "p99_itl_ms": 123.44734409998648,
      "output_throughput_tokens_per_sec": 983.7655898073211,
      "avg_batch_size": 31.972132904608788,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          41,
          54,
          95,
          80,
          85,
          82,
          72,
          38,
          44,
          43,
          39,
          21,
          24,
          22,
          20,
          16,
          22,
          9,
          13,
          15,
          10,
          7,
          13,
          6,
          10,
          9,
          7,
          4,
          2,
          2,
          3,
          5,
          3,
          5,
          2,
          3,
          0,
          6,
          3,
          2,
          2,
          1,
          1,
          1,
          0,
          5,
          1,
          0,
          32
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8997684670856395,
      "energy_per_request_joules": 821.5808718642709,
      "avg_output_len": 913.1025390625,
      "avg_power_watts": 4597.270460150431,
      "median_itl_ms": 48.13392701908015,
      "p90_itl_ms": 125.17640480073169,
      "p95_itl_ms": 131.71685921261087,
      "p99_itl_ms": 171.68920587049797,
      "output_throughput_tokens_per_sec": 5109.392725265249,
      "avg_batch_size": 383.62608695652176,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          38,
          51,
          58,
          86,
          95,
          75,
          79,
          67,
          52,
          41,
          39,
          40,
          24,
          25,
          24,
          17,
          24,
          15,
          7,
          11,
          9,
          15,
          7,
          12,
          7,
          8,
          7,
          2,
          9,
          5,
          3,
          5,
          1,
          5,
          5,
          5,
          7,
          4,
          2,
          1,
          3,
          2,
          2,
          2,
          1,
          0,
          2,
          1,
          0,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.7363435163185645,
      "energy_per_request_joules": 2525.4606830399393,
      "avg_output_len": 922.9326171875,
      "avg_power_watts": 4512.516335117868,
      "median_itl_ms": 33.10224000597373,
      "p90_itl_ms": 36.258085584267974,
      "p95_itl_ms": 112.15054059866814,
      "p99_itl_ms": 121.87398519134149,
      "output_throughput_tokens_per_sec": 1649.1044739839315,
      "avg_batch_size": 63.91198501872659,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          45,
          58,
          90,
          77,
          92,
          69,
          70,
          41,
          44,
          46,
          42,
          36,
          17,
          24,
          14,
          13,
          12,
          22,
          16,
          8,
          8,
          8,
          12,
          11,
          6,
          4,
          15,
          2,
          6,
          6,
          2,
          2,
          4,
          6,
          4,
          4,
          4,
          2,
          1,
          2,
          0,
          1,
          0,
          3,
          1,
          1,
          0,
          1,
          29
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.076049221453903,
      "energy_per_request_joules": 1908.598821652376,
      "avg_output_len": 919.341796875,
      "avg_power_watts": 4501.354952678083,
      "median_itl_ms": 35.891598992748186,
      "p90_itl_ms": 42.54712139954791,
      "p95_itl_ms": 121.36377985443687,
      "p99_itl_ms": 129.03118076006646,
      "output_throughput_tokens_per_sec": 2168.231324267777,
      "avg_batch_size": 95.91071428571429,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          45,
          41,
          63,
          81,
          82,
          79,
          84,
          72,
          54,
          44,
          43,
          26,
          23,
          21,
          26,
          30,
          15,
          19,
          14,
          14,
          10,
          6,
          10,
          11,
          7,
          9,
          7,
          4,
          10,
          3,
          8,
          2,
          1,
          4,
          2,
          3,
          2,
          1,
          4,
          1,
          4,
          0,
          0,
          2,
          2,
          1,
          1,
          4,
          0,
          29
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.7504557408324712,
      "energy_per_request_joules": 698.9886946298913,
      "avg_output_len": 931.4189453125,
      "avg_power_watts": 4524.148184437653,
      "median_itl_ms": 56.52425248990767,
      "p90_itl_ms": 134.6198219951475,
      "p95_itl_ms": 141.90061084664194,
      "p99_itl_ms": 183.10376408393495,
      "output_throughput_tokens_per_sec": 6028.534313587996,
      "avg_batch_size": 511.47639484978544,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          86,
          93,
          103,
          181,
          168,
          186,
          156,
          125,
          90,
          88,
          78,
          75,
          46,
          58,
          52,
          41,
          26,
          39,
          29,
          19,
          29,
          13,
          15,
          15,
          12,
          17,
          17,
          13,
          8,
          10,
          10,
          8,
          8,
          8,
          4,
          6,
          9,
          5,
          4,
          5,
          4,
          3,
          5,
          4,
          4,
          3,
          4,
          0,
          5,
          61
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6120116241876551,
      "energy_per_request_joules": 569.9830407652917,
      "avg_output_len": 931.3271484375,
      "avg_power_watts": 4241.050385162986,
      "median_itl_ms": 120.08048950519878,
      "p90_itl_ms": 176.6882411000552,
      "p95_itl_ms": 194.07242584275082,
      "p99_itl_ms": 433.33343841979513,
      "output_throughput_tokens_per_sec": 6929.68926986033,
      "avg_batch_size": 1022.8076923076923,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          81,
          89,
          126,
          166,
          196,
          142,
          162,
          124,
          106,
          77,
          87,
          70,
          61,
          46,
          47,
          39,
          28,
          30,
          34,
          23,
          16,
          25,
          22,
          19,
          12,
          21,
          12,
          7,
          8,
          9,
          10,
          14,
          6,
          9,
          13,
          5,
          6,
          1,
          5,
          5,
          4,
          4,
          3,
          5,
          1,
          0,
          3,
          4,
          3,
          62
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5169772522422859,
      "energy_per_request_joules": 485.28378677523193,
      "avg_output_len": 938.6946614583334,
      "avg_power_watts": 4613.620521349179,
      "median_itl_ms": 153.5743064887356,
      "p90_itl_ms": 199.3606451083906,
      "p95_itl_ms": 223.73212852398834,
      "p99_itl_ms": 396.8008841716783,
      "output_throughput_tokens_per_sec": 8924.223457296273,
      "avg_batch_size": 1534.25786163522,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          131,
          122,
          168,
          251,
          275,
          243,
          257,
          171,
          151,
          134,
          127,
          115,
          69,
          73,
          58,
          61,
          50,
          44,
          40,
          48,
          35,
          27,
          35,
          27,
          22,
          21,
          20,
          28,
          19,
          19,
          8,
          13,
          10,
          12,
          20,
          8,
          10,
          9,
          9,
          10,
          3,
          7,
          1,
          3,
          4,
          1,
          4,
          4,
          3,
          92
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4586514455672989,
      "energy_per_request_joules": 430.78657864187625,
      "avg_output_len": 939.24609375,
      "avg_power_watts": 4983.629472159795,
      "median_itl_ms": 149.0010855050059,
      "p90_itl_ms": 216.64371179940642,
      "p95_itl_ms": 258.1615651433822,
      "p99_itl_ms": 477.82679484749644,
      "output_throughput_tokens_per_sec": 10865.831821364089,
      "avg_batch_size": 2046.0729166666667,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          134,
          125,
          169,
          269,
          246,
          262,
          212,
          189,
          169,
          132,
          121,
          121,
          78,
          86,
          63,
          38,
          53,
          36,
          37,
          39,
          34,
          34,
          23,
          28,
          30,
          25,
          29,
          15,
          18,
          17,
          13,
          10,
          16,
          13,
          17,
          10,
          4,
          4,
          10,
          10,
          7,
          4,
          5,
          3,
          6,
          5,
          6,
          3,
          3,
          91
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.2737332890054938,
      "energy_per_request_joules": 1185.4712841344362,
      "avg_output_len": 930.7060546875,
      "avg_power_watts": 2981.9836753767026,
      "median_itl_ms": 45.112803985830396,
      "p90_itl_ms": 110.95497500500642,
      "p95_itl_ms": 122.4943128763698,
      "p99_itl_ms": 129.4628916517831,
      "output_throughput_tokens_per_sec": 2341.1366422753836,
      "avg_batch_size": 127.87252124645893,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          43,
          61,
          85,
          79,
          88,
          80,
          62,
          57,
          43,
          40,
          31,
          27,
          28,
          16,
          22,
          16,
          17,
          18,
          12,
          10,
          7,
          13,
          8,
          9,
          12,
          5,
          6,
          5,
          4,
          6,
          5,
          7,
          0,
          3,
          4,
          2,
          3,
          3,
          1,
          3,
          0,
          0,
          1,
          3,
          2,
          1,
          2,
          2,
          29
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 4.799211874874819,
      "energy_per_request_joules": 4456.035418708844,
      "avg_output_len": 928.4931640625,
      "avg_power_watts": 2847.570793571764,
      "median_itl_ms": 25.563647999661043,
      "p90_itl_ms": 26.401526003610343,
      "p95_itl_ms": 26.797347993124276,
      "p99_itl_ms": 109.2353199783247,
      "output_throughput_tokens_per_sec": 593.341337664122,
      "avg_batch_size": 15.98706338939198,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          47,
          36,
          55,
          90,
          81,
          92,
          84,
          77,
          42,
          40,
          37,
          32,
          29,
          23,
          17,
          15,
          17,
          8,
          23,
          11,
          10,
          9,
          15,
          7,
          11,
          9,
          14,
          7,
          6,
          6,
          7,
          5,
          4,
          3,
          3,
          4,
          2,
          3,
          2,
          6,
          2,
          0,
          2,
          0,
          1,
          1,
          2,
          1,
          3,
          23
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.96723112554252,
      "energy_per_request_joules": 885.9213699283098,
      "avg_output_len": 915.935546875,
      "avg_power_watts": 2903.7468142816138,
      "median_itl_ms": 51.21387599501759,
      "p90_itl_ms": 118.81735629285686,
      "p95_itl_ms": 123.9791058047558,
      "p99_itl_ms": 138.8368956191696,
      "output_throughput_tokens_per_sec": 3002.123006176938,
      "avg_batch_size": 191.7976653696498,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          45,
          38,
          54,
          95,
          84,
          91,
          85,
          53,
          63,
          46,
          41,
          34,
          18,
          22,
          19,
          15,
          14,
          16,
          13,
          17,
          14,
          12,
          10,
          12,
          11,
          6,
          4,
          5,
          5,
          4,
          7,
          3,
          5,
          5,
          3,
          7,
          3,
          2,
          4,
          1,
          2,
          2,
          1,
          3,
          1,
          2,
          1,
          1,
          4,
          21
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.790051709096917,
      "energy_per_request_joules": 739.1365798130071,
      "avg_output_len": 935.5546875,
      "avg_power_watts": 2943.0818396445216,
      "median_itl_ms": 52.3127780033974,
      "p90_itl_ms": 118.49325870280154,
      "p95_itl_ms": 125.10159990342798,
      "p99_itl_ms": 153.7854100301047,
      "output_throughput_tokens_per_sec": 3725.1762204383617,
      "avg_batch_size": 255.68947368421053,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          40,
          67,
          88,
          85,
          79,
          90,
          64,
          49,
          40,
          39,
          32,
          26,
          21,
          19,
          32,
          15,
          15,
          9,
          12,
          10,
          12,
          5,
          16,
          9,
          5,
          7,
          3,
          4,
          6,
          6,
          6,
          2,
          4,
          5,
          1,
          5,
          3,
          4,
          1,
          2,
          1,
          5,
          3,
          3,
          0,
          1,
          1,
          0,
          31
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.1684523472083437,
      "energy_per_request_joules": 2908.5804650940986,
      "avg_output_len": 917.9814453125,
      "avg_power_watts": 3115.937407652115,
      "median_itl_ms": 29.54949499689974,
      "p90_itl_ms": 30.968836398096755,
      "p95_itl_ms": 34.28403029683977,
      "p99_itl_ms": 115.02110118337441,
      "output_throughput_tokens_per_sec": 983.4256811207848,
      "avg_batch_size": 31.974780701754387,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          42,
          58,
          92,
          89,
          79,
          88,
          61,
          54,
          47,
          40,
          29,
          25,
          23,
          19,
          16,
          20,
          13,
          17,
          11,
          14,
          17,
          11,
          6,
          6,
          7,
          8,
          5,
          3,
          9,
          5,
          7,
          2,
          3,
          2,
          1,
          2,
          2,
          4,
          2,
          1,
          2,
          0,
          0,
          2,
          1,
          2,
          0,
          1,
          33
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6347152758815502,
      "energy_per_request_joules": 594.8689169850214,
      "avg_output_len": 937.2216796875,
      "avg_power_watts": 2939.309063919983,
      "median_itl_ms": 58.47321602050215,
      "p90_itl_ms": 123.84586001280695,
      "p95_itl_ms": 131.2282260041684,
      "p99_itl_ms": 187.34306048718253,
      "output_throughput_tokens_per_sec": 4630.909599327988,
      "avg_batch_size": 383.632,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          48,
          38,
          71,
          77,
          92,
          79,
          76,
          69,
          49,
          52,
          41,
          28,
          20,
          22,
          24,
          21,
          12,
          19,
          8,
          10,
          13,
          11,
          15,
          5,
          11,
          5,
          5,
          5,
          4,
          4,
          6,
          9,
          6,
          4,
          5,
          3,
          4,
          3,
          1,
          4,
          2,
          2,
          0,
          4,
          2,
          0,
          1,
          3,
          0,
          31
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.1371219955693976,
      "energy_per_request_joules": 1993.8680368038865,
      "avg_output_len": 932.96875,
      "avg_power_watts": 3007.630659692327,
      "median_itl_ms": 40.43372950400226,
      "p90_itl_ms": 43.84741949616,
      "p95_itl_ms": 108.865691749088,
      "p99_itl_ms": 117.17617660469841,
      "output_throughput_tokens_per_sec": 1407.3275488847316,
      "avg_batch_size": 63.940988835725676,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          43,
          49,
          95,
          86,
          88,
          68,
          70,
          54,
          37,
          50,
          33,
          34,
          21,
          19,
          19,
          16,
          15,
          12,
          12,
          13,
          11,
          4,
          9,
          11,
          9,
          10,
          6,
          6,
          1,
          6,
          3,
          6,
          3,
          4,
          2,
          3,
          2,
          3,
          5,
          1,
          2,
          0,
          5,
          3,
          1,
          0,
          0,
          1,
          30
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 6.632630906751159,
      "energy_per_request_joules": 6115.480011383165,
      "avg_output_len": 922.029296875,
      "avg_power_watts": 2564.5780145630083,
      "median_itl_ms": 19.990801491076127,
      "p90_itl_ms": 20.715421496424824,
      "p95_itl_ms": 20.928950459347107,
      "p99_itl_ms": 26.84810380858835,
      "output_throughput_tokens_per_sec": 386.6607460325585,
      "avg_batch_size": 7.995852343425964,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          42,
          48,
          61,
          81,
          93,
          66,
          94,
          60,
          54,
          48,
          33,
          35,
          35,
          17,
          18,
          15,
          23,
          21,
          15,
          14,
          8,
          3,
          11,
          10,
          11,
          5,
          6,
          10,
          9,
          6,
          3,
          2,
          8,
          5,
          3,
          0,
          5,
          3,
          1,
          1,
          2,
          1,
          0,
          3,
          3,
          2,
          0,
          0,
          1,
          29
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.5920491209975816,
      "energy_per_request_joules": 1477.3158622738144,
      "avg_output_len": 927.93359375,
      "avg_power_watts": 3004.159586840488,
      "median_itl_ms": 43.27604698482901,
      "p90_itl_ms": 52.07954239740502,
      "p95_itl_ms": 118.1745307345409,
      "p99_itl_ms": 129.1171749445493,
      "output_throughput_tokens_per_sec": 1886.976693883713,
      "avg_batch_size": 95.90687361419069,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          49,
          53,
          91,
          80,
          101,
          69,
          66,
          56,
          38,
          38,
          31,
          25,
          24,
          19,
          29,
          18,
          16,
          7,
          16,
          8,
          12,
          11,
          12,
          6,
          2,
          6,
          6,
          7,
          8,
          3,
          4,
          5,
          3,
          6,
          0,
          1,
          4,
          2,
          1,
          1,
          6,
          2,
          0,
          1,
          3,
          2,
          0,
          1,
          32
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3697245746225884,
      "energy_per_request_joules": 344.85788903555755,
      "avg_output_len": 932.74267578125,
      "avg_power_watts": 2984.615710020861,
      "median_itl_ms": 107.58416299358942,
      "p90_itl_ms": 187.95034061186016,
      "p95_itl_ms": 229.09402041113918,
      "p99_itl_ms": 592.8801333950832,
      "output_throughput_tokens_per_sec": 8072.538086134878,
      "avg_batch_size": 951.9222222222222,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          89,
          81,
          124,
          170,
          184,
          165,
          141,
          124,
          104,
          103,
          82,
          65,
          48,
          45,
          55,
          42,
          30,
          27,
          30,
          25,
          18,
          19,
          24,
          14,
          15,
          20,
          10,
          14,
          6,
          10,
          13,
          13,
          10,
          7,
          5,
          7,
          9,
          5,
          3,
          2,
          4,
          1,
          3,
          5,
          2,
          5,
          1,
          2,
          2,
          65
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5238025833335942,
      "energy_per_request_joules": 485.0097333203506,
      "avg_output_len": 925.93994140625,
      "avg_power_watts": 2696.776465629277,
      "median_itl_ms": 66.81747701077256,
      "p90_itl_ms": 139.47950389410835,
      "p95_itl_ms": 153.37277690123298,
      "p99_itl_ms": 319.21800266223727,
      "output_throughput_tokens_per_sec": 5148.459651470984,
      "avg_batch_size": 511.4792452830189,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          86,
          89,
          114,
          195,
          165,
          167,
          160,
          130,
          115,
          85,
          79,
          57,
          57,
          46,
          50,
          34,
          27,
          25,
          28,
          23,
          28,
          19,
          14,
          13,
          21,
          17,
          18,
          13,
          11,
          5,
          9,
          8,
          8,
          6,
          9,
          2,
          6,
          3,
          4,
          5,
          6,
          1,
          0,
          5,
          3,
          6,
          5,
          5,
          2,
          64
        ]
      }
    }
  ]
}