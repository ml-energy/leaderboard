{
  "activated_params_billions": 3.0,
  "architecture": "MoE",
  "configurations": [
    {
      "avg_batch_size": 15.919024390243903,
      "avg_output_len": 940.4853515625,
      "avg_power_watts": 535.6640895500041,
      "energy_per_request_joules": 565.9579947390123,
      "energy_per_token_joules": 0.6017722591837747,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 16,
      "median_itl_ms": 16.982789005851373,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          46,
          55,
          95,
          95,
          84,
          76,
          97,
          54,
          40,
          33,
          37,
          27,
          24,
          20,
          14,
          20,
          14,
          12,
          6,
          4,
          6,
          14,
          6,
          4,
          10,
          6,
          12,
          4,
          5,
          0,
          1,
          5,
          9,
          4,
          1,
          5,
          8,
          1,
          1,
          3,
          2,
          0,
          1,
          2,
          3,
          0,
          2,
          1,
          0,
          55
        ]
      },
      "output_throughput_tokens_per_sec": 890.1442055115041,
      "p90_itl_ms": 17.97059419332072,
      "p95_itl_ms": 21.874672209378325,
      "p99_itl_ms": 67.06122953910382,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 31.80327868852459,
      "avg_output_len": 924.5732421875,
      "avg_power_watts": 557.042007086968,
      "energy_per_request_joules": 388.917917383093,
      "energy_per_token_joules": 0.42064587167040457,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 32,
      "median_itl_ms": 22.154652993776836,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          51,
          55,
          82,
          100,
          106,
          79,
          67,
          54,
          44,
          34,
          23,
          34,
          30,
          33,
          18,
          12,
          10,
          4,
          12,
          11,
          13,
          10,
          4,
          6,
          11,
          9,
          5,
          6,
          4,
          1,
          9,
          1,
          4,
          3,
          2,
          4,
          4,
          1,
          3,
          4,
          2,
          0,
          2,
          0,
          1,
          2,
          1,
          1,
          0,
          52
        ]
      },
      "output_throughput_tokens_per_sec": 1324.2540688083495,
      "p90_itl_ms": 24.94026039561885,
      "p95_itl_ms": 36.56293428796955,
      "p99_itl_ms": 77.63206866016847,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 7.950344827586207,
      "avg_output_len": 928.841796875,
      "avg_power_watts": 496.8889249776025,
      "energy_per_request_joules": 728.4748875595249,
      "energy_per_token_joules": 0.784283060915658,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 8,
      "median_itl_ms": 12.165323016233742,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          51,
          57,
          85,
          108,
          100,
          79,
          58,
          52,
          41,
          39,
          27,
          39,
          18,
          18,
          15,
          21,
          10,
          15,
          11,
          8,
          12,
          5,
          9,
          9,
          10,
          7,
          5,
          9,
          4,
          4,
          9,
          6,
          0,
          5,
          4,
          4,
          6,
          0,
          3,
          2,
          4,
          0,
          3,
          1,
          0,
          0,
          1,
          1,
          2,
          47
        ]
      },
      "output_throughput_tokens_per_sec": 633.5581497801061,
      "p90_itl_ms": 12.6995415892452,
      "p95_itl_ms": 12.889946793438867,
      "p99_itl_ms": 23.38465000812888,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 127.87027027027027,
      "avg_output_len": 935.9375,
      "avg_power_watts": 942.0298202874875,
      "energy_per_request_joules": 210.72177394838616,
      "energy_per_token_joules": 0.22514513410178152,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 128,
      "median_itl_ms": 25.571873513399623,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          46,
          59,
          95,
          94,
          94,
          73,
          75,
          52,
          43,
          39,
          34,
          24,
          22,
          19,
          20,
          9,
          15,
          21,
          8,
          12,
          11,
          6,
          8,
          7,
          10,
          11,
          4,
          7,
          7,
          7,
          6,
          6,
          2,
          3,
          0,
          1,
          1,
          4,
          2,
          3,
          3,
          2,
          1,
          3,
          3,
          3,
          0,
          0,
          2,
          47
        ]
      },
      "output_throughput_tokens_per_sec": 4184.10028733565,
      "p90_itl_ms": 40.2215727126368,
      "p95_itl_ms": 71.02481509937206,
      "p99_itl_ms": 79.71882487065159,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 15.980662983425415,
      "avg_output_len": 927.203125,
      "avg_power_watts": 856.7782632272523,
      "energy_per_request_joules": 631.119041575434,
      "energy_per_token_joules": 0.6806696661806808,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 16,
      "median_itl_ms": 11.906124505912885,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          51,
          60,
          82,
          95,
          84,
          91,
          71,
          57,
          35,
          46,
          34,
          29,
          22,
          23,
          16,
          26,
          18,
          12,
          10,
          10,
          8,
          7,
          6,
          5,
          6,
          6,
          2,
          2,
          6,
          4,
          4,
          4,
          5,
          5,
          1,
          2,
          2,
          5,
          3,
          3,
          5,
          3,
          1,
          0,
          2,
          1,
          2,
          2,
          1,
          49
        ]
      },
      "output_throughput_tokens_per_sec": 1258.7284343589715,
      "p90_itl_ms": 12.324141507269815,
      "p95_itl_ms": 13.436813361075675,
      "p99_itl_ms": 60.25252692314099,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 191.4469696969697,
      "avg_output_len": 943.8251953125,
      "avg_power_watts": 941.8578329871856,
      "energy_per_request_joules": 174.01092672137355,
      "energy_per_token_joules": 0.18436774901284408,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 192,
      "median_itl_ms": 29.689154005609453,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          47,
          58,
          94,
          100,
          90,
          78,
          65,
          71,
          37,
          39,
          27,
          29,
          20,
          17,
          14,
          19,
          9,
          8,
          8,
          14,
          8,
          13,
          8,
          10,
          12,
          6,
          2,
          5,
          4,
          10,
          3,
          5,
          6,
          3,
          8,
          6,
          0,
          4,
          2,
          2,
          1,
          2,
          2,
          4,
          0,
          1,
          1,
          0,
          3,
          49
        ]
      },
      "output_throughput_tokens_per_sec": 5108.5823742501225,
      "p90_itl_ms": 52.02631429419853,
      "p95_itl_ms": 78.70412280171877,
      "p99_itl_ms": 93.39407151710475,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 251.15151515151516,
      "avg_output_len": 923.90625,
      "avg_power_watts": 938.2410130936585,
      "energy_per_request_joules": 146.419945814457,
      "energy_per_token_joules": 0.15847922428759087,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 256,
      "median_itl_ms": 30.229980279036994,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          55,
          58,
          90,
          99,
          68,
          87,
          76,
          52,
          53,
          33,
          32,
          31,
          16,
          16,
          16,
          19,
          15,
          20,
          10,
          5,
          11,
          11,
          10,
          8,
          10,
          6,
          7,
          5,
          3,
          7,
          7,
          6,
          5,
          7,
          5,
          2,
          2,
          2,
          3,
          3,
          2,
          2,
          2,
          2,
          1,
          1,
          0,
          1,
          1,
          41
        ]
      },
      "output_throughput_tokens_per_sec": 5920.277672428789,
      "p90_itl_ms": 55.177570412596985,
      "p95_itl_ms": 83.20593490789179,
      "p99_itl_ms": 104.39358878007629,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 31.96949891067538,
      "avg_output_len": 929.017578125,
      "avg_power_watts": 919.8470688399545,
      "energy_per_request_joules": 435.88343875516347,
      "energy_per_token_joules": 0.46918750411040666,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 32,
      "median_itl_ms": 14.74564999807626,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          44,
          58,
          79,
          102,
          98,
          86,
          75,
          61,
          38,
          40,
          25,
          23,
          23,
          26,
          20,
          16,
          11,
          15,
          8,
          12,
          6,
          10,
          6,
          5,
          8,
          6,
          11,
          7,
          4,
          6,
          4,
          6,
          3,
          4,
          1,
          1,
          8,
          1,
          2,
          5,
          2,
          1,
          2,
          3,
          0,
          0,
          2,
          0,
          4,
          46
        ]
      },
      "output_throughput_tokens_per_sec": 1960.5105864530892,
      "p90_itl_ms": 17.160637637858304,
      "p95_itl_ms": 20.590041025234544,
      "p99_itl_ms": 63.943592994473875,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 348.625,
      "avg_output_len": 919.00390625,
      "avg_power_watts": 1005.8746427702692,
      "energy_per_request_joules": 127.02004757226058,
      "energy_per_token_joules": 0.1382149158544565,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 384,
      "median_itl_ms": 27.160923506016843,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          53,
          48,
          96,
          102,
          97,
          77,
          71,
          61,
          49,
          29,
          25,
          29,
          27,
          14,
          18,
          12,
          19,
          16,
          14,
          11,
          6,
          8,
          6,
          9,
          4,
          11,
          5,
          4,
          3,
          3,
          7,
          1,
          2,
          5,
          3,
          6,
          0,
          6,
          4,
          0,
          1,
          2,
          3,
          1,
          4,
          1,
          1,
          2,
          0,
          48
        ]
      },
      "output_throughput_tokens_per_sec": 7277.612814448178,
      "p90_itl_ms": 38.91398001287599,
      "p95_itl_ms": 46.31462465040386,
      "p99_itl_ms": 156.53573861900009,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 63.083636363636366,
      "avg_output_len": 917.4130859375,
      "avg_power_watts": 953.1508575409222,
      "energy_per_request_joules": 284.5566986243259,
      "energy_per_token_joules": 0.31017292317510253,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 64,
      "median_itl_ms": 17.97010649170261,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          50,
          60,
          85,
          117,
          80,
          71,
          80,
          55,
          45,
          37,
          37,
          27,
          15,
          19,
          16,
          20,
          14,
          15,
          11,
          9,
          10,
          7,
          11,
          4,
          3,
          6,
          2,
          7,
          5,
          5,
          4,
          10,
          9,
          4,
          2,
          1,
          3,
          4,
          3,
          2,
          2,
          1,
          0,
          2,
          1,
          3,
          3,
          3,
          2,
          42
        ]
      },
      "output_throughput_tokens_per_sec": 3072.966033862466,
      "p90_itl_ms": 23.25233998708427,
      "p95_itl_ms": 61.30895564128877,
      "p99_itl_ms": 69.2810194814228,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 7.991228070175438,
      "avg_output_len": 909.9248046875,
      "avg_power_watts": 750.5171559319674,
      "energy_per_request_joules": 853.3120068036095,
      "energy_per_token_joules": 0.9377829930646485,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 8,
      "median_itl_ms": 9.55027699819766,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          52,
          58,
          96,
          102,
          88,
          72,
          59,
          59,
          51,
          44,
          27,
          31,
          19,
          14,
          19,
          19,
          14,
          19,
          9,
          8,
          14,
          10,
          8,
          8,
          4,
          7,
          10,
          3,
          8,
          5,
          2,
          6,
          6,
          4,
          1,
          3,
          1,
          2,
          4,
          1,
          3,
          3,
          1,
          1,
          3,
          0,
          0,
          0,
          1,
          45
        ]
      },
      "output_throughput_tokens_per_sec": 800.3100519868658,
      "p90_itl_ms": 9.884005994535983,
      "p95_itl_ms": 10.280133999185631,
      "p99_itl_ms": 20.611840424213828,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 95.70403587443946,
      "avg_output_len": 908.3720703125,
      "avg_power_watts": 955.1316474339901,
      "energy_per_request_joules": 244.70814789626502,
      "energy_per_token_joules": 0.2693919770255376,
      "gpu_model": "H100",
      "max_num_batched_tokens": null,
      "max_num_seqs": 96,
      "median_itl_ms": 22.778183993068524,
      "num_gpus": 2,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          52,
          56,
          83,
          100,
          88,
          93,
          68,
          57,
          51,
          43,
          32,
          25,
          15,
          21,
          17,
          21,
          13,
          8,
          12,
          14,
          14,
          9,
          8,
          5,
          3,
          6,
          4,
          11,
          2,
          5,
          5,
          3,
          2,
          2,
          1,
          4,
          1,
          2,
          0,
          4,
          3,
          2,
          2,
          3,
          0,
          0,
          2,
          3,
          4,
          45
        ]
      },
      "output_throughput_tokens_per_sec": 3545.5088825583193,
      "p90_itl_ms": 30.494484554657987,
      "p95_itl_ms": 66.43483100197045,
      "p99_itl_ms": 73.48209620686248,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 2,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 115.13333333333334,
      "avg_output_len": 943.3427734375,
      "avg_power_watts": 349.3652682537472,
      "energy_per_request_joules": 276.31972376153686,
      "energy_per_token_joules": 0.29291550382544385,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 128,
      "median_itl_ms": 75.68522856391247,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          50,
          53,
          93,
          93,
          97,
          65,
          76,
          62,
          48,
          37,
          35,
          26,
          25,
          23,
          20,
          15,
          14,
          13,
          10,
          11,
          3,
          10,
          6,
          6,
          6,
          8,
          3,
          7,
          4,
          8,
          3,
          1,
          3,
          2,
          3,
          4,
          0,
          0,
          5,
          3,
          2,
          1,
          3,
          1,
          0,
          2,
          4,
          1,
          4,
          55
        ]
      },
      "output_throughput_tokens_per_sec": 1192.7168882871536,
      "p90_itl_ms": 181.82858923930635,
      "p95_itl_ms": 235.20944229676388,
      "p99_itl_ms": 441.75925878051174,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 31.86051502145923,
      "avg_output_len": 929.794921875,
      "avg_power_watts": 365.5120916253695,
      "energy_per_request_joules": 540.1014799244695,
      "energy_per_token_joules": 0.5808823722496946,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 32,
      "median_itl_ms": 37.49177895952016,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          48,
          53,
          98,
          105,
          79,
          85,
          74,
          54,
          52,
          32,
          23,
          29,
          31,
          18,
          18,
          22,
          12,
          10,
          15,
          4,
          10,
          7,
          2,
          12,
          6,
          3,
          4,
          7,
          7,
          5,
          4,
          5,
          4,
          2,
          2,
          6,
          3,
          3,
          1,
          4,
          0,
          4,
          3,
          0,
          1,
          0,
          1,
          0,
          1,
          55
        ]
      },
      "output_throughput_tokens_per_sec": 629.2359849202873,
      "p90_itl_ms": 111.26450257143017,
      "p95_itl_ms": 148.1922325852792,
      "p99_itl_ms": 211.26691145589567,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 63.81059602649007,
      "avg_output_len": 922.3505859375,
      "avg_power_watts": 402.6522837668964,
      "energy_per_request_joules": 343.8668960799509,
      "energy_per_token_joules": 0.37281582656602974,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 64,
      "median_itl_ms": 33.155431505292654,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          50,
          59,
          87,
          94,
          90,
          88,
          66,
          65,
          41,
          41,
          34,
          25,
          19,
          14,
          31,
          18,
          16,
          12,
          7,
          4,
          14,
          8,
          10,
          2,
          7,
          6,
          5,
          8,
          3,
          6,
          2,
          3,
          3,
          3,
          3,
          4,
          1,
          3,
          2,
          4,
          5,
          2,
          2,
          2,
          1,
          3,
          3,
          0,
          0,
          48
        ]
      },
      "output_throughput_tokens_per_sec": 1080.030017705223,
      "p90_itl_ms": 136.0602586332243,
      "p95_itl_ms": 178.18821781838778,
      "p99_itl_ms": 303.02614579667824,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 7.752,
      "avg_output_len": 938.236328125,
      "avg_power_watts": 583.5827138575717,
      "energy_per_request_joules": 698.5116666226501,
      "energy_per_token_joules": 0.7444943727755426,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 8,
      "median_itl_ms": 8.75678300508298,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          51,
          49,
          85,
          100,
          97,
          85,
          56,
          75,
          40,
          42,
          36,
          26,
          24,
          23,
          13,
          16,
          14,
          12,
          10,
          6,
          11,
          3,
          11,
          3,
          9,
          7,
          7,
          4,
          2,
          5,
          5,
          4,
          6,
          2,
          2,
          3,
          2,
          2,
          4,
          1,
          2,
          1,
          2,
          1,
          3,
          3,
          1,
          1,
          2,
          55
        ]
      },
      "output_throughput_tokens_per_sec": 783.8645061639919,
      "p90_itl_ms": 14.508500334341079,
      "p95_itl_ms": 20.06250974577148,
      "p99_itl_ms": 92.16907136328985,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 15.923994038748138,
      "avg_output_len": 929.97265625,
      "avg_power_watts": 362.8790673150578,
      "energy_per_request_joules": 828.2311853167464,
      "energy_per_token_joules": 0.8905973522452655,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 16,
      "median_itl_ms": 31.96836798451841,
      "num_gpus": 1,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          48,
          64,
          100,
          94,
          90,
          73,
          84,
          58,
          35,
          34,
          31,
          21,
          17,
          17,
          24,
          19,
          12,
          13,
          9,
          11,
          10,
          7,
          4,
          10,
          8,
          5,
          11,
          7,
          5,
          4,
          5,
          7,
          4,
          5,
          2,
          3,
          5,
          2,
          4,
          1,
          0,
          0,
          2,
          1,
          4,
          1,
          1,
          1,
          1,
          50
        ]
      },
      "output_throughput_tokens_per_sec": 407.45581198979687,
      "p90_itl_ms": 61.09153580619024,
      "p95_itl_ms": 94.7185157623606,
      "p99_itl_ms": 178.08760315235887,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 1,
        "notes": "",
        "tensor_parallel": 1
      }
    }
  ],
  "model_id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
  "output_length_distribution": {
    "bins": [
      2.0,
      83.88,
      165.76,
      247.64,
      329.52,
      411.4,
      493.28,
      575.16,
      657.04,
      738.92,
      820.8,
      902.68,
      984.56,
      1066.44,
      1148.32,
      1230.1999999999998,
      1312.08,
      1393.96,
      1475.84,
      1557.7199999999998,
      1639.6,
      1721.48,
      1803.36,
      1885.2399999999998,
      1967.12,
      2049.0,
      2130.88,
      2212.7599999999998,
      2294.64,
      2376.52,
      2458.3999999999996,
      2540.2799999999997,
      2622.16,
      2704.04,
      2785.92,
      2867.7999999999997,
      2949.68,
      3031.56,
      3113.4399999999996,
      3195.3199999999997,
      3277.2,
      3359.08,
      3440.96,
      3522.8399999999997,
      3604.72,
      3686.6,
      3768.4799999999996,
      3850.3599999999997,
      3932.24,
      4014.12,
      4096.0
    ],
    "counts": [
      845,
      960,
      1525,
      1700,
      1530,
      1358,
      1218,
      999,
      743,
      642,
      519,
      475,
      367,
      335,
      309,
      304,
      230,
      225,
      170,
      154,
      167,
      145,
      123,
      113,
      127,
      116,
      99,
      103,
      76,
      85,
      80,
      79,
      73,
      63,
      41,
      59,
      47,
      42,
      46,
      45,
      39,
      26,
      32,
      27,
      27,
      21,
      25,
      17,
      28,
      829
    ]
  },
  "task": "image-chat",
  "total_params_billions": 30.0,
  "weight_precision": "bfloat16"
}