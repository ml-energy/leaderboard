{
  "model_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
  "task": "sourcegraph-fim",
  "total_params_billions": 480.0,
  "activated_params_billions": 35.0,
  "architecture": "MoE",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      2.0,
      42.92,
      83.84,
      124.76,
      165.68,
      206.60000000000002,
      247.52,
      288.44,
      329.36,
      370.28000000000003,
      411.20000000000005,
      452.12,
      493.04,
      533.96,
      574.88,
      615.8000000000001,
      656.72,
      697.64,
      738.5600000000001,
      779.48,
      820.4000000000001,
      861.32,
      902.24,
      943.1600000000001,
      984.08,
      1025.0,
      1065.92,
      1106.8400000000001,
      1147.76,
      1188.68,
      1229.6000000000001,
      1270.52,
      1311.44,
      1352.3600000000001,
      1393.28,
      1434.2,
      1475.1200000000001,
      1516.04,
      1556.96,
      1597.88,
      1638.8000000000002,
      1679.72,
      1720.64,
      1761.5600000000002,
      1802.48,
      1843.4,
      1884.3200000000002,
      1925.24,
      1966.16,
      2007.0800000000002,
      2048.0
    ],
    "counts": [
      3431,
      4954,
      2728,
      1717,
      1206,
      890,
      691,
      636,
      518,
      423,
      343,
      308,
      258,
      224,
      166,
      173,
      143,
      129,
      129,
      100,
      78,
      69,
      68,
      60,
      58,
      61,
      52,
      44,
      31,
      36,
      30,
      36,
      26,
      51,
      22,
      19,
      13,
      10,
      15,
      9,
      19,
      14,
      13,
      12,
      10,
      17,
      15,
      5,
      7,
      413
    ]
  },
  "configurations": [
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 13.05737188188872,
      "energy_per_request_joules": 3266.128158034157,
      "avg_power_watts": 5219.576418269039,
      "median_itl_ms": 17.74637600101414,
      "p90_itl_ms": 18.273918500199215,
      "p95_itl_ms": 18.582427750516217,
      "p99_itl_ms": 89.44865425291941,
      "output_throughput_tokens_per_sec": 389.0845652080728,
      "avg_batch_size": 7.964968152866242,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          174,
          251,
          135,
          81,
          57,
          39,
          37,
          26,
          26,
          29,
          17,
          14,
          15,
          15,
          10,
          7,
          11,
          4,
          6,
          4,
          2,
          4,
          6,
          1,
          3,
          4,
          3,
          1,
          0,
          2,
          2,
          3,
          2,
          4,
          2,
          2,
          3,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          17
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.7860973092763945,
      "energy_per_request_joules": 908.8704064229357,
      "avg_power_watts": 6481.297191074068,
      "median_itl_ms": 44.61098599131219,
      "p90_itl_ms": 126.14101159706476,
      "p95_itl_ms": 163.00839584800997,
      "p99_itl_ms": 237.4197714017646,
      "output_throughput_tokens_per_sec": 1387.753976767901,
      "avg_batch_size": 127.38938053097345,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          167,
          261,
          141,
          75,
          56,
          47,
          48,
          28,
          25,
          19,
          19,
          14,
          14,
          9,
          7,
          11,
          4,
          5,
          7,
          4,
          12,
          4,
          1,
          0,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          1,
          1,
          3,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          2,
          0,
          1,
          1,
          0,
          0,
          0,
          18
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 10.217131456725308,
      "energy_per_request_joules": 2450.3055918077584,
      "avg_power_watts": 5770.737641177804,
      "median_itl_ms": 24.124919989844784,
      "p90_itl_ms": 25.04802979528904,
      "p95_itl_ms": 64.99501719663385,
      "p99_itl_ms": 114.62345081672534,
      "output_throughput_tokens_per_sec": 546.9793133317847,
      "avg_batch_size": 15.93632075471698,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          173,
          236,
          144,
          95,
          44,
          61,
          39,
          33,
          31,
          14,
          16,
          9,
          8,
          13,
          8,
          9,
          12,
          5,
          8,
          2,
          6,
          5,
          3,
          4,
          1,
          6,
          0,
          3,
          4,
          1,
          3,
          2,
          1,
          3,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          3,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          15
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.0522412783538524,
      "energy_per_request_joules": 757.5519779064339,
      "avg_power_watts": 6534.924900490119,
      "median_itl_ms": 50.79536299308529,
      "p90_itl_ms": 198.796793098154,
      "p95_itl_ms": 261.1924407436163,
      "p99_itl_ms": 363.50305849366123,
      "output_throughput_tokens_per_sec": 1626.230159141793,
      "avg_batch_size": 254.51470588235293,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          166,
          258,
          134,
          93,
          59,
          40,
          27,
          32,
          30,
          20,
          22,
          17,
          15,
          10,
          9,
          7,
          7,
          5,
          4,
          6,
          4,
          3,
          2,
          4,
          1,
          6,
          1,
          1,
          1,
          3,
          1,
          1,
          0,
          1,
          2,
          0,
          0,
          2,
          0,
          1,
          3,
          0,
          0,
          1,
          2,
          2,
          0,
          1,
          1,
          19
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 7.900547897580478,
      "energy_per_request_joules": 2089.8955187589986,
      "avg_power_watts": 5905.0534836184825,
      "median_itl_ms": 36.230216501280665,
      "p90_itl_ms": 59.771512301813345,
      "p95_itl_ms": 83.87025249467115,
      "p99_itl_ms": 138.1913714518305,
      "output_throughput_tokens_per_sec": 708.126916116344,
      "avg_batch_size": 31.86135693215339,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          178,
          236,
          133,
          92,
          56,
          53,
          27,
          32,
          26,
          22,
          18,
          11,
          8,
          12,
          12,
          12,
          4,
          6,
          4,
          8,
          3,
          3,
          3,
          1,
          3,
          3,
          2,
          5,
          0,
          2,
          2,
          2,
          3,
          4,
          0,
          4,
          1,
          1,
          1,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          2,
          1,
          0,
          26
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 5.273857739078018,
      "energy_per_request_joules": 1369.6630869024875,
      "avg_power_watts": 6332.292083685544,
      "median_itl_ms": 40.417031006654724,
      "p90_itl_ms": 86.51096280373167,
      "p95_itl_ms": 113.15379080770064,
      "p99_itl_ms": 167.6504082407337,
      "output_throughput_tokens_per_sec": 1070.7285203802653,
      "avg_batch_size": 63.70558375634518,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          167,
          243,
          148,
          81,
          47,
          47,
          35,
          37,
          29,
          21,
          18,
          16,
          11,
          13,
          7,
          9,
          7,
          10,
          7,
          3,
          2,
          2,
          1,
          5,
          2,
          3,
          5,
          1,
          3,
          2,
          1,
          3,
          1,
          1,
          1,
          0,
          2,
          1,
          2,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          26
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.630909676829514,
      "energy_per_request_joules": 393.6966586624277,
      "avg_power_watts": 6531.914453145158,
      "median_itl_ms": 77.22047499555629,
      "p90_itl_ms": 364.8151783942012,
      "p95_itl_ms": 373.3048656024039,
      "p99_itl_ms": 380.78787511971314,
      "output_throughput_tokens_per_sec": 2822.0882076409457,
      "avg_batch_size": 744.0816326530612,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          347,
          490,
          278,
          177,
          129,
          71,
          78,
          67,
          58,
          29,
          30,
          34,
          26,
          25,
          20,
          15,
          20,
          9,
          17,
          7,
          10,
          3,
          14,
          4,
          8,
          5,
          5,
          3,
          3,
          2,
          1,
          4,
          1,
          5,
          0,
          4,
          1,
          1,
          2,
          1,
          2,
          0,
          1,
          1,
          2,
          1,
          2,
          0,
          0,
          35
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.703245362782763,
      "energy_per_request_joules": 436.9780767728803,
      "avg_power_watts": 6539.00452452717,
      "median_itl_ms": 69.49835500563495,
      "p90_itl_ms": 224.88081240444444,
      "p95_itl_ms": 353.266859985888,
      "p99_itl_ms": 371.02475157531444,
      "output_throughput_tokens_per_sec": 2801.030800686243,
      "avg_batch_size": 506.16438356164383,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          341,
          496,
          268,
          176,
          124,
          86,
          70,
          57,
          53,
          49,
          29,
          38,
          31,
          21,
          10,
          12,
          15,
          16,
          9,
          6,
          4,
          9,
          3,
          9,
          8,
          5,
          5,
          5,
          5,
          2,
          4,
          4,
          3,
          6,
          2,
          1,
          1,
          0,
          4,
          0,
          3,
          1,
          0,
          3,
          2,
          2,
          2,
          0,
          1,
          47
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.2399833523083432,
      "energy_per_request_joules": 313.6104379859143,
      "avg_power_watts": 6663.397820476585,
      "median_itl_ms": 98.21457401267253,
      "p90_itl_ms": 344.07692831009626,
      "p95_itl_ms": 372.4224541205331,
      "p99_itl_ms": 385.5508570870734,
      "output_throughput_tokens_per_sec": 4105.622793380507,
      "avg_batch_size": 1009.5436893203884,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          680,
          990,
          549,
          333,
          251,
          180,
          144,
          124,
          98,
          81,
          74,
          69,
          55,
          45,
          31,
          38,
          24,
          27,
          24,
          20,
          8,
          8,
          11,
          13,
          10,
          10,
          10,
          12,
          8,
          9,
          5,
          5,
          4,
          12,
          9,
          4,
          1,
          2,
          1,
          3,
          5,
          4,
          4,
          2,
          1,
          2,
          4,
          0,
          2,
          90
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.3661232958863816,
      "energy_per_request_joules": 340.1100023796823,
      "avg_power_watts": 6709.4314948328165,
      "median_itl_ms": 198.01920800819062,
      "p90_itl_ms": 393.2149354950525,
      "p95_itl_ms": 397.86103224469116,
      "p99_itl_ms": 485.27215850772353,
      "output_throughput_tokens_per_sec": 4445.850932269185,
      "avg_batch_size": 1520.8224852071005,
      "output_length_distribution": {
        "bins": [
          2.0,
          42.92,
          83.84,
          124.76,
          165.68,
          206.60000000000002,
          247.52,
          288.44,
          329.36,
          370.28000000000003,
          411.20000000000005,
          452.12,
          493.04,
          533.96,
          574.88,
          615.8000000000001,
          656.72,
          697.64,
          738.5600000000001,
          779.48,
          820.4000000000001,
          861.32,
          902.24,
          943.1600000000001,
          984.08,
          1025.0,
          1065.92,
          1106.8400000000001,
          1147.76,
          1188.68,
          1229.6000000000001,
          1270.52,
          1311.44,
          1352.3600000000001,
          1393.28,
          1434.2,
          1475.1200000000001,
          1516.04,
          1556.96,
          1597.88,
          1638.8000000000002,
          1679.72,
          1720.64,
          1761.5600000000002,
          1802.48,
          1843.4,
          1884.3200000000002,
          1925.24,
          1966.16,
          2007.0800000000002,
          2048.0
        ],
        "counts": [
          1038,
          1493,
          798,
          514,
          383,
          266,
          186,
          200,
          142,
          139,
          100,
          86,
          75,
          61,
          52,
          53,
          39,
          42,
          43,
          40,
          27,
          28,
          24,
          19,
          19,
          17,
          19,
          11,
          5,
          11,
          9,
          11,
          10,
          12,
          5,
          3,
          2,
          3,
          4,
          2,
          3,
          4,
          5,
          4,
          1,
          8,
          4,
          2,
          2,
          120
        ]
      }
    }
  ]
}