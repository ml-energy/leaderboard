{
  "activated_params_billions": 37.0,
  "architecture": "MoE",
  "configurations": [
    {
      "avg_batch_size": 7.999508720216163,
      "avg_output_len": 9081.873737373737,
      "avg_power_watts": 4260.855254483721,
      "energy_per_request_joules": 91299.6181960668,
      "energy_per_token_joules": 10.052949516392252,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 8,
      "median_itl_ms": 18.759104001219384,
      "num_gpus": 8,
      "output_length_distribution": {
        "bins": [
          487.0,
          1132.62,
          1778.24,
          2423.86,
          3069.48,
          3715.1,
          4360.72,
          5006.34,
          5651.96,
          6297.58,
          6943.2,
          7588.82,
          8234.44,
          8880.06,
          9525.68,
          10171.3,
          10816.92,
          11462.54,
          12108.16,
          12753.78,
          13399.4,
          14045.02,
          14690.64,
          15336.26,
          15981.880000000001,
          16627.5,
          17273.12,
          17918.74,
          18564.36,
          19209.98,
          19855.6,
          20501.22,
          21146.84,
          21792.46,
          22438.08,
          23083.7,
          23729.32,
          24374.94,
          25020.56,
          25666.18,
          26311.8,
          26957.420000000002,
          27603.04,
          28248.66,
          28894.28,
          29539.9,
          30185.52,
          30831.14,
          31476.760000000002,
          32122.38,
          32768.0
        ],
        "counts": [
          16,
          18,
          16,
          15,
          3,
          14,
          5,
          3,
          11,
          2,
          10,
          3,
          3,
          4,
          7,
          4,
          2,
          1,
          5,
          4,
          7,
          5,
          3,
          2,
          2,
          1,
          3,
          1,
          1,
          3,
          1,
          2,
          1,
          1,
          1,
          1,
          2,
          1,
          2,
          1,
          1,
          0,
          1,
          0,
          0,
          2,
          1,
          1,
          1,
          4
        ]
      },
      "output_throughput_tokens_per_sec": 423.8413062291826,
      "p90_itl_ms": 19.818756598397158,
      "p95_itl_ms": 20.0225453969324,
      "p99_itl_ms": 20.331353237852454,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 8,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 15.996767676767677,
      "avg_output_len": 8893.59090909091,
      "avg_power_watts": 4907.697680581875,
      "energy_per_request_joules": 65303.98064629207,
      "energy_per_token_joules": 7.342813641173804,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 16,
      "median_itl_ms": 23.8196899954346,
      "num_gpus": 8,
      "output_length_distribution": {
        "bins": [
          487.0,
          1132.62,
          1778.24,
          2423.86,
          3069.48,
          3715.1,
          4360.72,
          5006.34,
          5651.96,
          6297.58,
          6943.2,
          7588.82,
          8234.44,
          8880.06,
          9525.68,
          10171.3,
          10816.92,
          11462.54,
          12108.16,
          12753.78,
          13399.4,
          14045.02,
          14690.64,
          15336.26,
          15981.880000000001,
          16627.5,
          17273.12,
          17918.74,
          18564.36,
          19209.98,
          19855.6,
          20501.22,
          21146.84,
          21792.46,
          22438.08,
          23083.7,
          23729.32,
          24374.94,
          25020.56,
          25666.18,
          26311.8,
          26957.420000000002,
          27603.04,
          28248.66,
          28894.28,
          29539.9,
          30185.52,
          30831.14,
          31476.760000000002,
          32122.38,
          32768.0
        ],
        "counts": [
          14,
          25,
          19,
          13,
          5,
          13,
          7,
          5,
          5,
          4,
          9,
          4,
          1,
          3,
          3,
          6,
          3,
          3,
          4,
          4,
          0,
          2,
          2,
          5,
          2,
          0,
          2,
          1,
          1,
          1,
          3,
          2,
          4,
          2,
          1,
          3,
          2,
          3,
          3,
          2,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          4
        ]
      },
      "output_throughput_tokens_per_sec": 668.3674570007665,
      "p90_itl_ms": 25.742184797127265,
      "p95_itl_ms": 26.12001999950735,
      "p99_itl_ms": 26.771409560169552,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 8,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 31.993279569892472,
      "avg_output_len": 9057.924242424242,
      "avg_power_watts": 5364.666963511194,
      "energy_per_request_joules": 49442.84250807956,
      "energy_per_token_joules": 5.458517998694013,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 32,
      "median_itl_ms": 32.800897999550216,
      "num_gpus": 8,
      "output_length_distribution": {
        "bins": [
          487.0,
          1132.62,
          1778.24,
          2423.86,
          3069.48,
          3715.1,
          4360.72,
          5006.34,
          5651.96,
          6297.58,
          6943.2,
          7588.82,
          8234.44,
          8880.06,
          9525.68,
          10171.3,
          10816.92,
          11462.54,
          12108.16,
          12753.78,
          13399.4,
          14045.02,
          14690.64,
          15336.26,
          15981.880000000001,
          16627.5,
          17273.12,
          17918.74,
          18564.36,
          19209.98,
          19855.6,
          20501.22,
          21146.84,
          21792.46,
          22438.08,
          23083.7,
          23729.32,
          24374.94,
          25020.56,
          25666.18,
          26311.8,
          26957.420000000002,
          27603.04,
          28248.66,
          28894.28,
          29539.9,
          30185.52,
          30831.14,
          31476.760000000002,
          32122.38,
          32768.0
        ],
        "counts": [
          15,
          16,
          20,
          15,
          10,
          9,
          10,
          6,
          5,
          6,
          6,
          4,
          5,
          3,
          2,
          3,
          1,
          2,
          3,
          5,
          3,
          5,
          2,
          2,
          3,
          3,
          2,
          2,
          1,
          2,
          3,
          1,
          1,
          1,
          1,
          3,
          3,
          0,
          1,
          2,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          9
        ]
      },
      "output_throughput_tokens_per_sec": 982.80649890588,
      "p90_itl_ms": 36.317284997494426,
      "p95_itl_ms": 37.307107500964776,
      "p99_itl_ms": 38.29792009710218,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 8,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 63.998511904761905,
      "avg_output_len": 8675.828282828283,
      "avg_power_watts": 6041.29130155796,
      "energy_per_request_joules": 30513.483559207805,
      "energy_per_token_joules": 3.517068637654103,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 64,
      "median_itl_ms": 37.47100649707136,
      "num_gpus": 8,
      "output_length_distribution": {
        "bins": [
          487.0,
          1132.62,
          1778.24,
          2423.86,
          3069.48,
          3715.1,
          4360.72,
          5006.34,
          5651.96,
          6297.58,
          6943.2,
          7588.82,
          8234.44,
          8880.06,
          9525.68,
          10171.3,
          10816.92,
          11462.54,
          12108.16,
          12753.78,
          13399.4,
          14045.02,
          14690.64,
          15336.26,
          15981.880000000001,
          16627.5,
          17273.12,
          17918.74,
          18564.36,
          19209.98,
          19855.6,
          20501.22,
          21146.84,
          21792.46,
          22438.08,
          23083.7,
          23729.32,
          24374.94,
          25020.56,
          25666.18,
          26311.8,
          26957.420000000002,
          27603.04,
          28248.66,
          28894.28,
          29539.9,
          30185.52,
          30831.14,
          31476.760000000002,
          32122.38,
          32768.0
        ],
        "counts": [
          14,
          24,
          14,
          18,
          9,
          9,
          8,
          4,
          5,
          4,
          11,
          4,
          2,
          6,
          2,
          0,
          4,
          7,
          1,
          1,
          3,
          5,
          2,
          2,
          4,
          2,
          3,
          1,
          2,
          0,
          2,
          3,
          1,
          2,
          1,
          3,
          1,
          1,
          3,
          1,
          3,
          1,
          0,
          1,
          0,
          0,
          2,
          0,
          0,
          2
        ]
      },
      "output_throughput_tokens_per_sec": 1717.706398129188,
      "p90_itl_ms": 44.22798000450712,
      "p95_itl_ms": 45.16777925164206,
      "p99_itl_ms": 46.848201301327215,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 8,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 127.97902097902097,
      "avg_output_len": 9033.636363636364,
      "avg_power_watts": 6159.417027277624,
      "energy_per_request_joules": 16274.998351249935,
      "energy_per_token_joules": 1.8015998979948604,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 128,
      "median_itl_ms": 39.19294099978288,
      "num_gpus": 8,
      "output_length_distribution": {
        "bins": [
          487.0,
          1132.62,
          1778.24,
          2423.86,
          3069.48,
          3715.1,
          4360.72,
          5006.34,
          5651.96,
          6297.58,
          6943.2,
          7588.82,
          8234.44,
          8880.06,
          9525.68,
          10171.3,
          10816.92,
          11462.54,
          12108.16,
          12753.78,
          13399.4,
          14045.02,
          14690.64,
          15336.26,
          15981.880000000001,
          16627.5,
          17273.12,
          17918.74,
          18564.36,
          19209.98,
          19855.6,
          20501.22,
          21146.84,
          21792.46,
          22438.08,
          23083.7,
          23729.32,
          24374.94,
          25020.56,
          25666.18,
          26311.8,
          26957.420000000002,
          27603.04,
          28248.66,
          28894.28,
          29539.9,
          30185.52,
          30831.14,
          31476.760000000002,
          32122.38,
          32768.0
        ],
        "counts": [
          14,
          24,
          18,
          16,
          9,
          5,
          8,
          6,
          9,
          4,
          7,
          3,
          2,
          4,
          3,
          4,
          2,
          1,
          6,
          1,
          0,
          6,
          3,
          2,
          4,
          0,
          0,
          3,
          1,
          0,
          8,
          0,
          2,
          0,
          2,
          0,
          3,
          2,
          2,
          2,
          2,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          5
        ]
      },
      "output_throughput_tokens_per_sec": 3418.85955596074,
      "p90_itl_ms": 43.72462259925669,
      "p95_itl_ms": 45.05074470034742,
      "p99_itl_ms": 46.65174832058254,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 8,
        "notes": "",
        "tensor_parallel": 1
      }
    },
    {
      "avg_batch_size": 255.97607655502392,
      "avg_output_len": 8968.679292929293,
      "avg_power_watts": 6855.990889183953,
      "energy_per_request_joules": 11973.79343495625,
      "energy_per_token_joules": 1.335067633023306,
      "gpu_model": "B200",
      "max_num_batched_tokens": null,
      "max_num_seqs": 256,
      "median_itl_ms": 55.46886500087567,
      "num_gpus": 8,
      "output_length_distribution": {
        "bins": [
          487.0,
          1132.62,
          1778.24,
          2423.86,
          3069.48,
          3715.1,
          4360.72,
          5006.34,
          5651.96,
          6297.58,
          6943.2,
          7588.82,
          8234.44,
          8880.06,
          9525.68,
          10171.3,
          10816.92,
          11462.54,
          12108.16,
          12753.78,
          13399.4,
          14045.02,
          14690.64,
          15336.26,
          15981.880000000001,
          16627.5,
          17273.12,
          17918.74,
          18564.36,
          19209.98,
          19855.6,
          20501.22,
          21146.84,
          21792.46,
          22438.08,
          23083.7,
          23729.32,
          24374.94,
          25020.56,
          25666.18,
          26311.8,
          26957.420000000002,
          27603.04,
          28248.66,
          28894.28,
          29539.9,
          30185.52,
          30831.14,
          31476.760000000002,
          32122.38,
          32768.0
        ],
        "counts": [
          32,
          35,
          42,
          24,
          20,
          22,
          8,
          16,
          18,
          9,
          10,
          7,
          6,
          6,
          3,
          7,
          9,
          4,
          4,
          5,
          6,
          4,
          6,
          3,
          8,
          6,
          6,
          6,
          6,
          8,
          1,
          4,
          6,
          1,
          6,
          4,
          5,
          3,
          0,
          2,
          1,
          1,
          1,
          3,
          1,
          0,
          1,
          2,
          3,
          5
        ]
      },
      "output_throughput_tokens_per_sec": 5135.31353738112,
      "p90_itl_ms": 60.28186200273922,
      "p95_itl_ms": 62.36090200400213,
      "p99_itl_ms": 86.3645200006431,
      "parallelization": {
        "data_parallel": 1,
        "expert_parallel": 8,
        "notes": "",
        "tensor_parallel": 1
      }
    }
  ],
  "model_id": "deepseek-ai/DeepSeek-V3.1",
  "output_length_distribution": {
    "bins": [
      487.0,
      1132.62,
      1778.24,
      2423.86,
      3069.48,
      3715.1,
      4360.72,
      5006.34,
      5651.96,
      6297.58,
      6943.2,
      7588.82,
      8234.44,
      8880.06,
      9525.68,
      10171.3,
      10816.92,
      11462.54,
      12108.16,
      12753.78,
      13399.4,
      14045.02,
      14690.64,
      15336.26,
      15981.880000000001,
      16627.5,
      17273.12,
      17918.74,
      18564.36,
      19209.98,
      19855.6,
      20501.22,
      21146.84,
      21792.46,
      22438.08,
      23083.7,
      23729.32,
      24374.94,
      25020.56,
      25666.18,
      26311.8,
      26957.420000000002,
      27603.04,
      28248.66,
      28894.28,
      29539.9,
      30185.52,
      30831.14,
      31476.760000000002,
      32122.38,
      32768.0
    ],
    "counts": [
      105,
      142,
      129,
      101,
      56,
      72,
      46,
      40,
      53,
      29,
      53,
      25,
      19,
      26,
      20,
      24,
      21,
      18,
      23,
      20,
      19,
      27,
      18,
      16,
      23,
      12,
      16,
      14,
      12,
      14,
      18,
      12,
      15,
      7,
      12,
      14,
      16,
      10,
      11,
      10,
      8,
      3,
      4,
      5,
      2,
      3,
      5,
      3,
      6,
      29
    ]
  },
  "task": "gpqa",
  "total_params_billions": 671.0,
  "weight_precision": "fp8"
}