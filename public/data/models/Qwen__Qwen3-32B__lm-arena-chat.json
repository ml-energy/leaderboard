{
  "model_id": "Qwen/Qwen3-32B",
  "task": "lm-arena-chat",
  "total_params_billions": 32.0,
  "activated_params_billions": 32.0,
  "architecture": "Dense Transformer",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      2.0,
      83.88,
      165.76,
      247.64,
      329.52,
      411.4,
      493.28,
      575.16,
      657.04,
      738.92,
      820.8,
      902.68,
      984.56,
      1066.44,
      1148.32,
      1230.1999999999998,
      1312.08,
      1393.96,
      1475.84,
      1557.7199999999998,
      1639.6,
      1721.48,
      1803.36,
      1885.2399999999998,
      1967.12,
      2049.0,
      2130.88,
      2212.7599999999998,
      2294.64,
      2376.52,
      2458.3999999999996,
      2540.2799999999997,
      2622.16,
      2704.04,
      2785.92,
      2867.7999999999997,
      2949.68,
      3031.56,
      3113.4399999999996,
      3195.3199999999997,
      3277.2,
      3359.08,
      3440.96,
      3522.8399999999997,
      3604.72,
      3686.6,
      3768.4799999999996,
      3850.3599999999997,
      3932.24,
      4014.12,
      4096.0
    ],
    "counts": [
      4440,
      2164,
      1608,
      1541,
      1394,
      1213,
      1203,
      1263,
      1237,
      1263,
      1174,
      1043,
      970,
      813,
      685,
      598,
      468,
      407,
      347,
      318,
      259,
      234,
      189,
      146,
      129,
      92,
      86,
      64,
      60,
      45,
      32,
      10,
      19,
      18,
      7,
      10,
      6,
      6,
      2,
      5,
      6,
      2,
      0,
      2,
      2,
      2,
      1,
      2,
      1,
      14
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.9613599478219963,
      "energy_per_request_joules": 601.3437909556953,
      "avg_power_watts": 566.219327648272,
      "median_itl_ms": 26.353154331445694,
      "p90_itl_ms": 27.748262882232666,
      "p95_itl_ms": 28.254767972975966,
      "p99_itl_ms": 33.39976480230688,
      "output_throughput_tokens_per_sec": 581.6949776922954,
      "avg_batch_size": 15.969953051643193,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          183,
          84,
          66,
          55,
          57,
          47,
          54,
          54,
          42,
          54,
          48,
          41,
          35,
          40,
          27,
          23,
          23,
          10,
          13,
          16,
          7,
          4,
          8,
          5,
          5,
          3,
          7,
          2,
          5,
          2,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.6239901651860145,
      "energy_per_request_joules": 392.6896857517892,
      "avg_power_watts": 599.3695473965292,
      "median_itl_ms": 28.807315975427628,
      "p90_itl_ms": 29.899904504418373,
      "p95_itl_ms": 30.685177911072966,
      "p99_itl_ms": 67.19147257506849,
      "output_throughput_tokens_per_sec": 930.0413020110318,
      "avg_batch_size": 29.26,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          179,
          81,
          70,
          63,
          50,
          44,
          46,
          57,
          52,
          56,
          48,
          49,
          26,
          31,
          23,
          26,
          21,
          15,
          14,
          19,
          14,
          6,
          9,
          6,
          3,
          2,
          1,
          4,
          3,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.7256601588401939,
      "energy_per_request_joules": 1100.4790985603745,
      "avg_power_watts": 538.4142363571873,
      "median_itl_ms": 25.205765850842,
      "p90_itl_ms": 26.041114702820778,
      "p95_itl_ms": 26.380172930657864,
      "p99_itl_ms": 27.392359357327226,
      "output_throughput_tokens_per_sec": 309.84312360008494,
      "avg_batch_size": 7.9854651162790695,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          175,
          93,
          67,
          55,
          56,
          57,
          43,
          52,
          44,
          46,
          54,
          36,
          40,
          33,
          27,
          25,
          14,
          13,
          20,
          12,
          13,
          8,
          8,
          5,
          4,
          2,
          7,
          2,
          1,
          3,
          3,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.27493467660499615,
      "energy_per_request_joules": 171.5957529632542,
      "avg_power_watts": 1073.7054290819397,
      "median_itl_ms": 29.656008817255497,
      "p90_itl_ms": 33.37810207158327,
      "p95_itl_ms": 42.72646140307189,
      "p99_itl_ms": 97.02063553035259,
      "output_throughput_tokens_per_sec": 3372.457348426032,
      "avg_batch_size": 127.84027777777777,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          171,
          96,
          62,
          62,
          55,
          51,
          43,
          54,
          50,
          49,
          52,
          49,
          34,
          34,
          26,
          25,
          14,
          16,
          12,
          14,
          11,
          9,
          8,
          6,
          5,
          2,
          2,
          1,
          4,
          1,
          3,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.9099358744238063,
      "energy_per_request_joules": 569.230646536766,
      "avg_power_watts": 882.7766718244878,
      "median_itl_ms": 16.036865301430225,
      "p90_itl_ms": 16.648652032017708,
      "p95_itl_ms": 16.839390527457,
      "p99_itl_ms": 21.17397813126445,
      "output_throughput_tokens_per_sec": 948.7007765865945,
      "avg_batch_size": 15.970496894409937,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          171,
          99,
          58,
          74,
          59,
          45,
          39,
          56,
          50,
          56,
          30,
          41,
          43,
          34,
          24,
          24,
          22,
          16,
          15,
          12,
          8,
          9,
          4,
          15,
          3,
          3,
          5,
          2,
          1,
          1,
          0,
          2,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.24843677733933386,
      "energy_per_request_joules": 157.02174784007383,
      "avg_power_watts": 1143.1306846891766,
      "median_itl_ms": 37.01616916805506,
      "p90_itl_ms": 43.76935381442312,
      "p95_itl_ms": 61.56245293095707,
      "p99_itl_ms": 128.9956690557327,
      "output_throughput_tokens_per_sec": 3777.197938187244,
      "avg_batch_size": 191.74358974358975,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          181,
          79,
          67,
          64,
          53,
          46,
          46,
          54,
          48,
          46,
          53,
          44,
          45,
          34,
          22,
          19,
          16,
          17,
          18,
          13,
          10,
          9,
          12,
          7,
          4,
          4,
          1,
          4,
          0,
          3,
          0,
          0,
          1,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.22848064345644722,
      "energy_per_request_joules": 144.96092761983886,
      "avg_power_watts": 1177.9230310696903,
      "median_itl_ms": 44.45189796388149,
      "p90_itl_ms": 55.59205114841466,
      "p95_itl_ms": 74.43105783313511,
      "p99_itl_ms": 148.15355882048607,
      "output_throughput_tokens_per_sec": 3733.522067028902,
      "avg_batch_size": 255.58762886597938,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          174,
          94,
          64,
          46,
          63,
          62,
          47,
          46,
          42,
          43,
          52,
          47,
          41,
          33,
          25,
          27,
          16,
          19,
          12,
          15,
          6,
          8,
          7,
          6,
          7,
          4,
          4,
          7,
          1,
          1,
          2,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.5535647504164556,
      "energy_per_request_joules": 355.2177431451657,
      "avg_power_watts": 944.462703925736,
      "median_itl_ms": 17.91422814130783,
      "p90_itl_ms": 18.73834375292063,
      "p95_itl_ms": 19.087451603263617,
      "p99_itl_ms": 33.89401728287314,
      "output_throughput_tokens_per_sec": 1528.4446462979884,
      "avg_batch_size": 31.935656836461128,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          171,
          95,
          59,
          62,
          51,
          53,
          47,
          45,
          52,
          51,
          48,
          51,
          34,
          34,
          21,
          23,
          28,
          11,
          16,
          13,
          10,
          6,
          5,
          3,
          10,
          6,
          5,
          3,
          3,
          0,
          2,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.23269302379414677,
      "energy_per_request_joules": 146.0310064197816,
      "avg_power_watts": 1179.9335260193766,
      "median_itl_ms": 54.89538051187992,
      "p90_itl_ms": 82.19895176589489,
      "p95_itl_ms": 111.24950386583802,
      "p99_itl_ms": 240.1536944136023,
      "output_throughput_tokens_per_sec": 3829.9413180172537,
      "avg_batch_size": 340.18518518518516,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          178,
          87,
          61,
          61,
          67,
          39,
          48,
          51,
          43,
          59,
          42,
          49,
          45,
          28,
          30,
          22,
          15,
          17,
          18,
          9,
          12,
          6,
          10,
          5,
          6,
          3,
          2,
          2,
          1,
          1,
          2,
          0,
          2,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.3670707459382538,
      "energy_per_request_joules": 233.11824260529224,
      "avg_power_watts": 974.1410465427495,
      "median_itl_ms": 22.44568057358265,
      "p90_itl_ms": 23.600613698363304,
      "p95_itl_ms": 25.688573531806398,
      "p99_itl_ms": 64.99680075794453,
      "output_throughput_tokens_per_sec": 2313.0304866033935,
      "avg_batch_size": 63.8646288209607,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          174,
          91,
          61,
          59,
          61,
          51,
          47,
          47,
          53,
          45,
          48,
          37,
          37,
          41,
          37,
          20,
          13,
          18,
          15,
          14,
          11,
          8,
          6,
          4,
          5,
          4,
          5,
          1,
          5,
          0,
          2,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.6271197003089002,
      "energy_per_request_joules": 1026.7776792422917,
      "avg_power_watts": 850.1373193376241,
      "median_itl_ms": 15.06047509610653,
      "p90_itl_ms": 15.467118471860886,
      "p95_itl_ms": 15.633875504136086,
      "p99_itl_ms": 17.32978187501431,
      "output_throughput_tokens_per_sec": 517.2816099750263,
      "avg_batch_size": 7.990155865463494,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          176,
          85,
          65,
          56,
          55,
          50,
          56,
          56,
          45,
          63,
          35,
          44,
          36,
          30,
          32,
          25,
          18,
          14,
          13,
          12,
          10,
          8,
          10,
          4,
          4,
          4,
          3,
          3,
          2,
          2,
          2,
          1,
          1,
          2,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.30455435553491284,
      "energy_per_request_joules": 193.37327853381154,
      "avg_power_watts": 1021.968645687438,
      "median_itl_ms": 26.096563786268234,
      "p90_itl_ms": 28.729891031980515,
      "p95_itl_ms": 32.105561345815666,
      "p99_itl_ms": 78.12223881483078,
      "output_throughput_tokens_per_sec": 2647.271172617246,
      "avg_batch_size": 95.8135593220339,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          175,
          85,
          64,
          74,
          44,
          41,
          58,
          53,
          49,
          46,
          54,
          41,
          33,
          31,
          27,
          27,
          21,
          20,
          15,
          12,
          6,
          9,
          5,
          6,
          4,
          5,
          6,
          1,
          4,
          1,
          1,
          0,
          0,
          2,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.20864651577192456,
      "energy_per_request_joules": 132.2973764829926,
      "avg_power_watts": 975.5957432445775,
      "median_itl_ms": 24.72050450160168,
      "p90_itl_ms": 32.939433003775775,
      "p95_itl_ms": 38.228705797519076,
      "p99_itl_ms": 65.6113175497738,
      "output_throughput_tokens_per_sec": 3643.9591737120145,
      "avg_batch_size": 127.78048780487805,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          181,
          83,
          65,
          52,
          65,
          50,
          48,
          55,
          39,
          53,
          43,
          42,
          50,
          29,
          27,
          17,
          22,
          17,
          14,
          10,
          10,
          11,
          7,
          12,
          4,
          6,
          0,
          3,
          0,
          2,
          2,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.8159244170412998,
      "energy_per_request_joules": 512.9694499505373,
      "avg_power_watts": 836.3809406652724,
      "median_itl_ms": 15.11033899441827,
      "p90_itl_ms": 17.966197305941026,
      "p95_itl_ms": 20.78293744998517,
      "p99_itl_ms": 31.63132181711269,
      "output_throughput_tokens_per_sec": 1000.8879222181407,
      "avg_batch_size": 15.96742671009772,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          173,
          90,
          69,
          64,
          51,
          49,
          56,
          45,
          41,
          50,
          52,
          42,
          36,
          33,
          31,
          19,
          20,
          15,
          17,
          12,
          8,
          13,
          7,
          9,
          6,
          3,
          1,
          3,
          2,
          2,
          2,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.17681459087226048,
      "energy_per_request_joules": 112.34719675593938,
      "avg_power_watts": 969.4150830337443,
      "median_itl_ms": 31.635102990549058,
      "p90_itl_ms": 41.79628597921692,
      "p95_itl_ms": 51.09449400333688,
      "p99_itl_ms": 83.85509598883802,
      "output_throughput_tokens_per_sec": 4566.646199188962,
      "avg_batch_size": 191.58163265306123,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          179,
          84,
          62,
          66,
          51,
          53,
          49,
          51,
          54,
          49,
          45,
          40,
          38,
          26,
          28,
          28,
          16,
          18,
          10,
          11,
          11,
          13,
          9,
          5,
          6,
          7,
          5,
          1,
          1,
          3,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.15072305201913658,
      "energy_per_request_joules": 94.57739042768381,
      "avg_power_watts": 971.2567983598984,
      "median_itl_ms": 36.022864005644806,
      "p90_itl_ms": 48.6644494056236,
      "p95_itl_ms": 56.358281818393145,
      "p99_itl_ms": 97.60897816129719,
      "output_throughput_tokens_per_sec": 5598.395288953967,
      "avg_batch_size": 255.62285714285716,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          346,
          185,
          127,
          133,
          115,
          82,
          100,
          107,
          103,
          112,
          97,
          64,
          77,
          60,
          45,
          49,
          36,
          39,
          28,
          27,
          28,
          15,
          16,
          6,
          11,
          4,
          8,
          6,
          10,
          4,
          3,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.4734976077616866,
      "energy_per_request_joules": 300.0351809182488,
      "avg_power_watts": 848.7690635227195,
      "median_itl_ms": 16.813653986901045,
      "p90_itl_ms": 24.107908585574478,
      "p95_itl_ms": 27.652266106451858,
      "p99_itl_ms": 40.08290835598017,
      "output_throughput_tokens_per_sec": 1698.376407566365,
      "avg_batch_size": 31.902298850574713,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          181,
          79,
          69,
          61,
          44,
          59,
          45,
          53,
          45,
          52,
          49,
          39,
          43,
          28,
          35,
          24,
          18,
          15,
          14,
          11,
          11,
          15,
          5,
          7,
          7,
          1,
          1,
          3,
          3,
          3,
          0,
          0,
          0,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.1405811962285976,
      "energy_per_request_joules": 89.26404865431735,
      "avg_power_watts": 971.6747776603263,
      "median_itl_ms": 50.2491410006769,
      "p90_itl_ms": 66.56363700749351,
      "p95_itl_ms": 77.11441750579975,
      "p99_itl_ms": 131.57422270800444,
      "output_throughput_tokens_per_sec": 5418.501101645695,
      "avg_batch_size": 383.34640522875816,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          361,
          165,
          126,
          118,
          127,
          92,
          98,
          90,
          108,
          93,
          100,
          83,
          79,
          67,
          56,
          47,
          36,
          37,
          17,
          25,
          25,
          24,
          16,
          11,
          5,
          8,
          3,
          7,
          4,
          5,
          3,
          0,
          2,
          1,
          0,
          5,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.15078613374588773,
      "energy_per_request_joules": 94.60777040155742,
      "avg_power_watts": 968.8827415172412,
      "median_itl_ms": 57.57595301838592,
      "p90_itl_ms": 93.01012900541537,
      "p95_itl_ms": 131.57266860362097,
      "p99_itl_ms": 250.04708052263587,
      "output_throughput_tokens_per_sec": 5508.589952542401,
      "avg_batch_size": 455.73026315789474,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          368,
          156,
          133,
          128,
          115,
          108,
          78,
          94,
          110,
          86,
          109,
          73,
          82,
          62,
          60,
          49,
          41,
          32,
          34,
          26,
          13,
          17,
          10,
          14,
          13,
          9,
          10,
          3,
          5,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.31263251437703116,
      "energy_per_request_joules": 197.24272318925327,
      "avg_power_watts": 945.4371052002505,
      "median_itl_ms": 19.583309011068195,
      "p90_itl_ms": 27.58910280535929,
      "p95_itl_ms": 31.90371829841751,
      "p99_itl_ms": 48.932129096356185,
      "output_throughput_tokens_per_sec": 2786.367213199761,
      "avg_batch_size": 63.91,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          185,
          80,
          61,
          67,
          47,
          44,
          59,
          49,
          51,
          54,
          35,
          48,
          37,
          37,
          22,
          29,
          22,
          19,
          9,
          12,
          7,
          16,
          8,
          2,
          4,
          2,
          5,
          2,
          1,
          3,
          2,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.5450541142659606,
      "energy_per_request_joules": 997.7141677615186,
      "avg_power_watts": 859.6469411324731,
      "median_itl_ms": 14.126725000096485,
      "p90_itl_ms": 15.713961998699233,
      "p95_itl_ms": 17.302533000474796,
      "p99_itl_ms": 27.10405021207407,
      "output_throughput_tokens_per_sec": 551.1340492165906,
      "avg_batch_size": 7.973481608212147,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          176,
          88,
          65,
          56,
          62,
          43,
          44,
          47,
          65,
          54,
          40,
          35,
          28,
          29,
          39,
          29,
          17,
          15,
          13,
          11,
          15,
          9,
          12,
          4,
          8,
          2,
          1,
          2,
          3,
          3,
          2,
          0,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.23657720080514735,
      "energy_per_request_joules": 148.71996008309438,
      "avg_power_watts": 970.4547244114405,
      "median_itl_ms": 21.336754987714812,
      "p90_itl_ms": 28.89867899939418,
      "p95_itl_ms": 33.98535900050772,
      "p99_itl_ms": 50.91743976459812,
      "output_throughput_tokens_per_sec": 3112.050778889969,
      "avg_batch_size": 95.79577464788733,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          182,
          85,
          67,
          65,
          46,
          47,
          52,
          47,
          51,
          46,
          40,
          48,
          51,
          39,
          21,
          21,
          19,
          14,
          10,
          12,
          13,
          11,
          7,
          4,
          5,
          8,
          4,
          2,
          1,
          3,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    }
  ]
}