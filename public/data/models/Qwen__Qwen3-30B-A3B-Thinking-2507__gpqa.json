{
  "model_id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
  "task": "gpqa",
  "total_params_billions": 30.0,
  "activated_params_billions": 3.0,
  "architecture": "MoE",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      918.0,
      1417.76,
      1917.52,
      2417.2799999999997,
      2917.04,
      3416.8,
      3916.56,
      4416.32,
      4916.08,
      5415.84,
      5915.6,
      6415.36,
      6915.12,
      7414.88,
      7914.639999999999,
      8414.4,
      8914.16,
      9413.92,
      9913.68,
      10413.44,
      10913.2,
      11412.96,
      11912.72,
      12412.48,
      12912.24,
      13412.0,
      13911.76,
      14411.52,
      14911.279999999999,
      15411.039999999999,
      15910.8,
      16410.559999999998,
      16910.32,
      17410.079999999998,
      17909.84,
      18409.6,
      18909.36,
      19409.12,
      19908.88,
      20408.64,
      20908.4,
      21408.16,
      21907.92,
      22407.68,
      22907.44,
      23407.2,
      23906.96,
      24406.72,
      24906.48,
      25406.239999999998,
      25906.0
    ],
    "counts": [
      70,
      120,
      118,
      156,
      174,
      182,
      172,
      182,
      171,
      146,
      144,
      134,
      106,
      106,
      101,
      105,
      96,
      83,
      81,
      92,
      88,
      104,
      76,
      81,
      85,
      78,
      60,
      59,
      56,
      29,
      37,
      39,
      40,
      37,
      22,
      24,
      25,
      19,
      5,
      14,
      10,
      8,
      7,
      5,
      2,
      2,
      5,
      4,
      2,
      2
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5914881665808681,
      "energy_per_request_joules": 4875.6130586143145,
      "avg_output_len": 8242.959595959595,
      "avg_power_watts": 564.8065033526215,
      "median_itl_ms": 16.748839057981968,
      "p90_itl_ms": 18.053930439054966,
      "p95_itl_ms": 18.540182430297136,
      "p99_itl_ms": 21.3086342997849,
      "output_throughput_tokens_per_sec": 924.808799907507,
      "avg_batch_size": 15.995015576323988,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          2,
          4,
          9,
          7,
          10,
          14,
          12,
          12,
          7,
          5,
          11,
          9,
          3,
          8,
          5,
          3,
          0,
          4,
          5,
          3,
          5,
          5,
          13,
          7,
          5,
          5,
          1,
          2,
          5,
          1,
          2,
          1,
          4,
          1,
          2,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8011522660693712,
      "energy_per_request_joules": 6539.15450593015,
      "avg_output_len": 8162.186868686868,
      "avg_power_watts": 519.22159254518,
      "median_itl_ms": 12.309283018112183,
      "p90_itl_ms": 13.100481033325195,
      "p95_itl_ms": 13.35893217474222,
      "p99_itl_ms": 16.339488066732873,
      "output_throughput_tokens_per_sec": 632.9125162348574,
      "avg_batch_size": 7.997072354663321,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          2,
          7,
          8,
          8,
          7,
          9,
          12,
          10,
          10,
          7,
          8,
          8,
          10,
          5,
          4,
          9,
          6,
          6,
          3,
          5,
          5,
          7,
          2,
          2,
          8,
          4,
          0,
          5,
          0,
          2,
          2,
          3,
          3,
          3,
          1,
          2,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.19860518070462557,
      "energy_per_request_joules": 1600.3505155531907,
      "avg_output_len": 8057.949494949495,
      "avg_power_watts": 926.3172382702305,
      "median_itl_ms": 28.594817966222763,
      "p90_itl_ms": 32.3397321626544,
      "p95_itl_ms": 32.74561371654272,
      "p99_itl_ms": 33.72602770105004,
      "output_throughput_tokens_per_sec": 2816.968000561452,
      "avg_batch_size": 127.98863636363636,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          5,
          6,
          7,
          5,
          11,
          12,
          13,
          8,
          7,
          10,
          5,
          9,
          6,
          8,
          4,
          5,
          2,
          7,
          7,
          8,
          2,
          8,
          8,
          5,
          1,
          4,
          8,
          0,
          2,
          1,
          0,
          1,
          3,
          2,
          2,
          0,
          0,
          2,
          0,
          0,
          0,
          1,
          0,
          2,
          0,
          0,
          1,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5928453764785513,
      "energy_per_request_joules": 4713.210568061525,
      "avg_output_len": 7950.151515151515,
      "avg_power_watts": 787.4286318346727,
      "median_itl_ms": 11.967048048973083,
      "p90_itl_ms": 12.794099375605585,
      "p95_itl_ms": 13.057692814618349,
      "p99_itl_ms": 13.601342476904392,
      "output_throughput_tokens_per_sec": 1248.549483964826,
      "avg_batch_size": 15.999084249084248,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          4,
          8,
          8,
          12,
          5,
          6,
          15,
          7,
          9,
          8,
          7,
          6,
          8,
          9,
          6,
          8,
          7,
          3,
          4,
          4,
          7,
          5,
          4,
          4,
          7,
          4,
          2,
          4,
          1,
          3,
          2,
          1,
          0,
          1,
          0,
          3,
          1,
          2,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4291973367276949,
      "energy_per_request_joules": 3480.96381392695,
      "avg_output_len": 8110.404040404041,
      "avg_power_watts": 843.5222415723906,
      "median_itl_ms": 16.395246610045433,
      "p90_itl_ms": 17.110166512429714,
      "p95_itl_ms": 17.271547671407458,
      "p99_itl_ms": 17.595617100596428,
      "output_throughput_tokens_per_sec": 1780.3378962907657,
      "avg_batch_size": 31.99586206896552,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          5,
          6,
          5,
          10,
          14,
          8,
          8,
          10,
          10,
          7,
          3,
          11,
          4,
          6,
          6,
          7,
          4,
          7,
          4,
          7,
          4,
          5,
          5,
          10,
          3,
          0,
          5,
          2,
          3,
          2,
          4,
          2,
          3,
          2,
          1,
          2,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.30312186679783765,
      "energy_per_request_joules": 2460.302410131322,
      "avg_output_len": 8116.545454545455,
      "avg_power_watts": 910.0537943622338,
      "median_itl_ms": 21.53947949409485,
      "p90_itl_ms": 22.987710312008858,
      "p95_itl_ms": 23.289293609559536,
      "p99_itl_ms": 23.904349207878113,
      "output_throughput_tokens_per_sec": 2482.019395422607,
      "avg_batch_size": 63.997518610421835,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          2,
          3,
          9,
          9,
          8,
          12,
          9,
          14,
          12,
          7,
          9,
          9,
          5,
          2,
          8,
          3,
          7,
          3,
          6,
          2,
          5,
          7,
          6,
          4,
          5,
          6,
          2,
          2,
          2,
          3,
          3,
          3,
          2,
          3,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8358966354324942,
      "energy_per_request_joules": 6945.579129713426,
      "avg_output_len": 8309.136363636364,
      "avg_power_watts": 710.2988788848096,
      "median_itl_ms": 9.367374703288078,
      "p90_itl_ms": 9.84083116054535,
      "p95_itl_ms": 9.986687451601028,
      "p99_itl_ms": 10.294333472847937,
      "output_throughput_tokens_per_sec": 832.3275512517333,
      "avg_batch_size": 7.999461206896552,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          4,
          6,
          10,
          5,
          16,
          7,
          9,
          8,
          9,
          9,
          8,
          11,
          4,
          5,
          5,
          3,
          1,
          3,
          2,
          12,
          6,
          6,
          5,
          4,
          6,
          6,
          3,
          2,
          2,
          1,
          2,
          3,
          2,
          1,
          2,
          1,
          3,
          2,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2574851684497885,
      "energy_per_request_joules": 2132.7951653246278,
      "avg_output_len": 8283.176767676769,
      "avg_power_watts": 915.6778884394571,
      "median_itl_ms": 27.714597061276436,
      "p90_itl_ms": 30.28995543718338,
      "p95_itl_ms": 30.615631490945816,
      "p99_itl_ms": 31.410065293312076,
      "output_throughput_tokens_per_sec": 2542.1307504135607,
      "avg_batch_size": 95.99350649350649,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          5,
          8,
          8,
          6,
          8,
          10,
          7,
          11,
          9,
          7,
          8,
          7,
          9,
          5,
          7,
          5,
          8,
          4,
          5,
          3,
          5,
          6,
          4,
          4,
          5,
          5,
          4,
          4,
          1,
          0,
          2,
          2,
          2,
          3,
          1,
          1,
          2,
          3,
          0,
          0,
          2,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.1934264294192746,
      "energy_per_request_joules": 1631.7971343424108,
      "avg_output_len": 8436.267676767677,
      "avg_power_watts": 477.13867767070093,
      "median_itl_ms": 56.67889100732282,
      "p90_itl_ms": 75.91897319653073,
      "p95_itl_ms": 82.61979750532187,
      "p99_itl_ms": 98.56466554396317,
      "output_throughput_tokens_per_sec": 1290.8783076062641,
      "avg_batch_size": 127.97109826589596,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          5,
          5,
          4,
          8,
          10,
          13,
          11,
          8,
          12,
          8,
          6,
          8,
          5,
          3,
          3,
          8,
          5,
          8,
          6,
          6,
          5,
          2,
          2,
          5,
          3,
          8,
          2,
          2,
          5,
          1,
          2,
          3,
          1,
          1,
          4,
          0,
          2,
          4,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.7911158535301838,
      "energy_per_request_joules": 6413.084773811704,
      "avg_output_len": 8106.378787878788,
      "avg_power_watts": 389.82085814005154,
      "median_itl_ms": 32.46195850078948,
      "p90_itl_ms": 47.92680539540015,
      "p95_itl_ms": 52.92729524662718,
      "p99_itl_ms": 64.06189499393804,
      "output_throughput_tokens_per_sec": 474.48717906077445,
      "avg_batch_size": 15.994067237969677,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          5,
          8,
          3,
          12,
          8,
          9,
          13,
          10,
          7,
          12,
          7,
          5,
          3,
          9,
          7,
          7,
          5,
          2,
          5,
          4,
          5,
          7,
          4,
          6,
          4,
          3,
          2,
          4,
          3,
          0,
          3,
          1,
          1,
          2,
          2,
          3,
          0,
          2,
          1,
          2,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.14587475427987087,
      "energy_per_request_joules": 1205.2448476546642,
      "avg_output_len": 8262.189393939394,
      "avg_power_watts": 541.0238473628527,
      "median_itl_ms": 70.95763701363467,
      "p90_itl_ms": 100.13763199094683,
      "p95_itl_ms": 108.37734199594706,
      "p99_itl_ms": 130.12055170838727,
      "output_throughput_tokens_per_sec": 1685.2777206984842,
      "avg_batch_size": 241.4622222222222,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          6,
          19,
          7,
          19,
          19,
          20,
          20,
          22,
          15,
          17,
          14,
          10,
          11,
          11,
          13,
          14,
          19,
          7,
          9,
          8,
          7,
          13,
          6,
          8,
          10,
          8,
          8,
          9,
          10,
          4,
          3,
          5,
          4,
          5,
          4,
          2,
          2,
          1,
          2,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.49353726549342825,
      "energy_per_request_joules": 3950.743376762825,
      "avg_output_len": 8004.954545454545,
      "avg_power_watts": 437.99892250325576,
      "median_itl_ms": 35.12723097810522,
      "p90_itl_ms": 51.04164220392704,
      "p95_itl_ms": 56.551950084394775,
      "p99_itl_ms": 69.769805209944,
      "output_throughput_tokens_per_sec": 820.9256648631948,
      "avg_batch_size": 31.989911727616647,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          4,
          7,
          6,
          6,
          13,
          10,
          7,
          9,
          12,
          13,
          13,
          5,
          4,
          6,
          4,
          8,
          5,
          7,
          3,
          5,
          6,
          3,
          3,
          3,
          3,
          5,
          1,
          4,
          5,
          0,
          1,
          1,
          3,
          5,
          0,
          2,
          0,
          0,
          1,
          2,
          2,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.08764893013466918,
      "energy_per_request_joules": 713.6920377342874,
      "avg_output_len": 8142.621212121212,
      "avg_power_watts": 544.5395244066468,
      "median_itl_ms": 86.69960199040361,
      "p90_itl_ms": 110.86475100019015,
      "p95_itl_ms": 120.47574820753644,
      "p99_itl_ms": 168.23538968281358,
      "output_throughput_tokens_per_sec": 1782.5590356250043,
      "avg_batch_size": 459.52244897959184,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          14,
          19,
          18,
          28,
          27,
          36,
          23,
          36,
          36,
          20,
          22,
          18,
          22,
          14,
          13,
          17,
          17,
          17,
          11,
          17,
          12,
          20,
          3,
          10,
          15,
          12,
          17,
          12,
          9,
          8,
          8,
          8,
          6,
          5,
          1,
          4,
          9,
          2,
          0,
          1,
          1,
          2,
          1,
          0,
          0,
          0,
          1,
          2,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3046892441657647,
      "energy_per_request_joules": 2528.322119929481,
      "avg_output_len": 8298.035353535353,
      "avg_power_watts": 470.6360547173012,
      "median_itl_ms": 40.632746007759124,
      "p90_itl_ms": 55.97567781805993,
      "p95_itl_ms": 61.806749395327614,
      "p99_itl_ms": 78.25580780045065,
      "output_throughput_tokens_per_sec": 1115.6082732354787,
      "avg_batch_size": 63.98337595907928,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          5,
          6,
          8,
          11,
          6,
          8,
          6,
          10,
          11,
          8,
          9,
          10,
          5,
          5,
          8,
          3,
          5,
          4,
          4,
          6,
          4,
          6,
          7,
          6,
          4,
          2,
          4,
          4,
          4,
          2,
          1,
          2,
          3,
          2,
          0,
          1,
          3,
          0,
          0,
          4,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.3199246936016353,
      "energy_per_request_joules": 10522.292999092948,
      "avg_output_len": 7971.888888888889,
      "avg_power_watts": 304.76387398824545,
      "median_itl_ms": 35.00107250874862,
      "p90_itl_ms": 49.47978199925274,
      "p95_itl_ms": 54.143508736160584,
      "p99_itl_ms": 64.42524934682295,
      "output_throughput_tokens_per_sec": 230.31277418592592,
      "avg_batch_size": 7.994999242309441,
      "output_length_distribution": {
        "bins": [
          918.0,
          1417.76,
          1917.52,
          2417.2799999999997,
          2917.04,
          3416.8,
          3916.56,
          4416.32,
          4916.08,
          5415.84,
          5915.6,
          6415.36,
          6915.12,
          7414.88,
          7914.639999999999,
          8414.4,
          8914.16,
          9413.92,
          9913.68,
          10413.44,
          10913.2,
          11412.96,
          11912.72,
          12412.48,
          12912.24,
          13412.0,
          13911.76,
          14411.52,
          14911.279999999999,
          15411.039999999999,
          15910.8,
          16410.559999999998,
          16910.32,
          17410.079999999998,
          17909.84,
          18409.6,
          18909.36,
          19409.12,
          19908.88,
          20408.64,
          20908.4,
          21408.16,
          21907.92,
          22407.68,
          22907.44,
          23407.2,
          23906.96,
          24406.72,
          24906.48,
          25406.239999999998,
          25906.0
        ],
        "counts": [
          2,
          8,
          8,
          10,
          12,
          8,
          7,
          7,
          5,
          8,
          14,
          8,
          7,
          10,
          8,
          5,
          5,
          1,
          7,
          2,
          10,
          4,
          4,
          3,
          6,
          6,
          1,
          3,
          4,
          1,
          2,
          3,
          3,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0
        ]
      }
    }
  ]
}