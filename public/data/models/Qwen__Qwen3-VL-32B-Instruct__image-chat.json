{
  "model_id": "Qwen/Qwen3-VL-32B-Instruct",
  "task": "image-chat",
  "total_params_billions": 32.0,
  "activated_params_billions": 32.0,
  "architecture": "Dense Transformer",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      3.0,
      84.86,
      166.72,
      248.57999999999998,
      330.44,
      412.3,
      494.15999999999997,
      576.02,
      657.88,
      739.74,
      821.6,
      903.46,
      985.3199999999999,
      1067.18,
      1149.04,
      1230.9,
      1312.76,
      1394.62,
      1476.48,
      1558.34,
      1640.2,
      1722.06,
      1803.92,
      1885.78,
      1967.6399999999999,
      2049.5,
      2131.36,
      2213.22,
      2295.08,
      2376.94,
      2458.8,
      2540.66,
      2622.52,
      2704.38,
      2786.24,
      2868.1,
      2949.96,
      3031.82,
      3113.68,
      3195.54,
      3277.4,
      3359.2599999999998,
      3441.12,
      3522.98,
      3604.84,
      3686.7,
      3768.56,
      3850.42,
      3932.2799999999997,
      4014.14,
      4096.0
    ],
    "counts": [
      425,
      532,
      879,
      1188,
      1132,
      1043,
      980,
      874,
      662,
      600,
      538,
      489,
      371,
      287,
      255,
      269,
      216,
      176,
      181,
      163,
      139,
      118,
      135,
      115,
      113,
      90,
      79,
      61,
      80,
      51,
      72,
      52,
      59,
      30,
      51,
      46,
      33,
      35,
      31,
      29,
      20,
      18,
      18,
      14,
      19,
      9,
      22,
      17,
      20,
      476
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.35143196951424455,
      "energy_per_request_joules": 331.08254842012576,
      "avg_power_watts": 1278.0334700918388,
      "median_itl_ms": 30.139634996885434,
      "p90_itl_ms": 41.82081742291279,
      "p95_itl_ms": 79.97744850290472,
      "p99_itl_ms": 109.76323896087708,
      "output_throughput_tokens_per_sec": 2760.926763025687,
      "avg_batch_size": 127.84234234234235,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          32,
          44,
          69,
          91,
          91,
          69,
          90,
          61,
          45,
          45,
          40,
          32,
          37,
          19,
          22,
          21,
          13,
          14,
          23,
          12,
          8,
          11,
          12,
          14,
          6,
          6,
          3,
          3,
          2,
          5,
          7,
          8,
          3,
          2,
          3,
          1,
          3,
          3,
          2,
          2,
          0,
          2,
          1,
          1,
          1,
          1,
          0,
          1,
          4,
          39
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.0819765109485588,
      "energy_per_request_joules": 1016.5327813014682,
      "avg_power_watts": 1020.0699515367832,
      "median_itl_ms": 16.266300997813232,
      "p90_itl_ms": 16.717714595142752,
      "p95_itl_ms": 17.841420869404423,
      "p99_itl_ms": 57.83402329339878,
      "output_throughput_tokens_per_sec": 885.3958064852818,
      "avg_batch_size": 15.976791120080726,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          30,
          45,
          59,
          94,
          81,
          77,
          85,
          68,
          54,
          53,
          36,
          41,
          18,
          26,
          18,
          19,
          15,
          13,
          17,
          10,
          13,
          10,
          11,
          14,
          11,
          10,
          4,
          4,
          4,
          5,
          6,
          3,
          7,
          5,
          4,
          2,
          5,
          2,
          0,
          0,
          2,
          0,
          2,
          1,
          3,
          1,
          3,
          0,
          2,
          31
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.6784437177975452,
      "energy_per_request_joules": 640.3077603791597,
      "avg_power_watts": 1092.1921292745512,
      "median_itl_ms": 18.336353488848545,
      "p90_itl_ms": 19.3590039450167,
      "p95_itl_ms": 22.854162511066534,
      "p99_itl_ms": 72.44962169643297,
      "output_throughput_tokens_per_sec": 1455.7812438245105,
      "avg_batch_size": 31.947552447552447,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          31,
          45,
          65,
          96,
          78,
          70,
          91,
          66,
          51,
          52,
          37,
          36,
          26,
          27,
          20,
          23,
          12,
          17,
          11,
          14,
          8,
          8,
          8,
          9,
          8,
          6,
          5,
          10,
          7,
          2,
          5,
          4,
          4,
          2,
          2,
          10,
          2,
          3,
          4,
          2,
          2,
          2,
          1,
          0,
          1,
          3,
          3,
          0,
          2,
          33
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.45773588679929567,
      "energy_per_request_joules": 435.5473184897806,
      "avg_power_watts": 1143.4033351777207,
      "median_itl_ms": 22.629524508374743,
      "p90_itl_ms": 26.823773775497216,
      "p95_itl_ms": 53.14142275456105,
      "p99_itl_ms": 86.62330896768253,
      "output_throughput_tokens_per_sec": 2133.714812039983,
      "avg_batch_size": 63.89801699716714,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          32,
          42,
          72,
          88,
          87,
          82,
          75,
          62,
          46,
          44,
          47,
          36,
          36,
          24,
          16,
          19,
          14,
          20,
          14,
          9,
          10,
          8,
          8,
          9,
          5,
          6,
          6,
          8,
          5,
          2,
          10,
          4,
          8,
          3,
          4,
          4,
          1,
          2,
          0,
          2,
          3,
          0,
          2,
          3,
          3,
          2,
          2,
          1,
          2,
          36
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.9253417656758551,
      "energy_per_request_joules": 1796.4153156051584,
      "avg_power_watts": 965.1258969493875,
      "median_itl_ms": 15.593631993397139,
      "p90_itl_ms": 15.92206548084505,
      "p95_itl_ms": 16.024292194924783,
      "p99_itl_ms": 22.027823201206026,
      "output_throughput_tokens_per_sec": 489.8280865591907,
      "avg_batch_size": 7.994136460554371,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          31,
          39,
          72,
          97,
          77,
          83,
          85,
          65,
          53,
          49,
          36,
          38,
          29,
          17,
          21,
          19,
          15,
          13,
          14,
          10,
          14,
          11,
          15,
          8,
          5,
          7,
          4,
          4,
          11,
          4,
          3,
          3,
          6,
          1,
          5,
          3,
          2,
          6,
          2,
          3,
          1,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          37
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.38127864727873784,
      "energy_per_request_joules": 364.112916617757,
      "avg_power_watts": 1211.015829743394,
      "median_itl_ms": 26.47213899763301,
      "p90_itl_ms": 33.18210100987926,
      "p95_itl_ms": 67.46957179275327,
      "p99_itl_ms": 97.21258907578887,
      "output_throughput_tokens_per_sec": 2551.9046017226,
      "avg_batch_size": 95.9090909090909,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          36,
          35,
          69,
          90,
          79,
          89,
          59,
          75,
          51,
          48,
          47,
          36,
          28,
          23,
          20,
          19,
          19,
          15,
          13,
          13,
          13,
          8,
          11,
          6,
          9,
          10,
          4,
          5,
          6,
          2,
          9,
          3,
          2,
          3,
          4,
          3,
          2,
          3,
          5,
          1,
          0,
          2,
          2,
          3,
          1,
          0,
          0,
          2,
          2,
          39
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.3039736660976454,
      "energy_per_request_joules": 285.82815995745915,
      "avg_power_watts": 494.0674554434824,
      "median_itl_ms": 46.02685500867665,
      "p90_itl_ms": 171.5484309158045,
      "p95_itl_ms": 197.95149791803098,
      "p99_itl_ms": 307.2732544349894,
      "output_throughput_tokens_per_sec": 1169.904087705753,
      "avg_batch_size": 127.69252873563218,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          33,
          42,
          63,
          95,
          100,
          72,
          75,
          60,
          45,
          56,
          49,
          37,
          22,
          24,
          13,
          22,
          23,
          12,
          11,
          13,
          9,
          12,
          8,
          10,
          5,
          8,
          10,
          4,
          8,
          3,
          2,
          3,
          2,
          3,
          4,
          5,
          4,
          2,
          4,
          2,
          3,
          1,
          1,
          0,
          1,
          0,
          4,
          1,
          1,
          37
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.1089305049525482,
      "energy_per_request_joules": 1052.0599136756116,
      "avg_power_watts": 453.81672114261124,
      "median_itl_ms": 33.1301020050887,
      "p90_itl_ms": 56.114267796510845,
      "p95_itl_ms": 74.53642699401824,
      "p99_itl_ms": 191.50130887886897,
      "output_throughput_tokens_per_sec": 381.20105377971885,
      "avg_batch_size": 15.94634402945818,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          37,
          44,
          61,
          90,
          86,
          90,
          69,
          69,
          47,
          49,
          36,
          45,
          20,
          22,
          15,
          29,
          22,
          11,
          6,
          5,
          15,
          10,
          8,
          12,
          14,
          7,
          11,
          5,
          3,
          5,
          3,
          4,
          6,
          1,
          5,
          4,
          3,
          1,
          3,
          1,
          2,
          2,
          0,
          0,
          2,
          0,
          0,
          0,
          3,
          41
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.2655381340391102,
      "energy_per_request_joules": 249.39748672850146,
      "avg_power_watts": 536.9409252696726,
      "median_itl_ms": 49.05475600389764,
      "p90_itl_ms": 197.47916582186343,
      "p95_itl_ms": 276.6291006210898,
      "p99_itl_ms": 527.1454999962591,
      "output_throughput_tokens_per_sec": 1768.4048398937484,
      "avg_batch_size": 250.8042328042328,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          62,
          84,
          139,
          190,
          175,
          158,
          142,
          132,
          101,
          76,
          91,
          82,
          68,
          43,
          38,
          39,
          33,
          31,
          29,
          26,
          18,
          16,
          22,
          16,
          25,
          12,
          14,
          10,
          15,
          8,
          8,
          4,
          7,
          6,
          3,
          4,
          3,
          5,
          3,
          10,
          5,
          3,
          1,
          3,
          3,
          0,
          5,
          8,
          1,
          71
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.6636057247465799,
      "energy_per_request_joules": 624.531401334866,
      "avg_power_watts": 496.95639710530776,
      "median_itl_ms": 30.23387599387206,
      "p90_itl_ms": 83.05273210545155,
      "p95_itl_ms": 108.44035920454186,
      "p99_itl_ms": 159.32730629183627,
      "output_throughput_tokens_per_sec": 649.0005589434974,
      "avg_batch_size": 31.887394957983194,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          35,
          37,
          71,
          82,
          92,
          72,
          79,
          73,
          51,
          46,
          46,
          36,
          25,
          15,
          24,
          26,
          19,
          11,
          20,
          19,
          7,
          7,
          8,
          4,
          6,
          7,
          8,
          3,
          6,
          7,
          4,
          5,
          6,
          1,
          4,
          4,
          2,
          3,
          5,
          1,
          1,
          1,
          3,
          1,
          1,
          1,
          1,
          0,
          2,
          36
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.44962406735738364,
      "energy_per_request_joules": 421.52256314754715,
      "avg_power_watts": 488.28703654608444,
      "median_itl_ms": 42.69243701128289,
      "p90_itl_ms": 117.21614279085792,
      "p95_itl_ms": 182.3936978937126,
      "p99_itl_ms": 255.83262700019986,
      "output_throughput_tokens_per_sec": 900.0279622271634,
      "avg_batch_size": 63.7801724137931,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          32,
          38,
          68,
          88,
          91,
          93,
          65,
          77,
          61,
          40,
          33,
          29,
          37,
          23,
          25,
          16,
          11,
          11,
          9,
          18,
          12,
          11,
          17,
          5,
          7,
          7,
          3,
          1,
          10,
          5,
          6,
          3,
          4,
          1,
          5,
          2,
          2,
          1,
          1,
          4,
          1,
          2,
          4,
          1,
          1,
          1,
          1,
          1,
          1,
          39
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 0,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.5158183051415683,
      "energy_per_request_joules": 1421.1255501009423,
      "avg_power_watts": 752.7204611715797,
      "median_itl_ms": 14.732362993527204,
      "p90_itl_ms": 20.12159880832769,
      "p95_itl_ms": 23.313267764751792,
      "p99_itl_ms": 79.94683048862485,
      "output_throughput_tokens_per_sec": 467.22556085795185,
      "avg_batch_size": 7.936046511627907,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          34,
          37,
          71,
          87,
          95,
          88,
          65,
          66,
          57,
          42,
          40,
          41,
          25,
          24,
          23,
          17,
          20,
          8,
          14,
          14,
          12,
          6,
          7,
          8,
          12,
          4,
          7,
          4,
          3,
          3,
          9,
          8,
          4,
          2,
          8,
          4,
          4,
          4,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          2,
          2,
          0,
          37
        ]
      }
    }
  ]
}