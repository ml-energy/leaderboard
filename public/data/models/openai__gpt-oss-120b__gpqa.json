{
  "model_id": "openai/gpt-oss-120b",
  "task": "gpqa",
  "total_params_billions": 117.0,
  "activated_params_billions": 5.0,
  "architecture": "MoE",
  "weight_precision": "mxfp4",
  "output_length_distribution": {
    "bins": [
      90.0,
      743.56,
      1397.12,
      2050.68,
      2704.24,
      3357.7999999999997,
      4011.3599999999997,
      4664.92,
      5318.48,
      5972.039999999999,
      6625.599999999999,
      7279.16,
      7932.719999999999,
      8586.279999999999,
      9239.84,
      9893.4,
      10546.96,
      11200.519999999999,
      11854.079999999998,
      12507.64,
      13161.199999999999,
      13814.759999999998,
      14468.32,
      15121.88,
      15775.439999999999,
      16429.0,
      17082.559999999998,
      17736.12,
      18389.68,
      19043.239999999998,
      19696.8,
      20350.359999999997,
      21003.92,
      21657.48,
      22311.039999999997,
      22964.6,
      23618.159999999996,
      24271.719999999998,
      24925.28,
      25578.839999999997,
      26232.399999999998,
      26885.96,
      27539.519999999997,
      28193.079999999998,
      28846.64,
      29500.199999999997,
      30153.76,
      30807.319999999996,
      31460.879999999997,
      32114.44,
      32768.0
    ],
    "counts": [
      6187,
      11382,
      7282,
      4141,
      2557,
      1416,
      912,
      477,
      232,
      136,
      66,
      28,
      10,
      6,
      1,
      1,
      0,
      2,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      11
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5118758675585872,
      "energy_per_request_joules": 859.9462870351178,
      "avg_output_len": 1679.989898989899,
      "avg_power_watts": 609.8622051217071,
      "median_itl_ms": 13.226334936916828,
      "p90_itl_ms": 13.8166768476367,
      "p95_itl_ms": 14.032936654984951,
      "p99_itl_ms": 18.462037704885013,
      "output_throughput_tokens_per_sec": 1138.052559030488,
      "avg_batch_size": 15.99622641509434,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          38,
          60,
          43,
          31,
          10,
          5,
          4,
          3,
          0,
          3,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3759124523566032,
      "energy_per_request_joules": 660.8237144790817,
      "avg_output_len": 1757.919191919192,
      "avg_power_watts": 655.9374048511457,
      "median_itl_ms": 17.96223595738411,
      "p90_itl_ms": 18.692253343760967,
      "p95_itl_ms": 19.1040492306153,
      "p99_itl_ms": 35.42223773896699,
      "output_throughput_tokens_per_sec": 1564.094860003497,
      "avg_batch_size": 31.98857142857143,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          34,
          63,
          46,
          22,
          15,
          6,
          4,
          4,
          3,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.26757106007777065,
      "energy_per_request_joules": 465.2560728226024,
      "avg_output_len": 1738.8131313131314,
      "avg_power_watts": 688.1701637002966,
      "median_itl_ms": 24.15146678686142,
      "p90_itl_ms": 25.258196517825127,
      "p95_itl_ms": 26.005130261182785,
      "p99_itl_ms": 42.64888353645794,
      "output_throughput_tokens_per_sec": 2060.9974791902346,
      "avg_batch_size": 64.0,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          32,
          59,
          50,
          24,
          13,
          7,
          9,
          0,
          2,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6840787562079539,
      "energy_per_request_joules": 1218.1369682135755,
      "avg_output_len": 1780.6969696969697,
      "avg_power_watts": 549.9648189244016,
      "median_itl_ms": 9.85749065876007,
      "p90_itl_ms": 10.23793164640665,
      "p95_itl_ms": 10.347421746701002,
      "p99_itl_ms": 10.778715033084152,
      "output_throughput_tokens_per_sec": 781.6704139623178,
      "avg_batch_size": 7.992840095465394,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          31,
          63,
          45,
          19,
          19,
          9,
          5,
          5,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.09540020046199459,
      "energy_per_request_joules": 169.35816192856834,
      "avg_output_len": 1775.2390572390573,
      "avg_power_watts": 1138.9522207481266,
      "median_itl_ms": 79.71355800691526,
      "p90_itl_ms": 87.2380607004743,
      "p95_itl_ms": 91.536516979977,
      "p99_itl_ms": 114.61825579055589,
      "output_throughput_tokens_per_sec": 5100.4950896012515,
      "avg_batch_size": 1023.7627118644068,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          208,
          380,
          248,
          143,
          88,
          55,
          31,
          19,
          7,
          3,
          3,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.22263135796809058,
      "energy_per_request_joules": 391.0497314693555,
      "avg_output_len": 1756.489898989899,
      "avg_power_watts": 1208.3604693401549,
      "median_itl_ms": 22.496696561574936,
      "p90_itl_ms": 23.41281995177269,
      "p95_itl_ms": 23.590007796883583,
      "p99_itl_ms": 30.726888962089998,
      "output_throughput_tokens_per_sec": 3632.419970252483,
      "avg_batch_size": 127.96666666666667,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          34,
          67,
          39,
          19,
          19,
          5,
          8,
          3,
          3,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5779632719590391,
      "energy_per_request_joules": 991.4288558979787,
      "avg_output_len": 1715.3838383838383,
      "avg_power_watts": 992.4357622410904,
      "median_itl_ms": 9.206450544297695,
      "p90_itl_ms": 9.507095068693161,
      "p95_itl_ms": 9.606552217155695,
      "p99_itl_ms": 10.510198529809712,
      "output_throughput_tokens_per_sec": 1642.15681715759,
      "avg_batch_size": 15.983783783783784,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          34,
          67,
          43,
          18,
          19,
          6,
          4,
          2,
          2,
          2,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.19604752504783104,
      "energy_per_request_joules": 339.77115382721445,
      "avg_output_len": 1733.1060606060605,
      "avg_power_watts": 1264.511861931454,
      "median_itl_ms": 29.22416350338608,
      "p90_itl_ms": 30.091804104449693,
      "p95_itl_ms": 30.722570798388915,
      "p99_itl_ms": 34.1212665657804,
      "output_throughput_tokens_per_sec": 4525.079789849335,
      "avg_batch_size": 191.87692307692308,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          69,
          127,
          82,
          53,
          21,
          19,
          15,
          3,
          5,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.1505766036416854,
      "energy_per_request_joules": 254.57142236133882,
      "avg_output_len": 1690.6439393939395,
      "avg_power_watts": 1238.1363237302414,
      "median_itl_ms": 30.520553002133965,
      "p90_itl_ms": 31.859954996616576,
      "p95_itl_ms": 32.78333039197605,
      "p99_itl_ms": 38.00529548199845,
      "output_throughput_tokens_per_sec": 5386.746334938468,
      "avg_batch_size": 255.8139534883721,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          72,
          118,
          94,
          56,
          23,
          14,
          14,
          1,
          3,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4168421449297778,
      "energy_per_request_joules": 739.2842808764685,
      "avg_output_len": 1773.5353535353536,
      "avg_power_watts": 1086.5274011846657,
      "median_itl_ms": 12.075122445821762,
      "p90_itl_ms": 12.440547347068787,
      "p95_itl_ms": 12.622483540326357,
      "p99_itl_ms": 21.764685586094853,
      "output_throughput_tokens_per_sec": 2386.058456337645,
      "avg_batch_size": 31.99145299145299,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          38,
          60,
          36,
          25,
          15,
          10,
          8,
          5,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.13547640806695457,
      "energy_per_request_joules": 234.53566288665868,
      "avg_output_len": 1731.1919191919192,
      "avg_power_watts": 1258.8980713979674,
      "median_itl_ms": 40.18088299926603,
      "p90_itl_ms": 42.15094749815762,
      "p95_itl_ms": 43.16567475325428,
      "p99_itl_ms": 45.19459044677207,
      "output_throughput_tokens_per_sec": 6336.107976750837,
      "avg_batch_size": 383.9056603773585,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          111,
          185,
          119,
          73,
          48,
          28,
          18,
          6,
          1,
          3,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.11474400457038335,
      "energy_per_request_joules": 200.53267832077648,
      "avg_output_len": 1747.6527777777778,
      "avg_power_watts": 1163.858988838859,
      "median_itl_ms": 48.84157798369415,
      "p90_itl_ms": 51.67187621118501,
      "p95_itl_ms": 53.012487810337916,
      "p99_itl_ms": 60.52728712093086,
      "output_throughput_tokens_per_sec": 4376.796622165065,
      "avg_batch_size": 511.72058823529414,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          131,
          271,
          154,
          103,
          57,
          33,
          17,
          15,
          6,
          2,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2979923785007381,
      "energy_per_request_joules": 500.85595770715975,
      "avg_output_len": 1680.7676767676767,
      "avg_power_watts": 1164.007045700212,
      "median_itl_ms": 16.037579625844955,
      "p90_itl_ms": 16.466877050697803,
      "p95_itl_ms": 16.68805722147226,
      "p99_itl_ms": 25.734602697193623,
      "output_throughput_tokens_per_sec": 3249.6954281426697,
      "avg_batch_size": 63.92537313432836,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          33,
          68,
          40,
          23,
          15,
          8,
          6,
          4,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.10304731168896487,
      "energy_per_request_joules": 177.10918409911557,
      "avg_output_len": 1718.7171717171718,
      "avg_power_watts": 1169.4075889437233,
      "median_itl_ms": 65.03442699613515,
      "p90_itl_ms": 69.38796988979448,
      "p95_itl_ms": 71.45622423995519,
      "p99_itl_ms": 96.55798725638303,
      "output_throughput_tokens_per_sec": 7698.13360347091,
      "avg_batch_size": 767.75,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          179,
          322,
          200,
          121,
          73,
          40,
          22,
          19,
          6,
          5,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.7819241402752495,
      "energy_per_request_joules": 1376.3286549099437,
      "avg_output_len": 1760.1818181818182,
      "avg_power_watts": 864.1739530037215,
      "median_itl_ms": 7.176676765084267,
      "p90_itl_ms": 7.405425980687141,
      "p95_itl_ms": 7.466542534530163,
      "p99_itl_ms": 7.698871921747921,
      "output_throughput_tokens_per_sec": 1040.2404279649768,
      "avg_batch_size": 7.996644295302014,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          33,
          59,
          52,
          18,
          15,
          9,
          5,
          0,
          4,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.24997276391736417,
      "energy_per_request_joules": 451.8964701482083,
      "avg_output_len": 1807.7828282828282,
      "avg_power_watts": 1212.7099843565145,
      "median_itl_ms": 19.24681104719639,
      "p90_itl_ms": 19.789204001426697,
      "p95_itl_ms": 20.003909431397915,
      "p99_itl_ms": 27.672958895564076,
      "output_throughput_tokens_per_sec": 1614.127329065653,
      "avg_batch_size": 95.93023255813954,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          37,
          61,
          47,
          25,
          12,
          5,
          7,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.08807920440292867,
      "energy_per_request_joules": 151.16576156145595,
      "avg_output_len": 1716.2480359147025,
      "avg_power_watts": 973.2574856315339,
      "median_itl_ms": 126.29272416234016,
      "p90_itl_ms": 142.54298806190496,
      "p95_itl_ms": 152.40283245220778,
      "p99_itl_ms": 196.24773861840376,
      "output_throughput_tokens_per_sec": 7688.455701973553,
      "avg_batch_size": 1535.6063829787233,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          307,
          608,
          357,
          198,
          137,
          62,
          57,
          32,
          9,
          8,
          4,
          2,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.08603986209171981,
      "energy_per_request_joules": 148.07166948273303,
      "avg_output_len": 1720.965909090909,
      "avg_power_watts": 925.9872288388464,
      "median_itl_ms": 122.57824651896954,
      "p90_itl_ms": 174.04294423758984,
      "p95_itl_ms": 190.80506693571806,
      "p99_itl_ms": 271.0348512977364,
      "output_throughput_tokens_per_sec": 6613.830638884705,
      "avg_batch_size": 1915.4583333333333,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          421,
          790,
          474,
          275,
          175,
          104,
          63,
          44,
          13,
          7,
          2,
          7,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.48589007854707056,
      "energy_per_request_joules": 848.6438320368941,
      "avg_output_len": 1746.5757575757575,
      "avg_power_watts": 659.8314270319853,
      "median_itl_ms": 5.45397300447803,
      "p90_itl_ms": 7.809739495860412,
      "p95_itl_ms": 10.606128258223157,
      "p99_itl_ms": 15.62396485416682,
      "output_throughput_tokens_per_sec": 1327.665768682751,
      "avg_batch_size": 7.991869918699187,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          35,
          60,
          38,
          32,
          17,
          6,
          2,
          3,
          3,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.05527369879417791,
      "energy_per_request_joules": 101.28340004840888,
      "avg_output_len": 1832.3977272727273,
      "avg_power_watts": 893.2711214812631,
      "median_itl_ms": 30.294244992546737,
      "p90_itl_ms": 39.1099724045489,
      "p95_itl_ms": 41.19197288819123,
      "p99_itl_ms": 46.34756007755641,
      "output_throughput_tokens_per_sec": 8764.548873110123,
      "avg_batch_size": 511.8181818181818,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          125,
          254,
          159,
          110,
          55,
          31,
          22,
          12,
          8,
          10,
          2,
          2,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.04384929406737634,
      "energy_per_request_joules": 78.97161895065982,
      "avg_output_len": 1800.9781144781145,
      "avg_power_watts": 779.0159052431786,
      "median_itl_ms": 47.406072000740096,
      "p90_itl_ms": 74.54672059975564,
      "p95_itl_ms": 91.96001079981212,
      "p99_itl_ms": 114.10652056219992,
      "output_throughput_tokens_per_sec": 7284.536862045076,
      "avg_batch_size": 1023.5641025641025,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          210,
          367,
          242,
          149,
          97,
          49,
          28,
          18,
          9,
          11,
          3,
          1,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.11640061102748535,
      "energy_per_request_joules": 211.29297581733644,
      "avg_output_len": 1815.2222222222222,
      "avg_power_watts": 855.147302556861,
      "median_itl_ms": 16.48175199807156,
      "p90_itl_ms": 24.28926430293359,
      "p95_itl_ms": 27.64103554654866,
      "p99_itl_ms": 34.404707649373435,
      "output_throughput_tokens_per_sec": 3152.0661039565425,
      "avg_batch_size": 127.92647058823529,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          64,
          133,
          82,
          41,
          31,
          24,
          9,
          8,
          0,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.331038216179351,
      "energy_per_request_joules": 594.504510413729,
      "avg_output_len": 1795.878787878788,
      "avg_power_watts": 699.6688036032991,
      "median_itl_ms": 6.901834000018425,
      "p90_itl_ms": 12.178540087188598,
      "p95_itl_ms": 13.999344779585952,
      "p99_itl_ms": 19.26879448117685,
      "output_throughput_tokens_per_sec": 2010.2920473222252,
      "avg_batch_size": 15.974358974358974,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          29,
          73,
          37,
          17,
          18,
          7,
          8,
          7,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.042068700052336,
      "energy_per_request_joules": 76.08211162305982,
      "avg_output_len": 1808.5206228956229,
      "avg_power_watts": 713.4358023979836,
      "median_itl_ms": 130.05510000220966,
      "p90_itl_ms": 181.18592360115147,
      "p95_itl_ms": 191.36647525156147,
      "p99_itl_ms": 218.87476456176947,
      "output_throughput_tokens_per_sec": 7809.391278419233,
      "avg_batch_size": 2047.3855421686746,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          413,
          721,
          491,
          287,
          194,
          101,
          81,
          37,
          30,
          10,
          6,
          2,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.0396667643642537,
      "energy_per_request_joules": 71.14999922002823,
      "avg_output_len": 1793.6930415263748,
      "avg_power_watts": 673.5046499567148,
      "median_itl_ms": 175.4405300016515,
      "p90_itl_ms": 210.95160601544194,
      "p95_itl_ms": 225.76437098905444,
      "p99_itl_ms": 319.45279978972377,
      "output_throughput_tokens_per_sec": 6543.693795892051,
      "avg_batch_size": 2885.2268907563025,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          596,
          1124,
          766,
          414,
          276,
          164,
          113,
          43,
          25,
          22,
          9,
          4,
          2,
          2,
          0,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.258165017860706,
      "energy_per_request_joules": 458.5115026304264,
      "avg_output_len": 1776.040404040404,
      "avg_power_watts": 717.9210601086755,
      "median_itl_ms": 10.07053600915242,
      "p90_itl_ms": 17.513591202441606,
      "p95_itl_ms": 20.429867868369914,
      "p99_itl_ms": 26.98967366071887,
      "output_throughput_tokens_per_sec": 2362.8178516975754,
      "avg_batch_size": 31.99074074074074,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          31,
          68,
          39,
          26,
          12,
          8,
          6,
          2,
          4,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.18062173709145077,
      "energy_per_request_joules": 314.0181877814504,
      "avg_output_len": 1738.540404040404,
      "avg_power_watts": 762.2634694014198,
      "median_itl_ms": 13.951387998531573,
      "p90_itl_ms": 22.22058200277388,
      "p95_itl_ms": 25.4594292564434,
      "p99_itl_ms": 32.2278789491975,
      "output_throughput_tokens_per_sec": 3171.3401107313657,
      "avg_batch_size": 64.0,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          32,
          59,
          46,
          25,
          15,
          12,
          4,
          4,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.08008394787392092,
      "energy_per_request_joules": 149.05712431983224,
      "avg_output_len": 1861.2609427609427,
      "avg_power_watts": 952.0882696308249,
      "median_itl_ms": 20.717412000522017,
      "p90_itl_ms": 25.696520385099575,
      "p95_itl_ms": 27.278679786832072,
      "p99_itl_ms": 31.382965607917868,
      "output_throughput_tokens_per_sec": 5018.360570726602,
      "avg_batch_size": 255.83870967741936,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          94,
          182,
          134,
          64,
          56,
          22,
          18,
          11,
          6,
          4,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.43141800838899413,
      "energy_per_request_joules": 706.148482337234,
      "avg_output_len": 1636.8080808080808,
      "avg_power_watts": 1207.9932870816103,
      "median_itl_ms": 5.63221650372725,
      "p90_itl_ms": 5.898638404323719,
      "p95_itl_ms": 6.022722747002263,
      "p99_itl_ms": 7.582832919433715,
      "output_throughput_tokens_per_sec": 2664.115875853775,
      "avg_batch_size": 15.981481481481481,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          36,
          65,
          48,
          24,
          9,
          6,
          4,
          3,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.06570325234324967,
      "energy_per_request_joules": 108.47488054469393,
      "avg_output_len": 1650.9819023569023,
      "avg_power_watts": 1472.5107613760902,
      "median_itl_ms": 88.74269849911798,
      "p90_itl_ms": 155.07174840313382,
      "p95_itl_ms": 176.24314289423634,
      "p99_itl_ms": 229.7573606693185,
      "output_throughput_tokens_per_sec": 9334.489462103811,
      "avg_batch_size": 2047.27868852459,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          438,
          792,
          514,
          268,
          180,
          92,
          43,
          26,
          14,
          6,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.06084576786611849,
      "energy_per_request_joules": 99.88134975383628,
      "avg_output_len": 1641.5496632996633,
      "avg_power_watts": 1327.4665650816123,
      "median_itl_ms": 158.94596549333073,
      "p90_itl_ms": 217.16104648658074,
      "p95_itl_ms": 261.172524507856,
      "p99_itl_ms": 430.8699949106085,
      "output_throughput_tokens_per_sec": 10850.962083404595,
      "avg_batch_size": 3071.1685393258426,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          657,
          1190,
          747,
          442,
          236,
          137,
          86,
          31,
          21,
          6,
          8,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.30024083297792514,
      "energy_per_request_joules": 497.9539705974188,
      "avg_output_len": 1658.5151515151515,
      "avg_power_watts": 1355.6628027133322,
      "median_itl_ms": 6.954117503482848,
      "p90_itl_ms": 7.299648894695566,
      "p95_itl_ms": 7.457647251430899,
      "p99_itl_ms": 13.230332161183485,
      "output_throughput_tokens_per_sec": 3928.871669243254,
      "avg_batch_size": 31.921875,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          35,
          68,
          41,
          23,
          10,
          10,
          6,
          2,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.06082515167539012,
      "energy_per_request_joules": 99.41804481833107,
      "avg_output_len": 1634.4890572390573,
      "avg_power_watts": 1301.8971482487527,
      "median_itl_ms": 208.13817699672654,
      "p90_itl_ms": 291.7018283129438,
      "p95_itl_ms": 378.0616642499807,
      "p99_itl_ms": 633.2739127724216,
      "output_throughput_tokens_per_sec": 10552.670898858378,
      "avg_batch_size": 4095.0243902439024,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          887,
          1609,
          984,
          550,
          325,
          195,
          107,
          50,
          24,
          10,
          10,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.20634999001322119,
      "energy_per_request_joules": 321.8872253306239,
      "avg_output_len": 1559.909090909091,
      "avg_power_watts": 1462.743173222873,
      "median_itl_ms": 8.798983006272465,
      "p90_itl_ms": 9.287583603872918,
      "p95_itl_ms": 9.778764459770171,
      "p99_itl_ms": 16.495890735241122,
      "output_throughput_tokens_per_sec": 5589.325957876669,
      "avg_batch_size": 63.91428571428571,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          38,
          70,
          37,
          28,
          16,
          2,
          3,
          3,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6277227456303269,
      "energy_per_request_joules": 982.7316614532481,
      "avg_output_len": 1565.550505050505,
      "avg_power_watts": 1067.9081734775832,
      "median_itl_ms": 4.657438985304907,
      "p90_itl_ms": 4.903670208295807,
      "p95_itl_ms": 5.0160094047896555,
      "p99_itl_ms": 5.42817416368052,
      "output_throughput_tokens_per_sec": 1656.0207832005522,
      "avg_batch_size": 8.0,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          39,
          66,
          46,
          19,
          14,
          9,
          3,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.07189915713799827,
      "energy_per_request_joules": 117.38979535944479,
      "avg_output_len": 1632.7005772005773,
      "avg_power_watts": 1512.14937374798,
      "median_itl_ms": 40.83580899168737,
      "p90_itl_ms": 65.67976798978636,
      "p95_itl_ms": 75.68022679188287,
      "p99_itl_ms": 85.90234324452462,
      "output_throughput_tokens_per_sec": 14227.19316284115,
      "avg_batch_size": 1023.6326530612245,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          254,
          468,
          293,
          163,
          100,
          53,
          28,
          17,
          4,
          5,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.14774330548433176,
      "energy_per_request_joules": 260.03008309820024,
      "avg_output_len": 1760.0126262626263,
      "avg_power_watts": 1517.7596917099556,
      "median_itl_ms": 12.117908016080037,
      "p90_itl_ms": 13.056740420870485,
      "p95_itl_ms": 14.86866000341251,
      "p99_itl_ms": 18.686776203103364,
      "output_throughput_tokens_per_sec": 3931.7904735241655,
      "avg_batch_size": 127.93877551020408,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          75,
          133,
          71,
          50,
          28,
          10,
          17,
          8,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.10590367705490719,
      "energy_per_request_joules": 177.555715877408,
      "avg_output_len": 1676.577441077441,
      "avg_power_watts": 1658.658721130682,
      "median_itl_ms": 15.680338983656839,
      "p90_itl_ms": 19.89219079259783,
      "p95_itl_ms": 21.525613620178767,
      "p99_itl_ms": 25.227223421679767,
      "output_throughput_tokens_per_sec": 11082.785272559733,
      "avg_batch_size": 255.8409090909091,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          110,
          192,
          131,
          75,
          28,
          27,
          15,
          10,
          2,
          3,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.08160209861766116,
      "energy_per_request_joules": 136.5259777997511,
      "avg_output_len": 1673.0694444444443,
      "avg_power_watts": 1642.7936294692759,
      "median_itl_ms": 24.378373025683686,
      "p90_itl_ms": 30.872450990136716,
      "p95_itl_ms": 32.35608909744769,
      "p99_itl_ms": 38.31311052374076,
      "output_throughput_tokens_per_sec": 12786.649833876525,
      "avg_batch_size": 511.8787878787879,
      "output_length_distribution": {
        "bins": [
          90.0,
          743.56,
          1397.12,
          2050.68,
          2704.24,
          3357.7999999999997,
          4011.3599999999997,
          4664.92,
          5318.48,
          5972.039999999999,
          6625.599999999999,
          7279.16,
          7932.719999999999,
          8586.279999999999,
          9239.84,
          9893.4,
          10546.96,
          11200.519999999999,
          11854.079999999998,
          12507.64,
          13161.199999999999,
          13814.759999999998,
          14468.32,
          15121.88,
          15775.439999999999,
          16429.0,
          17082.559999999998,
          17736.12,
          18389.68,
          19043.239999999998,
          19696.8,
          20350.359999999997,
          21003.92,
          21657.48,
          22311.039999999997,
          22964.6,
          23618.159999999996,
          24271.719999999998,
          24925.28,
          25578.839999999997,
          26232.399999999998,
          26885.96,
          27539.519999999997,
          28193.079999999998,
          28846.64,
          29500.199999999997,
          30153.76,
          30807.319999999996,
          31460.879999999997,
          32114.44,
          32768.0
        ],
        "counts": [
          147,
          260,
          167,
          88,
          66,
          26,
          12,
          12,
          10,
          2,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    }
  ]
}