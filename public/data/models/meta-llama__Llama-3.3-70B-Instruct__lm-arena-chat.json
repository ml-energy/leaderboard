{
  "model_id": "meta-llama/Llama-3.3-70B-Instruct",
  "task": "lm-arena-chat",
  "total_params_billions": 70.0,
  "activated_params_billions": 70.0,
  "architecture": "Dense Transformer",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      2.0,
      83.88,
      165.76,
      247.64,
      329.52,
      411.4,
      493.28,
      575.16,
      657.04,
      738.92,
      820.8,
      902.68,
      984.56,
      1066.44,
      1148.32,
      1230.1999999999998,
      1312.08,
      1393.96,
      1475.84,
      1557.7199999999998,
      1639.6,
      1721.48,
      1803.36,
      1885.2399999999998,
      1967.12,
      2049.0,
      2130.88,
      2212.7599999999998,
      2294.64,
      2376.52,
      2458.3999999999996,
      2540.2799999999997,
      2622.16,
      2704.04,
      2785.92,
      2867.7999999999997,
      2949.68,
      3031.56,
      3113.4399999999996,
      3195.3199999999997,
      3277.2,
      3359.08,
      3440.96,
      3522.8399999999997,
      3604.72,
      3686.6,
      3768.4799999999996,
      3850.3599999999997,
      3932.24,
      4014.12,
      4096.0
    ],
    "counts": [
      5410,
      2328,
      1841,
      1797,
      1825,
      1846,
      1964,
      1701,
      1280,
      995,
      685,
      461,
      292,
      270,
      183,
      141,
      103,
      82,
      65,
      48,
      28,
      28,
      15,
      21,
      8,
      13,
      8,
      7,
      8,
      5,
      7,
      4,
      7,
      9,
      5,
      3,
      3,
      3,
      0,
      4,
      2,
      2,
      1,
      0,
      1,
      1,
      1,
      1,
      0,
      40
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6036206575024905,
      "energy_per_request_joules": 248.33036375914227,
      "avg_output_len": 411.4013671875,
      "avg_power_watts": 2351.335081311273,
      "median_itl_ms": 27.75922231376171,
      "p90_itl_ms": 32.05261752009392,
      "p95_itl_ms": 54.11705840379,
      "p99_itl_ms": 123.06474521756172,
      "output_throughput_tokens_per_sec": 2620.177775110049,
      "avg_batch_size": 127.7127659574468,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          236,
          100,
          79,
          80,
          86,
          78,
          85,
          64,
          55,
          50,
          26,
          20,
          11,
          11,
          8,
          9,
          3,
          8,
          2,
          4,
          1,
          2,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.1016443053811678,
      "energy_per_request_joules": 861.2021161923748,
      "avg_output_len": 409.775390625,
      "avg_power_watts": 1838.807782685267,
      "median_itl_ms": 17.56241451948881,
      "p90_itl_ms": 17.893794924020767,
      "p95_itl_ms": 18.158955965191126,
      "p99_itl_ms": 28.45144355669618,
      "output_throughput_tokens_per_sec": 858.7946424306577,
      "avg_batch_size": 15.970212765957447,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          232,
          109,
          71,
          86,
          77,
          78,
          102,
          68,
          48,
          49,
          25,
          20,
          11,
          10,
          12,
          8,
          3,
          2,
          1,
          2,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5400161867812329,
      "energy_per_request_joules": 219.46648076861783,
      "avg_output_len": 406.4072265625,
      "avg_power_watts": 2461.337558890742,
      "median_itl_ms": 33.60642120242119,
      "p90_itl_ms": 48.582508787512985,
      "p95_itl_ms": 75.1825701445341,
      "p99_itl_ms": 171.24340519309044,
      "output_throughput_tokens_per_sec": 2874.1057218929323,
      "avg_batch_size": 191.53424657534248,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          237,
          108,
          79,
          74,
          80,
          78,
          72,
          84,
          55,
          48,
          34,
          15,
          13,
          17,
          5,
          6,
          4,
          2,
          3,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4910870247635751,
      "energy_per_request_joules": 202.9719263454225,
      "avg_output_len": 413.3115234375,
      "avg_power_watts": 2519.352730636792,
      "median_itl_ms": 39.05790485441685,
      "p90_itl_ms": 59.90947894752055,
      "p95_itl_ms": 85.33287849277252,
      "p99_itl_ms": 181.4057970046997,
      "output_throughput_tokens_per_sec": 3186.3541109041967,
      "avg_batch_size": 255.4516129032258,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          237,
          102,
          84,
          71,
          77,
          80,
          89,
          63,
          58,
          45,
          40,
          18,
          14,
          11,
          8,
          3,
          4,
          7,
          2,
          3,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.2490713279290644,
      "energy_per_request_joules": 515.7798529031772,
      "avg_output_len": 412.9306640625,
      "avg_power_watts": 1895.6477994442098,
      "median_itl_ms": 19.864235073328018,
      "p90_itl_ms": 20.36301977932453,
      "p95_itl_ms": 21.960968896746593,
      "p99_itl_ms": 51.30415171384808,
      "output_throughput_tokens_per_sec": 1464.1930980885606,
      "avg_batch_size": 31.911439114391143,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          238,
          101,
          79,
          82,
          78,
          62,
          83,
          73,
          68,
          45,
          21,
          26,
          15,
          17,
          6,
          7,
          5,
          3,
          4,
          1,
          2,
          2,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4437462324400039,
      "energy_per_request_joules": 181.17673323083628,
      "avg_output_len": 408.2890625,
      "avg_power_watts": 2510.6066406517143,
      "median_itl_ms": 53.8472905755043,
      "p90_itl_ms": 81.16421084851027,
      "p95_itl_ms": 104.58444682881232,
      "p99_itl_ms": 268.8867459446191,
      "output_throughput_tokens_per_sec": 2974.754274160048,
      "avg_batch_size": 382.9166666666667,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          232,
          108,
          79,
          79,
          76,
          80,
          87,
          72,
          54,
          48,
          22,
          19,
          19,
          12,
          4,
          6,
          6,
          6,
          2,
          4,
          0,
          2,
          3,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.42511732904780986,
      "energy_per_request_joules": 175.83417338370057,
      "avg_output_len": 413.61328125,
      "avg_power_watts": 2490.545119063151,
      "median_itl_ms": 73.5875191166997,
      "p90_itl_ms": 104.21592239290477,
      "p95_itl_ms": 134.7207486629486,
      "p99_itl_ms": 277.25199323147484,
      "output_throughput_tokens_per_sec": 4155.448700329297,
      "avg_batch_size": 510.8,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          470,
          195,
          168,
          144,
          172,
          170,
          188,
          118,
          119,
          85,
          56,
          35,
          26,
          15,
          23,
          12,
          8,
          10,
          8,
          2,
          2,
          5,
          1,
          2,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8223267233123469,
      "energy_per_request_joules": 336.2015351773509,
      "avg_output_len": 408.841796875,
      "avg_power_watts": 2108.3171636085754,
      "median_itl_ms": 22.33504317700863,
      "p90_itl_ms": 23.909232392907143,
      "p95_itl_ms": 29.054128192365162,
      "p99_itl_ms": 84.97802283614882,
      "output_throughput_tokens_per_sec": 2381.845484597419,
      "avg_batch_size": 63.857142857142854,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          237,
          98,
          84,
          86,
          78,
          69,
          85,
          78,
          57,
          33,
          35,
          22,
          8,
          14,
          11,
          7,
          8,
          2,
          1,
          2,
          2,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.42309416473966643,
      "energy_per_request_joules": 174.91534994349365,
      "avg_output_len": 413.41943359375,
      "avg_power_watts": 2546.049766678004,
      "median_itl_ms": 97.54406102001667,
      "p90_itl_ms": 149.4576372206211,
      "p95_itl_ms": 193.7341911718247,
      "p99_itl_ms": 570.3238400816917,
      "output_throughput_tokens_per_sec": 4092.437563559187,
      "avg_batch_size": 724.2444444444444,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          464,
          207,
          157,
          152,
          164,
          168,
          153,
          162,
          109,
          92,
          55,
          40,
          24,
          28,
          11,
          14,
          9,
          7,
          9,
          3,
          0,
          2,
          1,
          1,
          0,
          4,
          1,
          0,
          1,
          0,
          0,
          1,
          2,
          2,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.8469267248117465,
      "energy_per_request_joules": 1572.7957049116321,
      "avg_output_len": 408.8447265625,
      "avg_power_watts": 1787.3856485130575,
      "median_itl_ms": 16.86663366854191,
      "p90_itl_ms": 17.01442338526249,
      "p95_itl_ms": 17.139077931642532,
      "p99_itl_ms": 20.57395108044147,
      "output_throughput_tokens_per_sec": 461.7619994037026,
      "avg_batch_size": 7.976430976430977,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          237,
          100,
          84,
          69,
          79,
          84,
          81,
          77,
          61,
          48,
          29,
          17,
          14,
          10,
          8,
          4,
          2,
          3,
          4,
          1,
          3,
          1,
          0,
          2,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6707632297133818,
      "energy_per_request_joules": 281.94130570658655,
      "avg_output_len": 420.3291015625,
      "avg_power_watts": 2223.797428056266,
      "median_itl_ms": 25.379663333296776,
      "p90_itl_ms": 27.717379480600354,
      "p95_itl_ms": 39.72181230783462,
      "p99_itl_ms": 100.1505321264267,
      "output_throughput_tokens_per_sec": 2736.5639341977685,
      "avg_batch_size": 95.86324786324786,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          237,
          105,
          68,
          76,
          83,
          91,
          73,
          76,
          54,
          45,
          38,
          21,
          8,
          11,
          7,
          5,
          4,
          2,
          3,
          2,
          1,
          1,
          1,
          1,
          2,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          4
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2185859542835205,
      "energy_per_request_joules": 89.32705003728988,
      "avg_output_len": 408.65869140625,
      "avg_power_watts": 1935.3379848233947,
      "median_itl_ms": 105.5690009961836,
      "p90_itl_ms": 123.76886698184535,
      "p95_itl_ms": 138.31367259263013,
      "p99_itl_ms": 514.3569973506965,
      "output_throughput_tokens_per_sec": 4954.729085862884,
      "avg_batch_size": 1021.5576923076923,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          469,
          201,
          153,
          170,
          158,
          168,
          162,
          158,
          106,
          70,
          68,
          44,
          30,
          24,
          16,
          12,
          2,
          10,
          5,
          3,
          3,
          2,
          1,
          2,
          0,
          1,
          0,
          1,
          1,
          2,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          4
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.48108686802094386,
      "energy_per_request_joules": 197.12534417158176,
      "avg_output_len": 409.75,
      "avg_power_watts": 1911.5402435916485,
      "median_itl_ms": 27.55990250443574,
      "p90_itl_ms": 33.62744760524947,
      "p95_itl_ms": 50.744753259641584,
      "p99_itl_ms": 107.72431701538142,
      "output_throughput_tokens_per_sec": 2619.690224009693,
      "avg_batch_size": 127.72527472527473,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          234,
          109,
          72,
          75,
          79,
          81,
          95,
          77,
          46,
          44,
          31,
          16,
          15,
          13,
          10,
          5,
          8,
          0,
          5,
          0,
          2,
          1,
          0,
          0,
          0,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.9214979320441667,
      "energy_per_request_joules": 779.4169809995365,
      "avg_output_len": 405.6298828125,
      "avg_power_watts": 1745.5327379190146,
      "median_itl_ms": 16.940318018896505,
      "p90_itl_ms": 17.743828997481614,
      "p95_itl_ms": 18.33818800514564,
      "p99_itl_ms": 28.917519008973606,
      "output_throughput_tokens_per_sec": 888.269249394289,
      "avg_batch_size": 15.964285714285714,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          231,
          106,
          91,
          78,
          74,
          80,
          80,
          77,
          48,
          41,
          35,
          26,
          11,
          13,
          5,
          9,
          5,
          1,
          1,
          2,
          1,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.35214391557233893,
      "energy_per_request_joules": 144.4835481095945,
      "avg_output_len": 410.296875,
      "avg_power_watts": 1942.152033355922,
      "median_itl_ms": 36.69821401126683,
      "p90_itl_ms": 56.227579014375834,
      "p95_itl_ms": 78.17061689711406,
      "p99_itl_ms": 170.2859676859225,
      "output_throughput_tokens_per_sec": 3256.7165069548123,
      "avg_batch_size": 255.51724137931035,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          238,
          97,
          78,
          71,
          88,
          73,
          94,
          79,
          49,
          50,
          32,
          22,
          8,
          6,
          8,
          5,
          7,
          2,
          3,
          1,
          3,
          2,
          0,
          3,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.09837607324156,
      "energy_per_request_joules": 446.7558867279323,
      "avg_output_len": 406.7421875,
      "avg_power_watts": 1757.6593043836017,
      "median_itl_ms": 18.645607007783838,
      "p90_itl_ms": 20.242558198515326,
      "p95_itl_ms": 23.322992264002092,
      "p99_itl_ms": 46.5622446453199,
      "output_throughput_tokens_per_sec": 1519.758607548423,
      "avg_batch_size": 31.916334661354583,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          239,
          95,
          87,
          83,
          73,
          73,
          83,
          78,
          60,
          43,
          26,
          26,
          7,
          10,
          12,
          7,
          7,
          2,
          1,
          5,
          0,
          0,
          2,
          1,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2726696708352643,
      "energy_per_request_joules": 112.8012327090528,
      "avg_output_len": 413.69189453125,
      "avg_power_watts": 1930.1302457264087,
      "median_itl_ms": 63.53210502129514,
      "p90_itl_ms": 83.94049727648962,
      "p95_itl_ms": 104.08187189023009,
      "p99_itl_ms": 183.94360792590302,
      "output_throughput_tokens_per_sec": 4613.0055722234965,
      "avg_batch_size": 510.625,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          470,
          192,
          170,
          149,
          164,
          158,
          174,
          154,
          121,
          82,
          50,
          38,
          28,
          31,
          11,
          10,
          10,
          6,
          5,
          4,
          3,
          2,
          0,
          3,
          0,
          1,
          0,
          0,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          4
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6835897220173396,
      "energy_per_request_joules": 283.8446104335905,
      "avg_output_len": 415.2265625,
      "avg_power_watts": 1815.1244370249738,
      "median_itl_ms": 21.814916501170956,
      "p90_itl_ms": 24.840720393694934,
      "p95_itl_ms": 31.674871589348182,
      "p99_itl_ms": 69.46604490774922,
      "output_throughput_tokens_per_sec": 2382.751795799994,
      "avg_batch_size": 63.847682119205295,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          238,
          92,
          74,
          93,
          70,
          86,
          95,
          72,
          58,
          34,
          25,
          20,
          19,
          10,
          7,
          4,
          3,
          4,
          3,
          4,
          2,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.61682729251943,
      "energy_per_request_joules": 1487.2153646902502,
      "avg_output_len": 411.193359375,
      "avg_power_watts": 1701.4827217894435,
      "median_itl_ms": 16.615877000731416,
      "p90_itl_ms": 17.130404198542237,
      "p95_itl_ms": 17.365419460111298,
      "p99_itl_ms": 21.898801030183677,
      "output_throughput_tokens_per_sec": 464.0140587769295,
      "avg_batch_size": 7.984090909090909,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          234,
          103,
          84,
          79,
          69,
          89,
          83,
          71,
          54,
          43,
          37,
          16,
          11,
          7,
          11,
          8,
          5,
          5,
          3,
          4,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    }
  ]
}