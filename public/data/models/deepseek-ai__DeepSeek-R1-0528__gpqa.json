{
  "model_id": "deepseek-ai/DeepSeek-R1-0528",
  "task": "gpqa",
  "total_params_billions": 671.0,
  "activated_params_billions": 37.0,
  "architecture": "MoE",
  "weight_precision": "fp8",
  "output_length_distribution": {
    "bins": [
      674.0,
      1315.88,
      1957.76,
      2599.64,
      3241.52,
      3883.4,
      4525.28,
      5167.16,
      5809.04,
      6450.92,
      7092.8,
      7734.68,
      8376.56,
      9018.44,
      9660.32,
      10302.2,
      10944.08,
      11585.96,
      12227.84,
      12869.72,
      13511.6,
      14153.48,
      14795.36,
      15437.24,
      16079.119999999999,
      16721.0,
      17362.88,
      18004.76,
      18646.64,
      19288.52,
      19930.4,
      20572.28,
      21214.16,
      21856.04,
      22497.92,
      23139.8,
      23781.68,
      24423.56,
      25065.44,
      25707.32,
      26349.2,
      26991.079999999998,
      27632.96,
      28274.84,
      28916.72,
      29558.6,
      30200.48,
      30842.36,
      31484.239999999998,
      32126.12,
      32768.0
    ],
    "counts": [
      33,
      31,
      16,
      19,
      27,
      17,
      28,
      23,
      30,
      21,
      34,
      34,
      50,
      35,
      40,
      33,
      45,
      29,
      37,
      46,
      34,
      39,
      40,
      31,
      29,
      20,
      28,
      22,
      16,
      15,
      18,
      15,
      9,
      7,
      6,
      9,
      7,
      5,
      5,
      1,
      0,
      3,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      2
    ]
  },
  "configurations": [
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 2.3761518703101916,
      "energy_per_request_joules": 26819.638160958155,
      "avg_power_watts": 7126.160762314122,
      "median_itl_ms": 44.80024399526883,
      "p90_itl_ms": 55.71015099849319,
      "p95_itl_ms": 57.22191849781666,
      "p99_itl_ms": 70.27125449895033,
      "output_throughput_tokens_per_sec": 1855.8661317485244,
      "avg_batch_size": 127.98820754716981,
      "output_length_distribution": {
        "bins": [
          674.0,
          1315.88,
          1957.76,
          2599.64,
          3241.52,
          3883.4,
          4525.28,
          5167.16,
          5809.04,
          6450.92,
          7092.8,
          7734.68,
          8376.56,
          9018.44,
          9660.32,
          10302.2,
          10944.08,
          11585.96,
          12227.84,
          12869.72,
          13511.6,
          14153.48,
          14795.36,
          15437.24,
          16079.119999999999,
          16721.0,
          17362.88,
          18004.76,
          18646.64,
          19288.52,
          19930.4,
          20572.28,
          21214.16,
          21856.04,
          22497.92,
          23139.8,
          23781.68,
          24423.56,
          25065.44,
          25707.32,
          26349.2,
          26991.079999999998,
          27632.96,
          28274.84,
          28916.72,
          29558.6,
          30200.48,
          30842.36,
          31484.239999999998,
          32126.12,
          32768.0
        ],
        "counts": [
          8,
          4,
          5,
          1,
          8,
          1,
          6,
          6,
          5,
          3,
          14,
          4,
          13,
          7,
          10,
          5,
          8,
          6,
          6,
          5,
          6,
          5,
          8,
          8,
          6,
          3,
          9,
          5,
          2,
          5,
          4,
          3,
          2,
          3,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 7.121823518199807,
      "energy_per_request_joules": 81506.39266134499,
      "avg_power_watts": 4911.310683149415,
      "median_itl_ms": 23.074202499628882,
      "p90_itl_ms": 24.405937698247726,
      "p95_itl_ms": 24.694001998250315,
      "p99_itl_ms": 25.37768642858282,
      "output_throughput_tokens_per_sec": 658.6502395696727,
      "avg_batch_size": 15.998377676833226,
      "output_length_distribution": {
        "bins": [
          674.0,
          1315.88,
          1957.76,
          2599.64,
          3241.52,
          3883.4,
          4525.28,
          5167.16,
          5809.04,
          6450.92,
          7092.8,
          7734.68,
          8376.56,
          9018.44,
          9660.32,
          10302.2,
          10944.08,
          11585.96,
          12227.84,
          12869.72,
          13511.6,
          14153.48,
          14795.36,
          15437.24,
          16079.119999999999,
          16721.0,
          17362.88,
          18004.76,
          18646.64,
          19288.52,
          19930.4,
          20572.28,
          21214.16,
          21856.04,
          22497.92,
          23139.8,
          23781.68,
          24423.56,
          25065.44,
          25707.32,
          26349.2,
          26991.079999999998,
          27632.96,
          28274.84,
          28916.72,
          29558.6,
          30200.48,
          30842.36,
          31484.239999999998,
          32126.12,
          32768.0
        ],
        "counts": [
          7,
          5,
          3,
          5,
          4,
          4,
          5,
          6,
          5,
          2,
          7,
          8,
          7,
          7,
          10,
          10,
          12,
          5,
          7,
          10,
          5,
          11,
          6,
          5,
          10,
          3,
          6,
          0,
          5,
          2,
          0,
          2,
          0,
          3,
          3,
          2,
          1,
          3,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 5.325354212945934,
      "energy_per_request_joules": 59106.24088812866,
      "avg_power_watts": 5398.11355380596,
      "median_itl_ms": 31.792588000826072,
      "p90_itl_ms": 33.83861699694535,
      "p95_itl_ms": 34.92035549788852,
      "p99_itl_ms": 36.30347400103346,
      "output_throughput_tokens_per_sec": 929.9000266372047,
      "avg_batch_size": 31.99740529320187,
      "output_length_distribution": {
        "bins": [
          674.0,
          1315.88,
          1957.76,
          2599.64,
          3241.52,
          3883.4,
          4525.28,
          5167.16,
          5809.04,
          6450.92,
          7092.8,
          7734.68,
          8376.56,
          9018.44,
          9660.32,
          10302.2,
          10944.08,
          11585.96,
          12227.84,
          12869.72,
          13511.6,
          14153.48,
          14795.36,
          15437.24,
          16079.119999999999,
          16721.0,
          17362.88,
          18004.76,
          18646.64,
          19288.52,
          19930.4,
          20572.28,
          21214.16,
          21856.04,
          22497.92,
          23139.8,
          23781.68,
          24423.56,
          25065.44,
          25707.32,
          26349.2,
          26991.079999999998,
          27632.96,
          28274.84,
          28916.72,
          29558.6,
          30200.48,
          30842.36,
          31484.239999999998,
          32126.12,
          32768.0
        ],
        "counts": [
          6,
          7,
          4,
          7,
          3,
          5,
          4,
          4,
          4,
          6,
          3,
          5,
          12,
          8,
          10,
          6,
          9,
          7,
          8,
          14,
          8,
          8,
          9,
          6,
          3,
          4,
          6,
          4,
          3,
          4,
          3,
          3,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 3.8585186465566834,
      "energy_per_request_joules": 44599.83753683223,
      "avg_power_watts": 6156.141760730251,
      "median_itl_ms": 40.92244700223091,
      "p90_itl_ms": 46.50866350129945,
      "p95_itl_ms": 47.99175275002199,
      "p99_itl_ms": 49.16423429895076,
      "output_throughput_tokens_per_sec": 1318.587007841042,
      "avg_batch_size": 63.99813953488372,
      "output_length_distribution": {
        "bins": [
          674.0,
          1315.88,
          1957.76,
          2599.64,
          3241.52,
          3883.4,
          4525.28,
          5167.16,
          5809.04,
          6450.92,
          7092.8,
          7734.68,
          8376.56,
          9018.44,
          9660.32,
          10302.2,
          10944.08,
          11585.96,
          12227.84,
          12869.72,
          13511.6,
          14153.48,
          14795.36,
          15437.24,
          16079.119999999999,
          16721.0,
          17362.88,
          18004.76,
          18646.64,
          19288.52,
          19930.4,
          20572.28,
          21214.16,
          21856.04,
          22497.92,
          23139.8,
          23781.68,
          24423.56,
          25065.44,
          25707.32,
          26349.2,
          26991.079999999998,
          27632.96,
          28274.84,
          28916.72,
          29558.6,
          30200.48,
          30842.36,
          31484.239999999998,
          32126.12,
          32768.0
        ],
        "counts": [
          5,
          8,
          2,
          4,
          4,
          5,
          8,
          6,
          11,
          2,
          3,
          12,
          8,
          5,
          5,
          6,
          6,
          4,
          9,
          9,
          8,
          9,
          6,
          6,
          4,
          4,
          3,
          7,
          4,
          1,
          8,
          2,
          3,
          1,
          2,
          3,
          0,
          1,
          2,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 9.873897137623922,
      "energy_per_request_joules": 117113.0472451733,
      "avg_power_watts": 4277.775202157113,
      "median_itl_ms": 18.35748300072737,
      "p90_itl_ms": 19.096106800134294,
      "p95_itl_ms": 19.433520199527266,
      "p99_itl_ms": 20.211977198632663,
      "output_throughput_tokens_per_sec": 427.1691672970253,
      "avg_batch_size": 7.998855180309102,
      "output_length_distribution": {
        "bins": [
          674.0,
          1315.88,
          1957.76,
          2599.64,
          3241.52,
          3883.4,
          4525.28,
          5167.16,
          5809.04,
          6450.92,
          7092.8,
          7734.68,
          8376.56,
          9018.44,
          9660.32,
          10302.2,
          10944.08,
          11585.96,
          12227.84,
          12869.72,
          13511.6,
          14153.48,
          14795.36,
          15437.24,
          16079.119999999999,
          16721.0,
          17362.88,
          18004.76,
          18646.64,
          19288.52,
          19930.4,
          20572.28,
          21214.16,
          21856.04,
          22497.92,
          23139.8,
          23781.68,
          24423.56,
          25065.44,
          25707.32,
          26349.2,
          26991.079999999998,
          27632.96,
          28274.84,
          28916.72,
          29558.6,
          30200.48,
          30842.36,
          31484.239999999998,
          32126.12,
          32768.0
        ],
        "counts": [
          7,
          7,
          2,
          2,
          8,
          2,
          5,
          1,
          5,
          8,
          7,
          5,
          10,
          8,
          5,
          6,
          10,
          7,
          7,
          8,
          7,
          6,
          11,
          6,
          6,
          6,
          4,
          6,
          2,
          3,
          3,
          5,
          3,
          0,
          0,
          3,
          4,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    }
  ]
}