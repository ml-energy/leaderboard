{
  "model_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
  "task": "image-chat",
  "total_params_billions": 235.0,
  "activated_params_billions": 22.0,
  "architecture": "MoE",
  "weight_precision": "fp8",
  "output_length_distribution": {
    "bins": [
      3.0,
      84.86,
      166.72,
      248.57999999999998,
      330.44,
      412.3,
      494.15999999999997,
      576.02,
      657.88,
      739.74,
      821.6,
      903.46,
      985.3199999999999,
      1067.18,
      1149.04,
      1230.9,
      1312.76,
      1394.62,
      1476.48,
      1558.34,
      1640.2,
      1722.06,
      1803.92,
      1885.78,
      1967.6399999999999,
      2049.5,
      2131.36,
      2213.22,
      2295.08,
      2376.94,
      2458.8,
      2540.66,
      2622.52,
      2704.38,
      2786.24,
      2868.1,
      2949.96,
      3031.82,
      3113.68,
      3195.54,
      3277.4,
      3359.2599999999998,
      3441.12,
      3522.98,
      3604.84,
      3686.7,
      3768.56,
      3850.42,
      3932.2799999999997,
      4014.14,
      4096.0
    ],
    "counts": [
      1924,
      1907,
      2641,
      4050,
      3932,
      3699,
      3595,
      2977,
      2365,
      2022,
      1877,
      1450,
      1246,
      1026,
      965,
      838,
      730,
      643,
      595,
      573,
      520,
      416,
      434,
      415,
      377,
      375,
      300,
      274,
      244,
      203,
      210,
      228,
      217,
      194,
      176,
      156,
      136,
      116,
      112,
      88,
      89,
      66,
      71,
      59,
      60,
      59,
      60,
      72,
      49,
      1249
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 5.361291941472724,
      "energy_per_request_joules": 4998.881171757156,
      "avg_power_watts": 2212.203636670805,
      "median_itl_ms": 37.1500002220273,
      "p90_itl_ms": 38.16250171512365,
      "p95_itl_ms": 38.738379348069415,
      "p99_itl_ms": 131.69068951159713,
      "output_throughput_tokens_per_sec": 397.9442731104029,
      "avg_batch_size": 15.985333333333333,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          43,
          53,
          88,
          96,
          84,
          81,
          63,
          53,
          39,
          38,
          37,
          31,
          16,
          18,
          18,
          23,
          15,
          13,
          8,
          12,
          9,
          9,
          8,
          14,
          10,
          6,
          6,
          5,
          8,
          4,
          5,
          4,
          3,
          5,
          2,
          6,
          1,
          1,
          2,
          3,
          1,
          2,
          1,
          0,
          2,
          1,
          2,
          0,
          32
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 3.0783652690352787,
      "energy_per_request_joules": 2797.638798768626,
      "avg_power_watts": 2202.60783164473,
      "median_itl_ms": 41.73819161951542,
      "p90_itl_ms": 43.30527223646641,
      "p95_itl_ms": 47.579519264400005,
      "p99_itl_ms": 135.2543289586902,
      "output_throughput_tokens_per_sec": 659.5175176429509,
      "avg_batch_size": 31.973983739837397,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          40,
          46,
          61,
          88,
          79,
          91,
          79,
          54,
          52,
          46,
          54,
          32,
          21,
          23,
          26,
          20,
          20,
          20,
          12,
          10,
          11,
          9,
          10,
          5,
          11,
          10,
          10,
          11,
          5,
          3,
          4,
          2,
          3,
          2,
          3,
          1,
          5,
          2,
          3,
          0,
          1,
          3,
          2,
          2,
          3,
          2,
          1,
          2,
          1,
          23
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 10.081913788887013,
      "energy_per_request_joules": 9305.862413235009,
      "avg_power_watts": 2363.214069839988,
      "median_itl_ms": 33.2266440091189,
      "p90_itl_ms": 34.26524801761843,
      "p95_itl_ms": 34.40390300238505,
      "p99_itl_ms": 39.68359341379253,
      "output_throughput_tokens_per_sec": 231.09896852945903,
      "avg_batch_size": 7.9929257200606365,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          40,
          48,
          61,
          86,
          84,
          78,
          82,
          64,
          50,
          53,
          39,
          34,
          34,
          18,
          19,
          22,
          18,
          17,
          15,
          8,
          9,
          5,
          9,
          9,
          11,
          12,
          7,
          7,
          4,
          3,
          3,
          3,
          11,
          0,
          3,
          6,
          3,
          5,
          1,
          1,
          2,
          3,
          2,
          0,
          2,
          2,
          2,
          0,
          1,
          28
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.9329863119168873,
      "energy_per_request_joules": 1749.4979637945657,
      "avg_power_watts": 2226.399452511597,
      "median_itl_ms": 47.49224241822958,
      "p90_itl_ms": 52.70032750872465,
      "p95_itl_ms": 96.83710243552923,
      "p99_itl_ms": 145.87322231382132,
      "output_throughput_tokens_per_sec": 999.3534355311757,
      "avg_batch_size": 60.85402455661664,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          43,
          52,
          88,
          90,
          85,
          78,
          69,
          60,
          38,
          54,
          32,
          23,
          29,
          20,
          16,
          18,
          11,
          13,
          6,
          18,
          7,
          8,
          9,
          10,
          7,
          7,
          7,
          6,
          5,
          5,
          4,
          2,
          4,
          5,
          5,
          3,
          2,
          1,
          1,
          2,
          2,
          0,
          2,
          0,
          3,
          1,
          1,
          1,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.516540744911418,
      "energy_per_request_joules": 1395.7358342059256,
      "avg_power_watts": 3480.2284564350794,
      "median_itl_ms": 42.62426681816578,
      "p90_itl_ms": 72.11171160452068,
      "p95_itl_ms": 152.61421473696828,
      "p99_itl_ms": 158.6471839807928,
      "output_throughput_tokens_per_sec": 1846.9870736348946,
      "avg_batch_size": 127.84571428571428,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          39,
          45,
          60,
          82,
          93,
          83,
          76,
          71,
          59,
          36,
          40,
          32,
          38,
          16,
          26,
          18,
          13,
          17,
          15,
          6,
          10,
          12,
          7,
          12,
          8,
          9,
          7,
          9,
          3,
          5,
          2,
          6,
          6,
          5,
          4,
          3,
          5,
          1,
          2,
          0,
          3,
          3,
          3,
          2,
          1,
          2,
          3,
          1,
          1,
          24
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 6.978268126402804,
      "energy_per_request_joules": 6404.891638493352,
      "avg_power_watts": 3964.0284004536393,
      "median_itl_ms": 25.919047999195755,
      "p90_itl_ms": 26.280071184737608,
      "p95_itl_ms": 27.4373285849263,
      "p99_itl_ms": 142.30308621306904,
      "output_throughput_tokens_per_sec": 548.6382507264792,
      "avg_batch_size": 15.985552763819095,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          42,
          45,
          49,
          103,
          86,
          77,
          89,
          62,
          33,
          56,
          48,
          32,
          28,
          18,
          27,
          20,
          16,
          10,
          17,
          20,
          10,
          6,
          9,
          9,
          6,
          5,
          8,
          2,
          7,
          4,
          6,
          5,
          6,
          3,
          1,
          4,
          4,
          4,
          4,
          1,
          5,
          2,
          1,
          1,
          1,
          2,
          0,
          3,
          0,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.2289192537576366,
      "energy_per_request_joules": 1130.6957221914317,
      "avg_power_watts": 3545.390231394801,
      "median_itl_ms": 50.02221651375294,
      "p90_itl_ms": 146.31957560777664,
      "p95_itl_ms": 158.24205242097378,
      "p99_itl_ms": 166.92388020455837,
      "output_throughput_tokens_per_sec": 2165.308739616604,
      "avg_batch_size": 191.81274900398407,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          46,
          51,
          87,
          89,
          89,
          81,
          72,
          50,
          42,
          37,
          32,
          25,
          19,
          20,
          25,
          11,
          19,
          20,
          13,
          10,
          6,
          12,
          8,
          4,
          9,
          11,
          4,
          7,
          3,
          6,
          6,
          5,
          2,
          4,
          6,
          2,
          1,
          2,
          0,
          2,
          2,
          2,
          3,
          5,
          2,
          2,
          3,
          1,
          22
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.0900983277168166,
      "energy_per_request_joules": 1001.9887883709789,
      "avg_power_watts": 3609.760585676512,
      "median_itl_ms": 55.1033690571785,
      "p90_itl_ms": 157.21938852220774,
      "p95_itl_ms": 163.49651301279664,
      "p99_itl_ms": 177.74222860112783,
      "output_throughput_tokens_per_sec": 2406.5046417035937,
      "avg_batch_size": 255.25130890052355,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          40,
          49,
          56,
          95,
          76,
          81,
          91,
          71,
          44,
          37,
          53,
          30,
          30,
          15,
          22,
          25,
          20,
          12,
          9,
          10,
          9,
          9,
          9,
          11,
          9,
          10,
          8,
          9,
          6,
          6,
          3,
          3,
          8,
          1,
          1,
          3,
          6,
          3,
          3,
          0,
          2,
          2,
          1,
          2,
          0,
          1,
          0,
          1,
          2,
          30
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 4.08783840222643,
      "energy_per_request_joules": 3844.8914593722343,
      "avg_power_watts": 3986.043493665406,
      "median_itl_ms": 28.96841049368959,
      "p90_itl_ms": 30.5063020932721,
      "p95_itl_ms": 34.317532788038314,
      "p99_itl_ms": 143.4579001032398,
      "output_throughput_tokens_per_sec": 912.4527922152045,
      "avg_batch_size": 31.964630225080384,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          42,
          39,
          59,
          86,
          95,
          70,
          87,
          66,
          59,
          39,
          40,
          30,
          26,
          25,
          21,
          21,
          18,
          16,
          14,
          11,
          15,
          8,
          12,
          5,
          7,
          9,
          6,
          5,
          5,
          5,
          5,
          5,
          1,
          5,
          5,
          4,
          2,
          4,
          8,
          0,
          1,
          0,
          1,
          2,
          0,
          1,
          4,
          0,
          1,
          34
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.8567941242776116,
      "energy_per_request_joules": 803.232777528093,
      "avg_power_watts": 3644.439014177174,
      "median_itl_ms": 58.677997440099716,
      "p90_itl_ms": 160.82807388156652,
      "p95_itl_ms": 168.71721325442192,
      "p99_itl_ms": 224.98375266790381,
      "output_throughput_tokens_per_sec": 2705.554035791767,
      "avg_batch_size": 383.4695652173913,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          40,
          60,
          88,
          85,
          89,
          81,
          54,
          50,
          49,
          40,
          40,
          28,
          18,
          21,
          24,
          19,
          14,
          11,
          11,
          14,
          4,
          10,
          3,
          10,
          8,
          7,
          4,
          8,
          7,
          5,
          6,
          5,
          5,
          5,
          5,
          3,
          3,
          0,
          2,
          2,
          0,
          4,
          3,
          1,
          0,
          4,
          1,
          0,
          30
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.48196908646473957,
      "energy_per_request_joules": 436.73082789396614,
      "avg_power_watts": 3648.13622468253,
      "median_itl_ms": 53.4059964120388,
      "p90_itl_ms": 97.44621962308885,
      "p95_itl_ms": 179.00135554373264,
      "p99_itl_ms": 303.56877967715263,
      "output_throughput_tokens_per_sec": 2791.6698378613455,
      "avg_batch_size": 511.46153846153845,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          39,
          45,
          56,
          89,
          85,
          98,
          72,
          69,
          58,
          51,
          36,
          30,
          32,
          23,
          23,
          12,
          13,
          7,
          16,
          18,
          17,
          11,
          6,
          12,
          10,
          5,
          5,
          6,
          1,
          3,
          3,
          6,
          2,
          6,
          6,
          2,
          3,
          3,
          4,
          3,
          1,
          2,
          1,
          1,
          0,
          2,
          2,
          1,
          0,
          28
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 2.2990191353317746,
      "energy_per_request_joules": 2121.900366204505,
      "avg_power_watts": 3439.0068586986677,
      "median_itl_ms": 35.368237644433975,
      "p90_itl_ms": 41.44383650273085,
      "p95_itl_ms": 143.72925283387303,
      "p99_itl_ms": 153.15585708245635,
      "output_throughput_tokens_per_sec": 1309.1792917666169,
      "avg_batch_size": 63.92566371681416,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          45,
          40,
          60,
          91,
          68,
          87,
          93,
          68,
          43,
          41,
          38,
          43,
          41,
          23,
          20,
          16,
          14,
          17,
          7,
          12,
          6,
          13,
          10,
          8,
          9,
          5,
          7,
          5,
          8,
          7,
          9,
          8,
          4,
          3,
          1,
          2,
          1,
          4,
          2,
          2,
          1,
          3,
          3,
          2,
          2,
          1,
          2,
          2,
          2,
          25
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 12.42517833780704,
      "energy_per_request_joules": 11378.806019485955,
      "avg_power_watts": 4037.5076656236174,
      "median_itl_ms": 23.588323005242273,
      "p90_itl_ms": 23.83061550790444,
      "p95_itl_ms": 23.932546755531803,
      "p99_itl_ms": 29.932429257314652,
      "output_throughput_tokens_per_sec": 318.9088949949793,
      "avg_batch_size": 7.994695898161245,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          45,
          52,
          97,
          89,
          79,
          71,
          63,
          51,
          50,
          49,
          29,
          28,
          24,
          16,
          16,
          20,
          20,
          15,
          24,
          6,
          9,
          7,
          15,
          8,
          4,
          6,
          9,
          6,
          2,
          5,
          5,
          5,
          5,
          2,
          2,
          3,
          0,
          2,
          0,
          3,
          0,
          3,
          0,
          1,
          2,
          2,
          3,
          1,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.7818674847661364,
      "energy_per_request_joules": 1619.9246161433234,
      "avg_power_watts": 3449.575065431318,
      "median_itl_ms": 39.21047691255808,
      "p90_itl_ms": 55.315070756478235,
      "p95_itl_ms": 146.49962587282062,
      "p99_itl_ms": 154.7284028492868,
      "output_throughput_tokens_per_sec": 1620.7930988288037,
      "avg_batch_size": 95.91190476190476,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          41,
          58,
          85,
          100,
          85,
          71,
          72,
          53,
          49,
          29,
          26,
          32,
          17,
          27,
          18,
          22,
          14,
          14,
          12,
          9,
          8,
          19,
          8,
          10,
          7,
          6,
          10,
          5,
          6,
          5,
          3,
          4,
          1,
          6,
          6,
          3,
          3,
          1,
          3,
          0,
          0,
          1,
          0,
          0,
          2,
          1,
          4,
          2,
          23
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.1385063161325453,
      "energy_per_request_joules": 1058.5684966820593,
      "avg_power_watts": 2762.331751111958,
      "median_itl_ms": 37.42286299529951,
      "p90_itl_ms": 142.3698814905947,
      "p95_itl_ms": 157.26155174343148,
      "p99_itl_ms": 177.2529069363372,
      "output_throughput_tokens_per_sec": 1998.1471690044639,
      "avg_batch_size": 127.85285285285285,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          44,
          61,
          90,
          98,
          75,
          75,
          65,
          49,
          45,
          45,
          32,
          22,
          36,
          20,
          18,
          11,
          15,
          10,
          10,
          12,
          12,
          14,
          14,
          8,
          9,
          3,
          3,
          1,
          3,
          7,
          4,
          3,
          3,
          4,
          3,
          2,
          3,
          1,
          5,
          4,
          1,
          1,
          1,
          2,
          1,
          0,
          4,
          1,
          33
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 5.431774134828368,
      "energy_per_request_joules": 4947.158036236649,
      "avg_power_watts": 2949.30104393696,
      "median_itl_ms": 27.266580000286922,
      "p90_itl_ms": 27.729119989089668,
      "p95_itl_ms": 28.083234479709063,
      "p99_itl_ms": 149.1699473859626,
      "output_throughput_tokens_per_sec": 528.7381882102092,
      "avg_batch_size": 15.983253588516746,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          43,
          58,
          89,
          85,
          90,
          82,
          58,
          69,
          37,
          37,
          37,
          21,
          27,
          27,
          21,
          14,
          9,
          11,
          13,
          13,
          7,
          8,
          5,
          9,
          10,
          7,
          9,
          7,
          3,
          5,
          8,
          4,
          3,
          6,
          6,
          5,
          0,
          3,
          0,
          3,
          1,
          1,
          1,
          2,
          2,
          0,
          1,
          2,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.8835661977881729,
      "energy_per_request_joules": 807.0842245073643,
      "avg_power_watts": 2668.5488976730885,
      "median_itl_ms": 42.7578709932277,
      "p90_itl_ms": 157.74796539044476,
      "p95_itl_ms": 166.01086678856518,
      "p99_itl_ms": 179.7327079603565,
      "output_throughput_tokens_per_sec": 2402.8790036355167,
      "avg_batch_size": 191.76706827309238,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          48,
          35,
          61,
          101,
          82,
          73,
          87,
          63,
          55,
          44,
          47,
          29,
          26,
          20,
          13,
          29,
          17,
          13,
          14,
          20,
          8,
          12,
          13,
          6,
          7,
          6,
          5,
          6,
          2,
          5,
          3,
          6,
          5,
          5,
          4,
          4,
          1,
          3,
          3,
          2,
          2,
          1,
          1,
          0,
          2,
          0,
          1,
          2,
          4,
          28
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 3.12133061381664,
      "energy_per_request_joules": 2899.774055549782,
      "avg_power_watts": 3029.7111216030894,
      "median_itl_ms": 28.61866500461474,
      "p90_itl_ms": 29.437012283597145,
      "p95_itl_ms": 32.419078261591494,
      "p99_itl_ms": 165.3744545954396,
      "output_throughput_tokens_per_sec": 901.8016331729496,
      "avg_batch_size": 31.964401294498384,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          38,
          58,
          93,
          87,
          82,
          73,
          63,
          64,
          51,
          48,
          25,
          22,
          19,
          19,
          23,
          14,
          15,
          16,
          13,
          14,
          6,
          8,
          12,
          13,
          9,
          3,
          4,
          7,
          3,
          6,
          3,
          5,
          4,
          5,
          1,
          3,
          2,
          3,
          0,
          2,
          0,
          2,
          4,
          0,
          2,
          1,
          3,
          1,
          31
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.5804466603404967,
      "energy_per_request_joules": 532.0224442276374,
      "avg_power_watts": 2681.428690712584,
      "median_itl_ms": 51.08402599580586,
      "p90_itl_ms": 157.95656121335924,
      "p95_itl_ms": 162.8703500085976,
      "p99_itl_ms": 183.61759079271,
      "output_throughput_tokens_per_sec": 3181.7180891585012,
      "avg_batch_size": 383.4878048780488,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          45,
          39,
          64,
          91,
          78,
          83,
          86,
          69,
          52,
          42,
          43,
          25,
          28,
          19,
          20,
          24,
          23,
          20,
          6,
          15,
          9,
          8,
          11,
          9,
          14,
          7,
          4,
          4,
          2,
          4,
          3,
          11,
          4,
          5,
          3,
          2,
          4,
          5,
          4,
          1,
          1,
          1,
          1,
          0,
          3,
          1,
          2,
          2,
          1,
          26
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.8703528444800777,
      "energy_per_request_joules": 1713.1664918528643,
      "avg_power_watts": 2878.4556719831503,
      "median_itl_ms": 32.84370149776805,
      "p90_itl_ms": 37.08334251132328,
      "p95_itl_ms": 147.15252452151617,
      "p99_itl_ms": 170.2822776933317,
      "output_throughput_tokens_per_sec": 1369.202293574897,
      "avg_batch_size": 63.91531531531532,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          46,
          55,
          95,
          91,
          90,
          57,
          79,
          44,
          54,
          39,
          29,
          30,
          21,
          12,
          13,
          15,
          23,
          17,
          11,
          17,
          8,
          9,
          16,
          7,
          9,
          10,
          5,
          5,
          3,
          2,
          3,
          7,
          5,
          2,
          4,
          3,
          3,
          2,
          6,
          3,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          0,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 9.709842420901362,
      "energy_per_request_joules": 8987.81512486666,
      "avg_power_watts": 2903.988650713749,
      "median_itl_ms": 25.865551986498758,
      "p90_itl_ms": 26.278491783887148,
      "p95_itl_ms": 26.427289107232355,
      "p99_itl_ms": 32.38997953361831,
      "output_throughput_tokens_per_sec": 294.151843455017,
      "avg_batch_size": 7.991997439180538,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          47,
          35,
          65,
          91,
          88,
          73,
          86,
          51,
          50,
          48,
          33,
          40,
          31,
          22,
          22,
          20,
          16,
          18,
          15,
          14,
          9,
          9,
          13,
          12,
          5,
          10,
          8,
          6,
          7,
          4,
          7,
          2,
          2,
          7,
          5,
          4,
          6,
          3,
          3,
          1,
          1,
          4,
          1,
          1,
          0,
          2,
          1,
          2,
          1,
          23
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.3757002982006254,
      "energy_per_request_joules": 1265.3728959654381,
      "avg_power_watts": 2823.1009216037037,
      "median_itl_ms": 35.343625000678,
      "p90_itl_ms": 42.992464898270576,
      "p95_itl_ms": 149.71589140186552,
      "p99_itl_ms": 158.0951226624893,
      "output_throughput_tokens_per_sec": 1749.095564126632,
      "avg_batch_size": 95.89646464646465,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          40,
          45,
          61,
          88,
          96,
          81,
          77,
          67,
          54,
          48,
          39,
          31,
          27,
          19,
          16,
          24,
          19,
          11,
          17,
          13,
          11,
          5,
          11,
          7,
          6,
          11,
          7,
          2,
          3,
          4,
          1,
          8,
          8,
          4,
          7,
          4,
          5,
          1,
          2,
          3,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          4,
          30
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.6739794352285546,
      "energy_per_request_joules": 621.7835454317479,
      "avg_power_watts": 2947.579975801328,
      "median_itl_ms": 45.945856982143596,
      "p90_itl_ms": 75.03020999138243,
      "p95_itl_ms": 154.28496199456276,
      "p99_itl_ms": 169.897924317047,
      "output_throughput_tokens_per_sec": 3632.7886358090295,
      "avg_batch_size": 255.74864864864864,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          89,
          83,
          119,
          173,
          182,
          168,
          151,
          145,
          109,
          88,
          72,
          58,
          52,
          52,
          50,
          27,
          32,
          39,
          24,
          28,
          21,
          15,
          18,
          22,
          12,
          10,
          14,
          17,
          6,
          9,
          15,
          10,
          8,
          9,
          9,
          4,
          7,
          9,
          4,
          5,
          1,
          3,
          3,
          1,
          3,
          3,
          4,
          4,
          0,
          61
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.5051435245223389,
      "energy_per_request_joules": 468.3654748162835,
      "avg_power_watts": 2570.52858328408,
      "median_itl_ms": 58.53327197837643,
      "p90_itl_ms": 177.04453327460214,
      "p95_itl_ms": 187.55832169554196,
      "p99_itl_ms": 214.49589497351647,
      "output_throughput_tokens_per_sec": 4203.932148336411,
      "avg_batch_size": 511.4375,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          88,
          84,
          111,
          177,
          188,
          169,
          143,
          128,
          106,
          90,
          90,
          53,
          62,
          45,
          52,
          33,
          28,
          25,
          28,
          18,
          24,
          24,
          11,
          19,
          18,
          23,
          12,
          16,
          16,
          7,
          10,
          16,
          15,
          8,
          8,
          9,
          5,
          4,
          6,
          3,
          3,
          3,
          0,
          2,
          4,
          4,
          2,
          4,
          2,
          52
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.4196753544832558,
      "energy_per_request_joules": 390.9485969608376,
      "avg_power_watts": 2254.9937345051994,
      "median_itl_ms": 184.00014750659466,
      "p90_itl_ms": 231.9906999007799,
      "p95_itl_ms": 248.69464874791444,
      "p99_itl_ms": 316.3154187117469,
      "output_throughput_tokens_per_sec": 4675.889328386187,
      "avg_batch_size": 1022.9409523809524,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          165,
          177,
          238,
          370,
          314,
          324,
          310,
          277,
          212,
          182,
          162,
          134,
          105,
          95,
          81,
          83,
          67,
          55,
          64,
          50,
          47,
          36,
          41,
          31,
          30,
          26,
          28,
          26,
          19,
          27,
          22,
          21,
          22,
          19,
          13,
          16,
          10,
          7,
          13,
          8,
          9,
          6,
          6,
          7,
          4,
          1,
          3,
          2,
          5,
          126
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.36085144226807253,
      "energy_per_request_joules": 331.07225628354684,
      "avg_power_watts": 2386.1732018707626,
      "median_itl_ms": 269.74317702115513,
      "p90_itl_ms": 359.82781240018085,
      "p95_itl_ms": 438.7185664410935,
      "p99_itl_ms": 889.0299589326523,
      "output_throughput_tokens_per_sec": 5602.820364074763,
      "avg_batch_size": 1889.631704410012,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          349,
          314,
          487,
          707,
          726,
          640,
          640,
          536,
          432,
          340,
          324,
          278,
          229,
          194,
          178,
          139,
          122,
          104,
          94,
          107,
          100,
          79,
          74,
          77,
          58,
          73,
          60,
          44,
          51,
          35,
          33,
          45,
          37,
          40,
          30,
          16,
          16,
          18,
          16,
          22,
          14,
          16,
          17,
          9,
          9,
          6,
          11,
          11,
          9,
          226
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 4.803888939901894,
      "energy_per_request_joules": 4362.526952250614,
      "avg_power_watts": 1801.824747293195,
      "median_itl_ms": 40.48846900695935,
      "p90_itl_ms": 41.85686380369589,
      "p95_itl_ms": 46.39439826369106,
      "p99_itl_ms": 144.68876982689835,
      "output_throughput_tokens_per_sec": 357.95539069878373,
      "avg_batch_size": 15.982271000422118,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          43,
          59,
          80,
          96,
          95,
          80,
          59,
          57,
          49,
          37,
          31,
          24,
          18,
          24,
          21,
          15,
          13,
          19,
          15,
          6,
          11,
          10,
          3,
          10,
          6,
          5,
          4,
          9,
          3,
          3,
          5,
          4,
          10,
          5,
          0,
          3,
          3,
          4,
          1,
          2,
          1,
          3,
          4,
          1,
          0,
          0,
          2,
          0,
          27
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 2.689980644895184,
      "energy_per_request_joules": 2449.4821897967477,
      "avg_power_watts": 1814.6034297441763,
      "median_itl_ms": 43.31289301626384,
      "p90_itl_ms": 45.95667341491208,
      "p95_itl_ms": 75.99624953952363,
      "p99_itl_ms": 146.22084551723677,
      "output_throughput_tokens_per_sec": 608.2823607008485,
      "avg_batch_size": 31.972178060413356,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          43,
          42,
          60,
          97,
          89,
          73,
          100,
          61,
          45,
          40,
          43,
          32,
          27,
          30,
          19,
          18,
          13,
          10,
          13,
          11,
          12,
          9,
          12,
          10,
          5,
          9,
          5,
          4,
          8,
          3,
          6,
          5,
          6,
          2,
          4,
          6,
          6,
          4,
          1,
          4,
          2,
          0,
          1,
          0,
          1,
          4,
          3,
          3,
          1,
          22
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 1.5120302538041,
      "energy_per_request_joules": 1411.2055958058074,
      "avg_power_watts": 1809.5805092317958,
      "median_itl_ms": 47.72696498548612,
      "p90_itl_ms": 55.85271940799436,
      "p95_itl_ms": 136.06376760290004,
      "p99_itl_ms": 153.46030232612975,
      "output_throughput_tokens_per_sec": 1024.3206507367827,
      "avg_batch_size": 63.93707250341997,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          44,
          47,
          59,
          89,
          74,
          84,
          82,
          67,
          51,
          55,
          48,
          27,
          24,
          27,
          21,
          14,
          18,
          11,
          12,
          11,
          11,
          13,
          6,
          9,
          5,
          11,
          6,
          6,
          2,
          3,
          5,
          3,
          5,
          9,
          3,
          5,
          3,
          4,
          1,
          2,
          3,
          0,
          3,
          1,
          2,
          1,
          0,
          1,
          1,
          35
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 8.444336265699711,
      "energy_per_request_joules": 7592.142755901202,
      "avg_power_watts": 1763.3573231438659,
      "median_itl_ms": 36.84750897809863,
      "p90_itl_ms": 38.14277398632839,
      "p95_itl_ms": 38.450214895419776,
      "p99_itl_ms": 47.359769062604734,
      "output_throughput_tokens_per_sec": 206.78163175070955,
      "avg_batch_size": 7.9930571626938205,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          45,
          63,
          94,
          80,
          83,
          87,
          71,
          48,
          40,
          52,
          26,
          22,
          27,
          22,
          16,
          17,
          12,
          7,
          14,
          19,
          6,
          10,
          13,
          6,
          10,
          5,
          4,
          10,
          4,
          6,
          4,
          4,
          2,
          4,
          4,
          4,
          3,
          3,
          0,
          1,
          1,
          2,
          0,
          2,
          1,
          2,
          1,
          2,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.8863511007056551,
      "energy_per_request_joules": 816.4929578495504,
      "avg_power_watts": 1763.8358216459405,
      "median_itl_ms": 52.68382799113169,
      "p90_itl_ms": 135.5588772217743,
      "p95_itl_ms": 147.40529558621347,
      "p99_itl_ms": 155.2641791733913,
      "output_throughput_tokens_per_sec": 1583.4970693073421,
      "avg_batch_size": 127.8661800486618,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          41,
          44,
          60,
          83,
          88,
          73,
          83,
          76,
          47,
          46,
          46,
          39,
          17,
          23,
          25,
          15,
          16,
          13,
          13,
          15,
          9,
          16,
          13,
          7,
          11,
          6,
          9,
          6,
          4,
          4,
          4,
          4,
          3,
          5,
          8,
          5,
          0,
          4,
          4,
          3,
          4,
          1,
          0,
          2,
          2,
          1,
          0,
          2,
          0,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 0,
        "notes": ""
      },
      "energy_per_token_joules": 0.544306370677898,
      "energy_per_request_joules": 495.936723250396,
      "avg_power_watts": 1717.462544968228,
      "median_itl_ms": 62.87448646617122,
      "p90_itl_ms": 155.99705999484286,
      "p95_itl_ms": 161.03158805926796,
      "p99_itl_ms": 174.60385213722478,
      "output_throughput_tokens_per_sec": 2599.2830156069635,
      "avg_batch_size": 255.73540856031127,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          86,
          88,
          114,
          189,
          175,
          167,
          164,
          124,
          106,
          97,
          77,
          65,
          60,
          48,
          38,
          29,
          28,
          28,
          24,
          26,
          22,
          24,
          15,
          21,
          26,
          20,
          8,
          14,
          9,
          12,
          7,
          3,
          9,
          9,
          5,
          12,
          4,
          4,
          5,
          7,
          5,
          3,
          1,
          2,
          5,
          4,
          2,
          2,
          2,
          53
        ]
      }
    }
  ]
}