{
  "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
  "task": "lm-arena-chat",
  "total_params_billions": 400.0,
  "activated_params_billions": 17.0,
  "architecture": "MoE",
  "weight_precision": "fp8",
  "output_length_distribution": {
    "bins": [
      2.0,
      80.58,
      159.16,
      237.74,
      316.32,
      394.9,
      473.48,
      552.06,
      630.64,
      709.22,
      787.8,
      866.38,
      944.96,
      1023.54,
      1102.12,
      1180.7,
      1259.28,
      1337.86,
      1416.44,
      1495.02,
      1573.6,
      1652.18,
      1730.76,
      1809.34,
      1887.92,
      1966.5,
      2045.08,
      2123.66,
      2202.24,
      2280.82,
      2359.4,
      2437.98,
      2516.56,
      2595.14,
      2673.72,
      2752.2999999999997,
      2830.88,
      2909.46,
      2988.04,
      3066.62,
      3145.2,
      3223.7799999999997,
      3302.36,
      3380.94,
      3459.52,
      3538.1,
      3616.68,
      3695.2599999999998,
      3773.84,
      3852.42,
      3931.0
    ],
    "counts": [
      1787,
      919,
      708,
      666,
      710,
      919,
      798,
      683,
      532,
      382,
      329,
      230,
      156,
      114,
      68,
      40,
      24,
      33,
      19,
      8,
      17,
      14,
      4,
      7,
      6,
      2,
      7,
      4,
      2,
      1,
      1,
      1,
      6,
      6,
      2,
      1,
      2,
      0,
      2,
      1,
      0,
      2,
      1,
      0,
      0,
      1,
      0,
      0,
      0,
      1
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.7573396700014222,
      "energy_per_request_joules": 307.16558047394597,
      "avg_output_len": 405.5849609375,
      "avg_power_watts": 3140.5181505218916,
      "median_itl_ms": 27.628473937511444,
      "p90_itl_ms": 31.287204846739783,
      "p95_itl_ms": 52.70781237632036,
      "p99_itl_ms": 59.35958638787269,
      "output_throughput_tokens_per_sec": 4146.7762417832855,
      "avg_batch_size": 127.72222222222223,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          202,
          102,
          79,
          73,
          78,
          109,
          83,
          80,
          55,
          38,
          47,
          23,
          13,
          9,
          8,
          5,
          3,
          7,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.8157942573743913,
      "energy_per_request_joules": 759.546383212392,
      "avg_output_len": 418.2998046875,
      "avg_power_watts": 2014.707172835016,
      "median_itl_ms": 13.283604755997658,
      "p90_itl_ms": 13.624375686049461,
      "p95_itl_ms": 13.8603825122118,
      "p99_itl_ms": 48.573178388178306,
      "output_throughput_tokens_per_sec": 1109.5459546987718,
      "avg_batch_size": 15.973474801061007,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          201,
          90,
          92,
          67,
          74,
          107,
          96,
          67,
          59,
          46,
          31,
          22,
          22,
          14,
          7,
          5,
          5,
          2,
          3,
          2,
          2,
          3,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6416026507218848,
      "energy_per_request_joules": 266.3089596057839,
      "avg_output_len": 415.068359375,
      "avg_power_watts": 3343.0232559162782,
      "median_itl_ms": 33.2093695178628,
      "p90_itl_ms": 38.075342774391174,
      "p95_itl_ms": 56.61759898066521,
      "p99_itl_ms": 66.56867032870652,
      "output_throughput_tokens_per_sec": 5210.42619159218,
      "avg_batch_size": 191.56716417910448,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          195,
          95,
          85,
          63,
          97,
          97,
          87,
          85,
          57,
          40,
          33,
          27,
          19,
          14,
          8,
          1,
          1,
          6,
          4,
          2,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5604892165392596,
      "energy_per_request_joules": 229.47161977802995,
      "avg_output_len": 409.4130859375,
      "avg_power_watts": 3507.338192747269,
      "median_itl_ms": 36.97950020432472,
      "p90_itl_ms": 41.91430062055588,
      "p95_itl_ms": 60.561890713870525,
      "p99_itl_ms": 83.9682464301582,
      "output_throughput_tokens_per_sec": 6257.637237703389,
      "avg_batch_size": 255.42307692307693,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          202,
          99,
          79,
          74,
          81,
          95,
          99,
          67,
          67,
          35,
          38,
          25,
          17,
          18,
          7,
          3,
          3,
          2,
          2,
          0,
          1,
          3,
          0,
          1,
          0,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.2655324258473077,
      "energy_per_request_joules": 521.8813493378412,
      "avg_output_len": 412.380859375,
      "avg_power_watts": 2284.2672979381214,
      "median_itl_ms": 16.148020513355732,
      "p90_itl_ms": 16.708863899111748,
      "p95_itl_ms": 18.226942885667086,
      "p99_itl_ms": 50.50701173022389,
      "output_throughput_tokens_per_sec": 1804.985199339119,
      "avg_batch_size": 31.9070796460177,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          192,
          109,
          72,
          79,
          78,
          100,
          90,
          71,
          63,
          46,
          40,
          18,
          20,
          11,
          10,
          6,
          3,
          1,
          3,
          2,
          4,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.48419284725112327,
      "energy_per_request_joules": 197.33553739574418,
      "avg_output_len": 407.5556640625,
      "avg_power_watts": 3461.5403094992657,
      "median_itl_ms": 47.900935634970665,
      "p90_itl_ms": 66.18660315871239,
      "p95_itl_ms": 69.31344084441656,
      "p99_itl_ms": 112.54705876111986,
      "output_throughput_tokens_per_sec": 7149.094269259128,
      "avg_batch_size": 383.3170731707317,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          199,
          112,
          75,
          80,
          66,
          108,
          78,
          74,
          57,
          47,
          38,
          28,
          20,
          18,
          5,
          3,
          1,
          2,
          2,
          0,
          4,
          1,
          2,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.9439309067180714,
      "energy_per_request_joules": 383.64430886159573,
      "avg_output_len": 406.4326171875,
      "avg_power_watts": 2655.646101321286,
      "median_itl_ms": 20.67001536488533,
      "p90_itl_ms": 22.415068745613098,
      "p95_itl_ms": 47.64300063252449,
      "p99_itl_ms": 53.07567436248064,
      "output_throughput_tokens_per_sec": 2813.3903471331737,
      "avg_batch_size": 63.86231884057971,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          201,
          100,
          86,
          69,
          77,
          99,
          99,
          70,
          61,
          50,
          31,
          33,
          11,
          8,
          5,
          6,
          3,
          4,
          2,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          2,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.8045326473291636,
      "energy_per_request_joules": 1162.6047671829551,
      "avg_output_len": 414.544921875,
      "avg_power_watts": 1845.3941329316724,
      "median_itl_ms": 11.49036269634962,
      "p90_itl_ms": 11.708237417042255,
      "p95_itl_ms": 11.806785874068735,
      "p99_itl_ms": 46.78823893889785,
      "output_throughput_tokens_per_sec": 658.0041543424691,
      "avg_batch_size": 7.984301412872841,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          199,
          101,
          67,
          82,
          88,
          93,
          87,
          78,
          52,
          42,
          37,
          30,
          18,
          14,
          9,
          8,
          3,
          4,
          2,
          0,
          2,
          1,
          1,
          1,
          2,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8487845785790009,
      "energy_per_request_joules": 345.9427115013843,
      "avg_output_len": 407.57421875,
      "avg_power_watts": 3009.7765411308883,
      "median_itl_ms": 24.52058345079422,
      "p90_itl_ms": 26.628663763403893,
      "p95_itl_ms": 50.2775227651,
      "p99_itl_ms": 56.6649042069912,
      "output_throughput_tokens_per_sec": 3545.9840071196018,
      "avg_batch_size": 95.79629629629629,
      "output_length_distribution": {
        "bins": [
          2.0,
          80.58,
          159.16,
          237.74,
          316.32,
          394.9,
          473.48,
          552.06,
          630.64,
          709.22,
          787.8,
          866.38,
          944.96,
          1023.54,
          1102.12,
          1180.7,
          1259.28,
          1337.86,
          1416.44,
          1495.02,
          1573.6,
          1652.18,
          1730.76,
          1809.34,
          1887.92,
          1966.5,
          2045.08,
          2123.66,
          2202.24,
          2280.82,
          2359.4,
          2437.98,
          2516.56,
          2595.14,
          2673.72,
          2752.2999999999997,
          2830.88,
          2909.46,
          2988.04,
          3066.62,
          3145.2,
          3223.7799999999997,
          3302.36,
          3380.94,
          3459.52,
          3538.1,
          3616.68,
          3695.2599999999998,
          3773.84,
          3852.42,
          3931.0
        ],
        "counts": [
          196,
          111,
          73,
          79,
          71,
          111,
          79,
          91,
          61,
          38,
          34,
          24,
          16,
          8,
          9,
          3,
          2,
          5,
          0,
          1,
          1,
          3,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          2,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    }
  ]
}