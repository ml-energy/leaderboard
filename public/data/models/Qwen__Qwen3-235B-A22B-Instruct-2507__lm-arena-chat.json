{
  "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
  "task": "lm-arena-chat",
  "total_params_billions": 235.0,
  "activated_params_billions": 22.0,
  "architecture": "MoE",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      2.0,
      83.88,
      165.76,
      247.64,
      329.52,
      411.4,
      493.28,
      575.16,
      657.04,
      738.92,
      820.8,
      902.68,
      984.56,
      1066.44,
      1148.32,
      1230.1999999999998,
      1312.08,
      1393.96,
      1475.84,
      1557.7199999999998,
      1639.6,
      1721.48,
      1803.36,
      1885.2399999999998,
      1967.12,
      2049.0,
      2130.88,
      2212.7599999999998,
      2294.64,
      2376.52,
      2458.3999999999996,
      2540.2799999999997,
      2622.16,
      2704.04,
      2785.92,
      2867.7999999999997,
      2949.68,
      3031.56,
      3113.4399999999996,
      3195.3199999999997,
      3277.2,
      3359.08,
      3440.96,
      3522.8399999999997,
      3604.72,
      3686.6,
      3768.4799999999996,
      3850.3599999999997,
      3932.24,
      4014.12,
      4096.0
    ],
    "counts": [
      9784,
      4511,
      3167,
      2929,
      2832,
      2750,
      2433,
      2167,
      1979,
      1827,
      1676,
      1786,
      1648,
      1558,
      1376,
      1209,
      1093,
      997,
      870,
      684,
      571,
      498,
      519,
      516,
      521,
      493,
      473,
      439,
      401,
      386,
      299,
      271,
      296,
      236,
      214,
      176,
      190,
      159,
      121,
      122,
      97,
      94,
      102,
      94,
      59,
      72,
      67,
      70,
      53,
      1435
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.4862393006169505,
      "energy_per_request_joules": 1282.582425670985,
      "avg_power_watts": 3903.4543908845462,
      "median_itl_ms": 46.639504998893244,
      "p90_itl_ms": 48.37928880042455,
      "p95_itl_ms": 53.2070759001726,
      "p99_itl_ms": 89.28590384100973,
      "output_throughput_tokens_per_sec": 2198.012269028752,
      "avg_batch_size": 127.84406779661018,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          177,
          79,
          60,
          64,
          53,
          44,
          44,
          39,
          36,
          31,
          26,
          44,
          25,
          23,
          25,
          25,
          14,
          21,
          16,
          12,
          13,
          10,
          10,
          7,
          9,
          14,
          15,
          3,
          4,
          5,
          3,
          10,
          6,
          3,
          6,
          3,
          1,
          2,
          2,
          5,
          1,
          2,
          0,
          2,
          1,
          1,
          0,
          2,
          0,
          26
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 5.17830831400822,
      "energy_per_request_joules": 4480.900425440654,
      "avg_power_watts": 3188.597383478894,
      "median_itl_ms": 25.347841999973753,
      "p90_itl_ms": 26.363165998918703,
      "p95_itl_ms": 26.64854619943071,
      "p99_itl_ms": 55.88809064021912,
      "output_throughput_tokens_per_sec": 607.1672229769315,
      "avg_batch_size": 15.974395448079658,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          180,
          77,
          64,
          48,
          51,
          56,
          49,
          34,
          33,
          37,
          19,
          32,
          37,
          29,
          21,
          24,
          22,
          19,
          14,
          10,
          9,
          12,
          12,
          7,
          8,
          8,
          7,
          10,
          12,
          9,
          6,
          4,
          6,
          5,
          4,
          6,
          3,
          3,
          3,
          1,
          3,
          3,
          2,
          1,
          0,
          1,
          0,
          0,
          0,
          23
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.148532751490339,
      "energy_per_request_joules": 1011.1754127417912,
      "avg_power_watts": 3987.424328613464,
      "median_itl_ms": 52.36333249922609,
      "p90_itl_ms": 54.93876010059467,
      "p95_itl_ms": 67.49959940143513,
      "p99_itl_ms": 101.43425735997883,
      "output_throughput_tokens_per_sec": 2635.308451180817,
      "avg_batch_size": 191.8106796116505,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          172,
          85,
          60,
          59,
          44,
          57,
          47,
          28,
          35,
          34,
          33,
          34,
          27,
          37,
          15,
          30,
          19,
          14,
          9,
          17,
          12,
          13,
          13,
          8,
          10,
          7,
          6,
          6,
          9,
          3,
          3,
          8,
          3,
          3,
          6,
          2,
          2,
          7,
          2,
          3,
          1,
          2,
          3,
          0,
          1,
          1,
          2,
          1,
          2,
          29
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.0927101193079563,
      "energy_per_request_joules": 955.2463326192346,
      "avg_power_watts": 4038.402679101194,
      "median_itl_ms": 55.47962600030587,
      "p90_itl_ms": 61.82613250075519,
      "p95_itl_ms": 88.42033074961364,
      "p99_itl_ms": 184.1327575995819,
      "output_throughput_tokens_per_sec": 2734.117768429016,
      "avg_batch_size": 228.4659090909091,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          179,
          81,
          61,
          53,
          47,
          54,
          41,
          35,
          36,
          32,
          30,
          38,
          26,
          46,
          23,
          21,
          21,
          9,
          19,
          12,
          7,
          11,
          8,
          4,
          12,
          8,
          9,
          8,
          10,
          4,
          8,
          6,
          5,
          1,
          2,
          4,
          4,
          4,
          1,
          3,
          2,
          1,
          0,
          2,
          1,
          0,
          0,
          7,
          1,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.825479811589516,
      "energy_per_request_joules": 3308.61788935041,
      "avg_power_watts": 3472.184599429809,
      "median_itl_ms": 34.71215199897415,
      "p90_itl_ms": 35.663523800394614,
      "p95_itl_ms": 35.957775101269355,
      "p99_itl_ms": 52.50825485960378,
      "output_throughput_tokens_per_sec": 883.8326740291839,
      "avg_batch_size": 31.966101694915253,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          179,
          82,
          70,
          43,
          51,
          57,
          43,
          36,
          33,
          24,
          39,
          30,
          34,
          24,
          36,
          16,
          22,
          17,
          13,
          10,
          9,
          10,
          13,
          10,
          9,
          12,
          7,
          4,
          7,
          4,
          6,
          11,
          4,
          6,
          1,
          1,
          1,
          4,
          5,
          4,
          3,
          0,
          2,
          3,
          2,
          0,
          0,
          0,
          1,
          26
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.3939569715302804,
      "energy_per_request_joules": 2104.846923791714,
      "avg_power_watts": 3704.701103562126,
      "median_itl_ms": 40.34211900034279,
      "p90_itl_ms": 40.97743200145487,
      "p95_itl_ms": 41.59834450001654,
      "p99_itl_ms": 72.15075349886321,
      "output_throughput_tokens_per_sec": 1401.26806411588,
      "avg_batch_size": 63.93071161048689,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          180,
          79,
          54,
          48,
          60,
          55,
          35,
          46,
          29,
          32,
          42,
          31,
          35,
          23,
          21,
          23,
          17,
          14,
          22,
          15,
          12,
          3,
          11,
          7,
          13,
          6,
          4,
          9,
          7,
          13,
          7,
          3,
          5,
          4,
          4,
          6,
          3,
          1,
          2,
          1,
          1,
          1,
          3,
          3,
          1,
          2,
          1,
          2,
          1,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 7.292589116187597,
      "energy_per_request_joules": 6303.880679088534,
      "avg_power_watts": 2828.5444663296767,
      "median_itl_ms": 20.238544999301666,
      "p90_itl_ms": 20.947102600439393,
      "p95_itl_ms": 21.136431999184424,
      "p99_itl_ms": 21.77302635951491,
      "output_throughput_tokens_per_sec": 385.6961982276843,
      "avg_batch_size": 7.990679094540613,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          181,
          73,
          72,
          48,
          56,
          43,
          42,
          39,
          45,
          36,
          28,
          33,
          21,
          32,
          30,
          20,
          17,
          17,
          15,
          10,
          11,
          16,
          10,
          7,
          4,
          13,
          7,
          4,
          7,
          11,
          9,
          7,
          3,
          2,
          5,
          1,
          3,
          2,
          3,
          0,
          2,
          3,
          2,
          3,
          0,
          1,
          1,
          2,
          3,
          24
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.819119929778148,
      "energy_per_request_joules": 1586.01676502642,
      "avg_power_watts": 3845.520596375327,
      "median_itl_ms": 43.67961599928094,
      "p90_itl_ms": 44.70363039945369,
      "p95_itl_ms": 46.96414245099729,
      "p99_itl_ms": 84.55999325944505,
      "output_throughput_tokens_per_sec": 1835.8526615831263,
      "avg_batch_size": 95.9023746701847,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          180,
          79,
          63,
          54,
          47,
          54,
          33,
          38,
          36,
          37,
          38,
          30,
          30,
          30,
          21,
          27,
          24,
          14,
          15,
          9,
          11,
          3,
          10,
          13,
          10,
          12,
          8,
          7,
          7,
          4,
          6,
          8,
          7,
          3,
          2,
          3,
          4,
          5,
          3,
          2,
          1,
          0,
          3,
          2,
          1,
          0,
          1,
          2,
          2,
          25
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.542182578567927,
      "energy_per_request_joules": 466.90285722453757,
      "avg_power_watts": 4508.793870120932,
      "median_itl_ms": 112.50159650080604,
      "p90_itl_ms": 135.53495049563935,
      "p95_itl_ms": 139.58224974703626,
      "p99_itl_ms": 170.15029240646984,
      "output_throughput_tokens_per_sec": 5802.046387798244,
      "avg_batch_size": 1022.6304347826087,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          364,
          160,
          124,
          107,
          95,
          94,
          93,
          73,
          73,
          65,
          64,
          61,
          59,
          53,
          60,
          44,
          44,
          34,
          25,
          29,
          19,
          22,
          31,
          20,
          17,
          21,
          15,
          9,
          9,
          19,
          12,
          12,
          6,
          11,
          9,
          3,
          6,
          10,
          3,
          3,
          3,
          2,
          3,
          2,
          2,
          2,
          4,
          4,
          1,
          47
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.5122787665380237,
      "energy_per_request_joules": 1331.0017335729428,
      "avg_power_watts": 4999.513810745349,
      "median_itl_ms": 36.91444099240471,
      "p90_itl_ms": 39.362635600264184,
      "p95_itl_ms": 41.41223899787292,
      "p99_itl_ms": 82.56698048324324,
      "output_throughput_tokens_per_sec": 2750.967690192201,
      "avg_batch_size": 127.82773109243698,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          174,
          86,
          54,
          62,
          51,
          37,
          46,
          48,
          31,
          37,
          32,
          24,
          27,
          31,
          28,
          19,
          17,
          23,
          18,
          11,
          12,
          11,
          4,
          18,
          5,
          8,
          9,
          7,
          7,
          7,
          6,
          6,
          5,
          6,
          4,
          4,
          1,
          1,
          3,
          2,
          0,
          2,
          3,
          3,
          1,
          3,
          1,
          1,
          2,
          26
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.46823173105889326,
      "energy_per_request_joules": 409.482366537498,
      "avg_power_watts": 4779.828628691161,
      "median_itl_ms": 143.55941200483358,
      "p90_itl_ms": 171.39873139676638,
      "p95_itl_ms": 178.11441884259693,
      "p99_itl_ms": 231.99295172540582,
      "output_throughput_tokens_per_sec": 6706.487559812184,
      "avg_batch_size": 1534.0267857142858,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          527,
          256,
          168,
          162,
          156,
          150,
          127,
          119,
          110,
          97,
          94,
          96,
          85,
          81,
          88,
          61,
          53,
          62,
          54,
          33,
          34,
          26,
          22,
          26,
          29,
          30,
          24,
          29,
          18,
          21,
          20,
          13,
          13,
          15,
          14,
          11,
          13,
          5,
          8,
          4,
          7,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          3,
          81
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 5.5810838222939285,
      "energy_per_request_joules": 4956.073287800221,
      "avg_power_watts": 4603.751957820395,
      "median_itl_ms": 18.702683999435976,
      "p90_itl_ms": 19.14035200024955,
      "p95_itl_ms": 19.311960000777617,
      "p99_itl_ms": 58.10142100381199,
      "output_throughput_tokens_per_sec": 812.9070425417179,
      "avg_batch_size": 15.98239110287303,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          180,
          81,
          54,
          65,
          45,
          45,
          48,
          44,
          42,
          20,
          23,
          34,
          34,
          31,
          18,
          22,
          22,
          16,
          14,
          14,
          11,
          11,
          6,
          12,
          10,
          9,
          10,
          8,
          3,
          5,
          7,
          5,
          7,
          4,
          6,
          4,
          1,
          3,
          1,
          2,
          5,
          3,
          1,
          2,
          1,
          1,
          2,
          1,
          3,
          28
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.41989460488784736,
      "energy_per_request_joules": 366.7888721248703,
      "avg_power_watts": 4924.190101961018,
      "median_itl_ms": 155.6095345003996,
      "p90_itl_ms": 187.33278021099977,
      "p95_itl_ms": 200.78389109912675,
      "p99_itl_ms": 286.1253915645647,
      "output_throughput_tokens_per_sec": 7066.936494253913,
      "avg_batch_size": 2044.982142857143,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          531,
          265,
          156,
          137,
          158,
          159,
          146,
          105,
          118,
          91,
          92,
          101,
          102,
          81,
          69,
          72,
          47,
          61,
          45,
          44,
          26,
          24,
          29,
          34,
          38,
          23,
          26,
          25,
          15,
          23,
          13,
          23,
          14,
          11,
          10,
          7,
          11,
          15,
          7,
          2,
          6,
          4,
          8,
          5,
          1,
          3,
          5,
          3,
          0,
          81
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.9397195034117868,
      "energy_per_request_joules": 820.2126944940134,
      "avg_power_watts": 5077.562470171535,
      "median_itl_ms": 43.46898099174723,
      "p90_itl_ms": 48.61373399035074,
      "p95_itl_ms": 60.02770250051981,
      "p99_itl_ms": 96.95789399847854,
      "output_throughput_tokens_per_sec": 3815.879722977546,
      "avg_batch_size": 255.66101694915255,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          177,
          82,
          65,
          39,
          62,
          46,
          45,
          41,
          30,
          42,
          30,
          27,
          34,
          26,
          25,
          19,
          22,
          17,
          18,
          15,
          8,
          7,
          10,
          10,
          11,
          7,
          8,
          8,
          11,
          7,
          6,
          1,
          4,
          6,
          6,
          4,
          3,
          2,
          0,
          3,
          3,
          1,
          0,
          2,
          3,
          0,
          3,
          0,
          1,
          27
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 4.200629952038238,
      "energy_per_request_joules": 3645.1335604803685,
      "avg_power_watts": 4530.013731280813,
      "median_itl_ms": 28.806008995161392,
      "p90_itl_ms": 29.66216999629978,
      "p95_itl_ms": 30.026355001609772,
      "p99_itl_ms": 62.37182980694343,
      "output_throughput_tokens_per_sec": 1048.4010104698286,
      "avg_batch_size": 31.9735516372796,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          178,
          81,
          62,
          46,
          51,
          55,
          48,
          36,
          32,
          35,
          31,
          30,
          33,
          27,
          19,
          25,
          25,
          21,
          16,
          16,
          10,
          4,
          12,
          9,
          4,
          7,
          12,
          9,
          9,
          3,
          3,
          2,
          7,
          11,
          6,
          2,
          5,
          3,
          2,
          2,
          2,
          0,
          2,
          1,
          0,
          3,
          1,
          2,
          1,
          23
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6740768160790235,
      "energy_per_request_joules": 582.6883909444114,
      "avg_power_watts": 4867.028033186916,
      "median_itl_ms": 58.895011999993585,
      "p90_itl_ms": 98.12347019906156,
      "p95_itl_ms": 106.29511259903666,
      "p99_itl_ms": 120.94796748075176,
      "output_throughput_tokens_per_sec": 5565.049837910219,
      "avg_batch_size": 511.37142857142857,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          358,
          160,
          106,
          112,
          106,
          92,
          96,
          77,
          80,
          58,
          71,
          69,
          67,
          47,
          46,
          50,
          40,
          26,
          38,
          21,
          24,
          19,
          20,
          14,
          25,
          16,
          16,
          11,
          16,
          17,
          16,
          9,
          11,
          10,
          8,
          5,
          6,
          6,
          6,
          4,
          2,
          3,
          4,
          2,
          2,
          1,
          3,
          1,
          2,
          49
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.5416779233101696,
      "energy_per_request_joules": 2208.2986392148973,
      "avg_power_watts": 4770.273283734266,
      "median_itl_ms": 32.98562100098934,
      "p90_itl_ms": 33.926146395970136,
      "p95_itl_ms": 35.452592905494384,
      "p99_itl_ms": 57.160001784504864,
      "output_throughput_tokens_per_sec": 1758.5765724612713,
      "avg_batch_size": 63.93736017897092,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          177,
          87,
          54,
          58,
          48,
          51,
          31,
          44,
          29,
          43,
          27,
          41,
          26,
          26,
          30,
          28,
          14,
          16,
          22,
          8,
          6,
          12,
          8,
          12,
          11,
          14,
          8,
          11,
          4,
          7,
          2,
          3,
          6,
          5,
          4,
          4,
          1,
          2,
          2,
          3,
          3,
          2,
          1,
          1,
          0,
          2,
          2,
          3,
          0,
          25
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 8.396027671034311,
      "energy_per_request_joules": 7410.486528426251,
      "avg_power_watts": 3941.7836755253757,
      "median_itl_ms": 16.562483004236128,
      "p90_itl_ms": 17.01701099955244,
      "p95_itl_ms": 17.150035199301783,
      "p99_itl_ms": 17.91131647914881,
      "output_throughput_tokens_per_sec": 462.4465496588866,
      "avg_batch_size": 7.989968321013728,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          172,
          83,
          54,
          58,
          54,
          52,
          42,
          43,
          42,
          29,
          30,
          32,
          29,
          25,
          25,
          23,
          19,
          19,
          17,
          12,
          8,
          6,
          12,
          9,
          10,
          9,
          8,
          8,
          6,
          7,
          4,
          4,
          7,
          3,
          5,
          2,
          2,
          7,
          2,
          3,
          1,
          0,
          2,
          4,
          1,
          1,
          1,
          1,
          3,
          28
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 8,
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.37321453066694377,
      "energy_per_request_joules": 326.0231812181162,
      "avg_power_watts": 5395.589402297423,
      "median_itl_ms": 240.9158169903094,
      "p90_itl_ms": 320.58046300080605,
      "p95_itl_ms": 367.319661048532,
      "p99_itl_ms": 789.0634731343014,
      "output_throughput_tokens_per_sec": 7333.191832190612,
      "avg_batch_size": 4090.3977272727275,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          1069,
          496,
          322,
          324,
          313,
          310,
          265,
          234,
          219,
          218,
          163,
          184,
          172,
          185,
          131,
          148,
          112,
          109,
          96,
          78,
          67,
          61,
          52,
          58,
          46,
          56,
          47,
          58,
          46,
          43,
          33,
          30,
          34,
          29,
          21,
          24,
          22,
          18,
          13,
          11,
          11,
          8,
          8,
          7,
          7,
          13,
          8,
          5,
          4,
          156
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 6.456770105737344,
      "energy_per_request_joules": 5584.70889877075,
      "avg_power_watts": 2562.1769211252954,
      "median_itl_ms": 19.666570995468646,
      "p90_itl_ms": 20.312772403121926,
      "p95_itl_ms": 20.50538700132165,
      "p99_itl_ms": 21.42864028399345,
      "output_throughput_tokens_per_sec": 394.1203387290699,
      "avg_batch_size": 7.990445859872612,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          181,
          80,
          54,
          56,
          54,
          48,
          40,
          51,
          28,
          43,
          33,
          32,
          29,
          23,
          26,
          16,
          20,
          21,
          11,
          10,
          18,
          5,
          9,
          7,
          9,
          10,
          6,
          11,
          11,
          6,
          2,
          7,
          9,
          6,
          2,
          2,
          3,
          2,
          1,
          3,
          2,
          1,
          1,
          2,
          4,
          2,
          2,
          2,
          2,
          21
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 4.550388063648032,
      "energy_per_request_joules": 3956.1002725542494,
      "avg_power_watts": 2896.7329268203844,
      "median_itl_ms": 24.541911014239304,
      "p90_itl_ms": 25.69366459356388,
      "p95_itl_ms": 26.0902940921369,
      "p99_itl_ms": 56.299414734530714,
      "output_throughput_tokens_per_sec": 622.534349976571,
      "avg_batch_size": 15.983870967741936,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          174,
          81,
          62,
          53,
          58,
          51,
          43,
          33,
          37,
          25,
          35,
          39,
          29,
          41,
          15,
          19,
          18,
          26,
          15,
          13,
          4,
          8,
          9,
          6,
          10,
          8,
          9,
          10,
          6,
          8,
          7,
          4,
          5,
          5,
          5,
          4,
          5,
          0,
          2,
          4,
          0,
          4,
          4,
          1,
          1,
          0,
          3,
          1,
          0,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.05275443145985,
      "energy_per_request_joules": 2660.1117799463236,
      "avg_power_watts": 3185.865439767311,
      "median_itl_ms": 29.83295900048688,
      "p90_itl_ms": 30.65786920778919,
      "p95_itl_ms": 31.018828594824296,
      "p99_itl_ms": 53.95943550916854,
      "output_throughput_tokens_per_sec": 1018.923944515232,
      "avg_batch_size": 31.96969696969697,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          183,
          74,
          67,
          48,
          53,
          47,
          45,
          35,
          56,
          25,
          22,
          24,
          35,
          32,
          34,
          22,
          14,
          17,
          11,
          14,
          18,
          9,
          7,
          7,
          9,
          7,
          7,
          6,
          12,
          6,
          5,
          4,
          3,
          5,
          4,
          3,
          5,
          1,
          5,
          4,
          2,
          1,
          3,
          1,
          2,
          1,
          2,
          1,
          1,
          25
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.2073053901940252,
      "energy_per_request_joules": 1047.6840546893295,
      "avg_power_watts": 3142.9811977702625,
      "median_itl_ms": 47.08670650143176,
      "p90_itl_ms": 50.35464620159473,
      "p95_itl_ms": 53.13555959728546,
      "p99_itl_ms": 85.30445821001186,
      "output_throughput_tokens_per_sec": 2190.8937519351834,
      "avg_batch_size": 127.87,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          181,
          83,
          54,
          46,
          56,
          42,
          53,
          48,
          32,
          32,
          36,
          26,
          36,
          21,
          30,
          14,
          21,
          25,
          15,
          17,
          10,
          7,
          7,
          8,
          5,
          11,
          13,
          6,
          7,
          4,
          7,
          5,
          8,
          3,
          3,
          4,
          1,
          3,
          3,
          2,
          3,
          3,
          1,
          2,
          0,
          1,
          0,
          0,
          2,
          27
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.043033334635237,
      "energy_per_request_joules": 1789.8288810233641,
      "avg_power_watts": 3122.5641096018644,
      "median_itl_ms": 40.821517002768815,
      "p90_itl_ms": 42.09522349992767,
      "p95_itl_ms": 43.59326000849251,
      "p99_itl_ms": 67.2282963452744,
      "output_throughput_tokens_per_sec": 1413.4452840451318,
      "avg_batch_size": 63.91256830601093,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          178,
          84,
          53,
          59,
          56,
          46,
          46,
          41,
          28,
          42,
          24,
          35,
          27,
          30,
          18,
          19,
          33,
          8,
          15,
          14,
          6,
          9,
          11,
          14,
          7,
          11,
          10,
          4,
          17,
          4,
          3,
          4,
          2,
          7,
          2,
          6,
          4,
          2,
          4,
          3,
          1,
          0,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          29
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.34368513275277296,
      "energy_per_request_joules": 298.38028333669223,
      "avg_power_watts": 3002.1073530617564,
      "median_itl_ms": 103.86629600543529,
      "p90_itl_ms": 128.0457684013527,
      "p95_itl_ms": 135.17154659202788,
      "p99_itl_ms": 182.001227917498,
      "output_throughput_tokens_per_sec": 5452.265759178418,
      "avg_batch_size": 1022.5977011494252,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          360,
          166,
          108,
          100,
          110,
          98,
          82,
          84,
          83,
          62,
          55,
          68,
          56,
          59,
          56,
          39,
          45,
          33,
          38,
          26,
          24,
          15,
          21,
          23,
          16,
          14,
          22,
          12,
          16,
          11,
          6,
          10,
          12,
          5,
          4,
          6,
          8,
          5,
          4,
          5,
          3,
          5,
          5,
          4,
          1,
          3,
          3,
          1,
          1,
          55
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 1536,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3162059656469451,
      "energy_per_request_joules": 278.39042896426184,
      "avg_power_watts": 3006.796685734427,
      "median_itl_ms": 135.5150669987779,
      "p90_itl_ms": 169.60162940667945,
      "p95_itl_ms": 188.24133549642283,
      "p99_itl_ms": 286.6105389723092,
      "output_throughput_tokens_per_sec": 5488.138886276164,
      "avg_batch_size": 1411.1935483870968,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          521,
          252,
          179,
          165,
          149,
          151,
          129,
          121,
          112,
          103,
          83,
          90,
          87,
          86,
          89,
          61,
          54,
          51,
          55,
          43,
          28,
          21,
          23,
          22,
          33,
          29,
          32,
          24,
          21,
          29,
          12,
          5,
          19,
          8,
          9,
          13,
          12,
          12,
          6,
          7,
          7,
          4,
          4,
          6,
          1,
          4,
          3,
          3,
          4,
          90
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2676523879809479,
      "energy_per_request_joules": 231.9495459068565,
      "avg_power_watts": 3268.479266859503,
      "median_itl_ms": 143.62831650942098,
      "p90_itl_ms": 177.43998000514694,
      "p95_itl_ms": 194.96807576797437,
      "p99_itl_ms": 353.6779921996638,
      "output_throughput_tokens_per_sec": 5305.98386445319,
      "avg_batch_size": 2044.8076923076924,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          536,
          246,
          165,
          165,
          147,
          161,
          139,
          122,
          107,
          95,
          93,
          100,
          90,
          80,
          66,
          59,
          73,
          65,
          39,
          34,
          32,
          29,
          29,
          28,
          26,
          20,
          27,
          32,
          18,
          24,
          18,
          12,
          20,
          11,
          13,
          8,
          9,
          5,
          6,
          7,
          5,
          8,
          6,
          7,
          2,
          4,
          4,
          2,
          2,
          76
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.710970071755604,
      "energy_per_request_joules": 624.8232723189357,
      "avg_power_watts": 3203.8406083650552,
      "median_itl_ms": 53.255411505233496,
      "p90_itl_ms": 58.379866098403,
      "p95_itl_ms": 64.27994945697716,
      "p99_itl_ms": 105.64801411645021,
      "output_throughput_tokens_per_sec": 3217.7612268391977,
      "avg_batch_size": 255.7062937062937,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          176,
          78,
          67,
          50,
          48,
          52,
          47,
          36,
          22,
          39,
          30,
          39,
          35,
          32,
          23,
          19,
          19,
          21,
          15,
          8,
          9,
          7,
          11,
          11,
          8,
          12,
          5,
          10,
          8,
          11,
          5,
          6,
          4,
          6,
          5,
          3,
          2,
          0,
          1,
          4,
          1,
          2,
          3,
          1,
          2,
          1,
          1,
          1,
          1,
          27
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4629841694171579,
      "energy_per_request_joules": 407.37904725739253,
      "avg_power_watts": 3012.2719003895086,
      "median_itl_ms": 67.11570649349596,
      "p90_itl_ms": 106.40274759498425,
      "p95_itl_ms": 114.1425818655989,
      "p99_itl_ms": 130.3036870845244,
      "output_throughput_tokens_per_sec": 4848.3612201965,
      "avg_batch_size": 511.3775510204082,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          359,
          158,
          109,
          114,
          96,
          96,
          95,
          85,
          64,
          59,
          67,
          71,
          58,
          48,
          49,
          45,
          43,
          38,
          32,
          33,
          18,
          24,
          18,
          16,
          24,
          19,
          10,
          13,
          16,
          17,
          10,
          10,
          7,
          8,
          9,
          4,
          12,
          6,
          6,
          4,
          0,
          7,
          3,
          1,
          3,
          3,
          3,
          3,
          1,
          54
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 3072,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.24557551756706672,
      "energy_per_request_joules": 213.28545466493532,
      "avg_power_watts": 3231.4177508472008,
      "median_itl_ms": 118.4986879961798,
      "p90_itl_ms": 222.9848100047093,
      "p95_itl_ms": 238.56627569039105,
      "p99_itl_ms": 360.99415537231835,
      "output_throughput_tokens_per_sec": 5390.174816690904,
      "avg_batch_size": 3046.5263157894738,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          717,
          326,
          232,
          214,
          204,
          214,
          161,
          150,
          147,
          144,
          120,
          127,
          117,
          105,
          117,
          87,
          92,
          66,
          56,
          35,
          52,
          41,
          37,
          43,
          34,
          30,
          38,
          38,
          30,
          19,
          20,
          11,
          28,
          10,
          19,
          11,
          22,
          9,
          7,
          9,
          4,
          8,
          9,
          9,
          6,
          4,
          3,
          6,
          4,
          104
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 4,
      "max_num_seqs": 4096,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.24024534151505447,
      "energy_per_request_joules": 209.92863171593132,
      "avg_power_watts": 3196.0657904719633,
      "median_itl_ms": 67.7747610170627,
      "p90_itl_ms": 215.12070119788407,
      "p95_itl_ms": 282.5096203494467,
      "p99_itl_ms": 393.15440698177474,
      "output_throughput_tokens_per_sec": 5260.241071279092,
      "avg_batch_size": 3764.6470588235293,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          883,
          411,
          294,
          272,
          253,
          233,
          232,
          202,
          174,
          160,
          166,
          164,
          146,
          144,
          122,
          112,
          90,
          97,
          82,
          61,
          43,
          42,
          44,
          46,
          59,
          42,
          48,
          39,
          32,
          35,
          34,
          28,
          26,
          24,
          16,
          16,
          15,
          14,
          8,
          12,
          12,
          10,
          11,
          10,
          7,
          8,
          4,
          8,
          4,
          125
        ]
      }
    }
  ]
}