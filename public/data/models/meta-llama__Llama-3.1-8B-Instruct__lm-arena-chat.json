{
  "model_id": "meta-llama/Llama-3.1-8B-Instruct",
  "task": "lm-arena-chat",
  "total_params_billions": 8.0,
  "activated_params_billions": 8.0,
  "architecture": "Dense Transformer",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      2.0,
      83.88,
      165.76,
      247.64,
      329.52,
      411.4,
      493.28,
      575.16,
      657.04,
      738.92,
      820.8,
      902.68,
      984.56,
      1066.44,
      1148.32,
      1230.1999999999998,
      1312.08,
      1393.96,
      1475.84,
      1557.7199999999998,
      1639.6,
      1721.48,
      1803.36,
      1885.2399999999998,
      1967.12,
      2049.0,
      2130.88,
      2212.7599999999998,
      2294.64,
      2376.52,
      2458.3999999999996,
      2540.2799999999997,
      2622.16,
      2704.04,
      2785.92,
      2867.7999999999997,
      2949.68,
      3031.56,
      3113.4399999999996,
      3195.3199999999997,
      3277.2,
      3359.08,
      3440.96,
      3522.8399999999997,
      3604.72,
      3686.6,
      3768.4799999999996,
      3850.3599999999997,
      3932.24,
      4014.12,
      4096.0
    ],
    "counts": [
      8607,
      4310,
      3518,
      3645,
      3626,
      3541,
      3242,
      2563,
      1856,
      1269,
      877,
      641,
      455,
      337,
      268,
      207,
      141,
      118,
      101,
      83,
      53,
      46,
      51,
      42,
      38,
      37,
      28,
      21,
      15,
      22,
      18,
      13,
      11,
      11,
      7,
      13,
      8,
      7,
      2,
      6,
      0,
      3,
      3,
      3,
      1,
      0,
      2,
      1,
      1,
      68
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.09510991243206074,
      "energy_per_request_joules": 38.48050460996364,
      "avg_output_len": 404.58984375,
      "avg_power_watts": 669.2439022030471,
      "median_itl_ms": 16.482017002999783,
      "p90_itl_ms": 20.042716525495052,
      "p95_itl_ms": 24.74002493545413,
      "p99_itl_ms": 46.433303505182266,
      "output_throughput_tokens_per_sec": 7036.531577937304,
      "avg_batch_size": 127.62,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          220,
          114,
          88,
          86,
          96,
          94,
          83,
          65,
          39,
          34,
          33,
          10,
          14,
          9,
          7,
          4,
          2,
          4,
          4,
          5,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          4
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.26273977845850766,
      "energy_per_request_joules": 106.2076803873686,
      "avg_output_len": 404.2314453125,
      "avg_power_watts": 513.280830756726,
      "median_itl_ms": 7.912369444966316,
      "p90_itl_ms": 8.581877872347832,
      "p95_itl_ms": 9.243009611964226,
      "p99_itl_ms": 13.290748298168158,
      "output_throughput_tokens_per_sec": 1953.571072367271,
      "avg_batch_size": 15.951690821256038,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          224,
          103,
          92,
          81,
          98,
          90,
          88,
          70,
          42,
          40,
          23,
          15,
          15,
          7,
          5,
          2,
          2,
          3,
          6,
          1,
          1,
          3,
          3,
          1,
          0,
          2,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.08369519184258484,
      "energy_per_request_joules": 33.20802896960434,
      "avg_output_len": 396.7734375,
      "avg_power_watts": 688.2545655688424,
      "median_itl_ms": 20.908080972731113,
      "p90_itl_ms": 26.95829514414072,
      "p95_itl_ms": 33.54309350252143,
      "p99_itl_ms": 59.01624012738466,
      "output_throughput_tokens_per_sec": 8223.34653182135,
      "avg_batch_size": 191.65853658536585,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          208,
          135,
          74,
          105,
          85,
          91,
          80,
          64,
          46,
          35,
          18,
          18,
          20,
          3,
          9,
          8,
          3,
          4,
          1,
          4,
          3,
          0,
          2,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          2,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.0766413032348523,
      "energy_per_request_joules": 30.97711994863476,
      "avg_output_len": 404.18310546875,
      "avg_power_watts": 690.5083838667351,
      "median_itl_ms": 26.12623802269809,
      "p90_itl_ms": 32.539849379099905,
      "p95_itl_ms": 38.75030499766581,
      "p99_itl_ms": 59.66428812243974,
      "output_throughput_tokens_per_sec": 9009.611720077452,
      "avg_batch_size": 255.18987341772151,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          434,
          229,
          176,
          182,
          187,
          197,
          151,
          125,
          96,
          66,
          42,
          33,
          25,
          18,
          18,
          6,
          10,
          9,
          7,
          9,
          3,
          2,
          5,
          2,
          1,
          4,
          0,
          0,
          0,
          0,
          2,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          5
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.16505510741316592,
      "energy_per_request_joules": 64.425811784883,
      "avg_output_len": 390.3291015625,
      "avg_power_watts": 559.7134507541415,
      "median_itl_ms": 8.906599134206772,
      "p90_itl_ms": 10.384867712855337,
      "p95_itl_ms": 11.403440311551089,
      "p99_itl_ms": 18.416078612208267,
      "output_throughput_tokens_per_sec": 3391.070167571773,
      "avg_batch_size": 31.911504424778762,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          231,
          95,
          96,
          92,
          94,
          87,
          88,
          64,
          46,
          37,
          18,
          23,
          18,
          6,
          3,
          2,
          5,
          5,
          3,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          2,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.07423418180476347,
      "energy_per_request_joules": 29.27382187823128,
      "avg_output_len": 394.34423828125,
      "avg_power_watts": 686.5186027909551,
      "median_itl_ms": 37.70148498006165,
      "p90_itl_ms": 47.82290779403411,
      "p95_itl_ms": 54.311841214075685,
      "p99_itl_ms": 96.15210728254148,
      "output_throughput_tokens_per_sec": 9248.01198181863,
      "avg_batch_size": 383.01428571428573,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          449,
          211,
          175,
          201,
          159,
          190,
          192,
          120,
          105,
          58,
          48,
          33,
          27,
          19,
          11,
          8,
          4,
          6,
          5,
          2,
          1,
          1,
          2,
          2,
          1,
          1,
          3,
          2,
          0,
          3,
          0,
          0,
          2,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          5
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.07019449941326047,
      "energy_per_request_joules": 27.844149422286517,
      "avg_output_len": 396.67138671875,
      "avg_power_watts": 688.2983232359837,
      "median_itl_ms": 47.40760399727151,
      "p90_itl_ms": 59.06887900782748,
      "p95_itl_ms": 65.01795589574611,
      "p99_itl_ms": 106.78900223167149,
      "output_throughput_tokens_per_sec": 9805.587745326337,
      "avg_batch_size": 510.8688524590164,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          443,
          211,
          190,
          195,
          182,
          201,
          149,
          118,
          100,
          59,
          42,
          36,
          29,
          16,
          19,
          12,
          6,
          2,
          8,
          3,
          4,
          2,
          3,
          1,
          4,
          1,
          0,
          2,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          3,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          4
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.11857964835952284,
      "energy_per_request_joules": 46.90311454458103,
      "avg_output_len": 395.541015625,
      "avg_power_watts": 610.3476218460647,
      "median_itl_ms": 11.500172317028046,
      "p90_itl_ms": 13.176492601633074,
      "p95_itl_ms": 14.754379913210862,
      "p99_itl_ms": 25.68335087969897,
      "output_throughput_tokens_per_sec": 5147.153245011704,
      "avg_batch_size": 63.917808219178085,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          216,
          111,
          91,
          99,
          105,
          83,
          81,
          57,
          46,
          39,
          19,
          17,
          12,
          13,
          5,
          6,
          6,
          2,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          4,
          2,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 768,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.07134822942888497,
      "energy_per_request_joules": 28.35051624785673,
      "avg_output_len": 397.3541666666667,
      "avg_power_watts": 685.140945777979,
      "median_itl_ms": 62.930971500463784,
      "p90_itl_ms": 87.81373900419567,
      "p95_itl_ms": 106.97549971955596,
      "p99_itl_ms": 192.04428087599808,
      "output_throughput_tokens_per_sec": 9602.774326178349,
      "avg_batch_size": 690.8681318681319,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          665,
          342,
          262,
          282,
          277,
          271,
          249,
          195,
          129,
          100,
          74,
          39,
          41,
          26,
          16,
          21,
          11,
          5,
          9,
          11,
          2,
          7,
          2,
          7,
          3,
          3,
          3,
          5,
          1,
          5,
          2,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4547982611462042,
      "energy_per_request_joules": 176.76995773999624,
      "avg_output_len": 388.677734375,
      "avg_power_watts": 486.4380535594687,
      "median_itl_ms": 7.316111586987972,
      "p90_itl_ms": 7.704039663076401,
      "p95_itl_ms": 7.996502518653869,
      "p99_itl_ms": 10.866769570857286,
      "output_throughput_tokens_per_sec": 1069.5688508868182,
      "avg_batch_size": 7.978201634877384,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          220,
          114,
          93,
          93,
          98,
          85,
          92,
          59,
          40,
          37,
          22,
          20,
          11,
          8,
          7,
          2,
          3,
          1,
          5,
          1,
          0,
          4,
          3,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.102865531346047,
      "energy_per_request_joules": 40.40897607889865,
      "avg_output_len": 392.8330078125,
      "avg_power_watts": 643.9532367685447,
      "median_itl_ms": 14.077862724661827,
      "p90_itl_ms": 16.678499430418015,
      "p95_itl_ms": 20.120452716946595,
      "p99_itl_ms": 35.39796203374864,
      "output_throughput_tokens_per_sec": 6260.145923927034,
      "avg_batch_size": 95.70175438596492,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          223,
          110,
          90,
          97,
          94,
          99,
          72,
          73,
          41,
          36,
          20,
          11,
          14,
          9,
          5,
          6,
          2,
          5,
          2,
          1,
          3,
          0,
          0,
          0,
          2,
          1,
          1,
          0,
          0,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2423460942028801,
      "energy_per_request_joules": 99.11245254574936,
      "avg_output_len": 408.970703125,
      "avg_power_watts": 666.6801912464827,
      "median_itl_ms": 5.083433003164828,
      "p90_itl_ms": 8.795807996648364,
      "p95_itl_ms": 12.222974241012707,
      "p99_itl_ms": 18.040224708965983,
      "output_throughput_tokens_per_sec": 2750.9425866313777,
      "avg_batch_size": 15.899328859060402,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          223,
          98,
          90,
          95,
          95,
          88,
          85,
          66,
          56,
          27,
          29,
          19,
          5,
          7,
          5,
          7,
          4,
          5,
          4,
          1,
          2,
          0,
          1,
          1,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.1510692760199108,
      "energy_per_request_joules": 60.090312522947194,
      "avg_output_len": 397.7666015625,
      "avg_power_watts": 575.5530724733363,
      "median_itl_ms": 6.345150992274284,
      "p90_itl_ms": 14.910607208730656,
      "p95_itl_ms": 18.325782212195918,
      "p99_itl_ms": 25.094780172803443,
      "output_throughput_tokens_per_sec": 3809.8618570031335,
      "avg_batch_size": 31.766990291262136,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          219,
          118,
          86,
          92,
          100,
          80,
          82,
          62,
          52,
          32,
          18,
          19,
          11,
          8,
          8,
          12,
          6,
          4,
          0,
          3,
          1,
          1,
          1,
          0,
          2,
          1,
          0,
          0,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.11030269049306295,
      "energy_per_request_joules": 42.986272638295084,
      "avg_output_len": 389.7119140625,
      "avg_power_watts": 616.5121449284105,
      "median_itl_ms": 8.997416487545706,
      "p90_itl_ms": 20.032751504913904,
      "p95_itl_ms": 24.230182738392614,
      "p99_itl_ms": 34.18971085484391,
      "output_throughput_tokens_per_sec": 5589.275675620837,
      "avg_batch_size": 63.803030303030305,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          223,
          115,
          86,
          95,
          87,
          93,
          88,
          62,
          44,
          45,
          18,
          20,
          8,
          6,
          6,
          7,
          5,
          3,
          2,
          0,
          0,
          2,
          2,
          0,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3905238905034637,
      "energy_per_request_joules": 151.50076862712154,
      "avg_output_len": 387.9423828125,
      "avg_power_watts": 639.3908265351646,
      "median_itl_ms": 4.574391001369804,
      "p90_itl_ms": 6.00760200759396,
      "p95_itl_ms": 7.697059109341346,
      "p99_itl_ms": 14.804588232655046,
      "output_throughput_tokens_per_sec": 1637.2643059323757,
      "avg_batch_size": 7.957983193277311,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          221,
          109,
          99,
          94,
          95,
          95,
          74,
          65,
          50,
          31,
          22,
          19,
          13,
          5,
          7,
          3,
          6,
          4,
          2,
          2,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 1024,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.054922598342342914,
      "energy_per_request_joules": 21.726446649141838,
      "avg_output_len": 395.5830078125,
      "avg_power_watts": 599.8901004576812,
      "median_itl_ms": 87.12003598338924,
      "p90_itl_ms": 113.56322859646755,
      "p95_itl_ms": 121.82107815460766,
      "p99_itl_ms": 153.47145174542663,
      "output_throughput_tokens_per_sec": 10922.463950420793,
      "avg_batch_size": 1021.3333333333334,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          877,
          444,
          355,
          376,
          369,
          359,
          326,
          289,
          208,
          115,
          82,
          67,
          43,
          39,
          32,
          18,
          13,
          12,
          11,
          4,
          6,
          6,
          6,
          6,
          4,
          6,
          3,
          2,
          0,
          1,
          2,
          2,
          1,
          0,
          1,
          0,
          1,
          3,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          4
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.09831669252055335,
      "energy_per_request_joules": 38.89831770775215,
      "avg_output_len": 395.64306640625,
      "avg_power_watts": 449.32570995413784,
      "median_itl_ms": 26.657679496565834,
      "p90_itl_ms": 42.8361739992397,
      "p95_itl_ms": 48.31662949582096,
      "p99_itl_ms": 58.44129902019631,
      "output_throughput_tokens_per_sec": 4570.187405970814,
      "avg_batch_size": 127.54268292682927,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          426,
          245,
          187,
          170,
          176,
          185,
          177,
          136,
          91,
          51,
          46,
          40,
          27,
          20,
          11,
          6,
          9,
          7,
          6,
          4,
          2,
          3,
          3,
          4,
          1,
          2,
          2,
          2,
          2,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 2048,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.04669576735104617,
      "energy_per_request_joules": 18.472040700505755,
      "avg_output_len": 395.582763671875,
      "avg_power_watts": 691.0648132414816,
      "median_itl_ms": 124.85829350771382,
      "p90_itl_ms": 175.23864297836553,
      "p95_itl_ms": 190.32727355806853,
      "p99_itl_ms": 287.23442446033016,
      "output_throughput_tokens_per_sec": 14799.303072722694,
      "avg_batch_size": 2042.921052631579,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          1770,
          887,
          705,
          750,
          780,
          701,
          650,
          537,
          390,
          262,
          183,
          131,
          75,
          70,
          66,
          39,
          26,
          24,
          18,
          16,
          11,
          12,
          11,
          13,
          10,
          4,
          3,
          2,
          6,
          5,
          1,
          2,
          5,
          3,
          1,
          2,
          2,
          0,
          0,
          2,
          0,
          2,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          13
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.07048406596246932,
      "energy_per_request_joules": 28.15810902362383,
      "avg_output_len": 399.49609375,
      "avg_power_watts": 540.1979487399086,
      "median_itl_ms": 31.692558506620117,
      "p90_itl_ms": 48.46516041143332,
      "p95_itl_ms": 54.20180945366155,
      "p99_itl_ms": 65.51385449856748,
      "output_throughput_tokens_per_sec": 7664.1144542874135,
      "avg_batch_size": 255.23076923076923,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          457,
          186,
          200,
          193,
          184,
          172,
          180,
          134,
          88,
          60,
          47,
          30,
          16,
          20,
          9,
          17,
          9,
          6,
          4,
          11,
          4,
          1,
          0,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          0,
          0,
          1,
          1,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          5
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.0602349719839345,
      "energy_per_request_joules": 23.86120572476089,
      "avg_output_len": 396.1354166666667,
      "avg_power_watts": 576.5352555778485,
      "median_itl_ms": 50.231036002514884,
      "p90_itl_ms": 71.37475250056013,
      "p95_itl_ms": 77.39006950578187,
      "p99_itl_ms": 93.56033818767166,
      "output_throughput_tokens_per_sec": 9571.437266238263,
      "avg_batch_size": 510.5533980582524,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          658,
          333,
          283,
          267,
          265,
          280,
          255,
          202,
          147,
          105,
          73,
          41,
          31,
          28,
          19,
          21,
          9,
          7,
          3,
          3,
          6,
          2,
          4,
          1,
          5,
          2,
          2,
          1,
          1,
          1,
          0,
          2,
          1,
          2,
          1,
          1,
          2,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          5
        ]
      }
    }
  ]
}