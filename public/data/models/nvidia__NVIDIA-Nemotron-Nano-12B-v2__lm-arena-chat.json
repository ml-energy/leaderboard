{
  "model_id": "nvidia/NVIDIA-Nemotron-Nano-12B-v2",
  "task": "lm-arena-chat",
  "total_params_billions": 12.0,
  "activated_params_billions": 12.0,
  "architecture": "Mamba-Transformer Hybrid",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      3.0,
      84.86,
      166.72,
      248.57999999999998,
      330.44,
      412.3,
      494.15999999999997,
      576.02,
      657.88,
      739.74,
      821.6,
      903.46,
      985.3199999999999,
      1067.18,
      1149.04,
      1230.9,
      1312.76,
      1394.62,
      1476.48,
      1558.34,
      1640.2,
      1722.06,
      1803.92,
      1885.78,
      1967.6399999999999,
      2049.5,
      2131.36,
      2213.22,
      2295.08,
      2376.94,
      2458.8,
      2540.66,
      2622.52,
      2704.38,
      2786.24,
      2868.1,
      2949.96,
      3031.82,
      3113.68,
      3195.54,
      3277.4,
      3359.2599999999998,
      3441.12,
      3522.98,
      3604.84,
      3686.7,
      3768.56,
      3850.42,
      3932.2799999999997,
      4014.14,
      4096.0
    ],
    "counts": [
      3170,
      1340,
      975,
      879,
      801,
      764,
      720,
      707,
      602,
      519,
      436,
      372,
      301,
      262,
      201,
      177,
      117,
      91,
      61,
      46,
      29,
      24,
      20,
      20,
      16,
      10,
      10,
      5,
      8,
      3,
      6,
      4,
      3,
      1,
      4,
      0,
      0,
      0,
      1,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1630
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.20886571099347784,
      "energy_per_request_joules": 95.98195301833874,
      "avg_power_watts": 674.5290034452222,
      "median_itl_ms": 29.165392741560936,
      "p90_itl_ms": 73.33428356796503,
      "p95_itl_ms": 77.04649427905679,
      "p99_itl_ms": 174.3089305609465,
      "output_throughput_tokens_per_sec": 2521.0959840897285,
      "avg_batch_size": 127.57142857142857,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          246,
          104,
          89,
          72,
          49,
          69,
          63,
          50,
          48,
          46,
          45,
          29,
          16,
          21,
          19,
          11,
          9,
          8,
          5,
          5,
          4,
          3,
          3,
          2,
          0,
          1,
          1,
          0,
          0,
          2,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4528176832252223,
      "energy_per_request_joules": 208.3708668895252,
      "avg_power_watts": 516.6568164274356,
      "median_itl_ms": 12.23376952111721,
      "p90_itl_ms": 12.520584464073181,
      "p95_itl_ms": 12.980451062321663,
      "p99_itl_ms": 56.04606762528419,
      "output_throughput_tokens_per_sec": 1097.824214299479,
      "avg_batch_size": 15.858910891089108,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          242,
          109,
          88,
          66,
          64,
          53,
          57,
          61,
          49,
          54,
          36,
          25,
          24,
          13,
          19,
          19,
          6,
          10,
          7,
          5,
          3,
          2,
          2,
          1,
          3,
          0,
          2,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.1878770881015258,
      "energy_per_request_joules": 86.82471754982495,
      "avg_power_watts": 691.9084429902782,
      "median_itl_ms": 38.656579330563545,
      "p90_itl_ms": 82.72171914577484,
      "p95_itl_ms": 87.65082247555256,
      "p99_itl_ms": 236.39661975204925,
      "output_throughput_tokens_per_sec": 2890.390951482086,
      "avg_batch_size": 191.31730769230768,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          243,
          102,
          77,
          70,
          69,
          58,
          67,
          54,
          48,
          54,
          32,
          28,
          22,
          26,
          15,
          17,
          8,
          8,
          6,
          5,
          1,
          2,
          1,
          2,
          0,
          4,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.1803028832475481,
      "energy_per_request_joules": 83.22016916377432,
      "avg_power_watts": 693.5924849065933,
      "median_itl_ms": 45.98557949066162,
      "p90_itl_ms": 92.31475181877613,
      "p95_itl_ms": 104.63101789355278,
      "p99_itl_ms": 285.7917774468661,
      "output_throughput_tokens_per_sec": 2997.777192076711,
      "avg_batch_size": 241.1573033707865,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          249,
          103,
          72,
          67,
          72,
          66,
          56,
          60,
          65,
          34,
          25,
          32,
          25,
          21,
          16,
          15,
          9,
          6,
          7,
          7,
          4,
          1,
          1,
          1,
          0,
          2,
          2,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.30959750220386845,
      "energy_per_request_joules": 142.67637624757475,
      "avg_power_watts": 559.5918240402709,
      "median_itl_ms": 14.496257528662682,
      "p90_itl_ms": 15.625864267349243,
      "p95_itl_ms": 55.9028796851635,
      "p99_itl_ms": 62.74990998208523,
      "output_throughput_tokens_per_sec": 1662.5027691181322,
      "avg_batch_size": 31.768924302788843,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          241,
          107,
          74,
          70,
          71,
          68,
          65,
          66,
          40,
          39,
          28,
          27,
          25,
          25,
          16,
          15,
          9,
          7,
          4,
          4,
          5,
          3,
          4,
          2,
          2,
          1,
          1,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.24638339538749862,
      "energy_per_request_joules": 113.00696845218933,
      "avg_power_watts": 628.9821341616944,
      "median_itl_ms": 19.291361793875694,
      "p90_itl_ms": 54.48200739920139,
      "p95_itl_ms": 63.501773029565804,
      "p99_itl_ms": 90.03322672098875,
      "output_throughput_tokens_per_sec": 2290.7350482120546,
      "avg_batch_size": 63.7093023255814,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          240,
          115,
          77,
          59,
          63,
          67,
          65,
          62,
          38,
          37,
          44,
          36,
          29,
          24,
          15,
          13,
          6,
          9,
          8,
          3,
          1,
          2,
          1,
          3,
          0,
          1,
          1,
          0,
          0,
          0,
          2,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.7473582609026902,
      "energy_per_request_joules": 348.47257551306757,
      "avg_power_watts": 497.97820634482736,
      "median_itl_ms": 11.14979200065136,
      "p90_itl_ms": 11.312101781368256,
      "p95_itl_ms": 11.4034753292799,
      "p99_itl_ms": 53.9729418605566,
      "output_throughput_tokens_per_sec": 626.6968119007904,
      "avg_batch_size": 7.90084985835694,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          243,
          107,
          86,
          69,
          70,
          59,
          53,
          52,
          43,
          42,
          39,
          24,
          26,
          31,
          17,
          16,
          8,
          10,
          5,
          5,
          4,
          2,
          2,
          3,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.21964969150130492,
      "energy_per_request_joules": 99.74627113651152,
      "avg_power_watts": 648.1298844528815,
      "median_itl_ms": 24.107911624014378,
      "p90_itl_ms": 65.90593066066504,
      "p95_itl_ms": 71.27436995506287,
      "p99_itl_ms": 130.53565505892036,
      "output_throughput_tokens_per_sec": 2472.582665606881,
      "avg_batch_size": 95.48591549295774,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          237,
          119,
          73,
          68,
          70,
          60,
          53,
          60,
          61,
          44,
          35,
          31,
          23,
          15,
          21,
          12,
          10,
          12,
          5,
          4,
          2,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.1576766960092536,
      "energy_per_request_joules": 221.7610323131786,
      "avg_power_watts": 719.0804003733156,
      "median_itl_ms": 23.154423019150272,
      "p90_itl_ms": 40.37621141760609,
      "p95_itl_ms": 66.97639439080375,
      "p99_itl_ms": 88.08277491712941,
      "output_throughput_tokens_per_sec": 3622.185160374584,
      "avg_batch_size": 127.74460431654676,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          208,
          76,
          62,
          51,
          50,
          44,
          29,
          45,
          38,
          28,
          29,
          19,
          15,
          10,
          9,
          9,
          10,
          3,
          3,
          0,
          1,
          1,
          1,
          1,
          3,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          277
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.420760577941986,
      "energy_per_request_joules": 559.8601625589888,
      "avg_power_watts": 510.2741532840746,
      "median_itl_ms": 10.752652015071362,
      "p90_itl_ms": 22.949242484173737,
      "p95_itl_ms": 27.950524745392613,
      "p99_itl_ms": 50.69378914340633,
      "output_throughput_tokens_per_sec": 1160.4594034919587,
      "avg_batch_size": 15.939309056956116,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          199,
          75,
          60,
          62,
          47,
          46,
          46,
          37,
          33,
          30,
          23,
          30,
          20,
          24,
          8,
          11,
          7,
          2,
          3,
          1,
          1,
          0,
          1,
          0,
          2,
          0,
          1,
          1,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          251
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.14196225091495468,
      "energy_per_request_joules": 207.8776530829472,
      "avg_power_watts": 884.8116469596908,
      "median_itl_ms": 33.855443994980305,
      "p90_itl_ms": 68.01143300253898,
      "p95_itl_ms": 84.35218151134904,
      "p99_itl_ms": 107.42822773754584,
      "output_throughput_tokens_per_sec": 4793.052914190367,
      "avg_batch_size": 255.61928934010152,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          197,
          76,
          54,
          53,
          54,
          41,
          43,
          40,
          39,
          28,
          20,
          25,
          20,
          12,
          10,
          6,
          3,
          2,
          3,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          296
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3021101274247577,
      "energy_per_request_joules": 423.5923270329613,
      "avg_power_watts": 518.6896311880196,
      "median_itl_ms": 15.963502984959632,
      "p90_itl_ms": 31.53710138867609,
      "p95_itl_ms": 37.65478119021279,
      "p99_itl_ms": 56.877935969969116,
      "output_throughput_tokens_per_sec": 1614.5012704585167,
      "avg_batch_size": 31.92829705505762,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          206,
          89,
          54,
          50,
          39,
          44,
          41,
          39,
          34,
          27,
          26,
          17,
          18,
          11,
          10,
          13,
          12,
          7,
          1,
          4,
          2,
          2,
          0,
          1,
          2,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          273
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2047758552589889,
      "energy_per_request_joules": 278.49116362380187,
      "avg_power_watts": 565.9963988572973,
      "median_itl_ms": 20.077912515262142,
      "p90_itl_ms": 35.47910900088027,
      "p95_itl_ms": 45.731572841759764,
      "p99_itl_ms": 78.18046510219585,
      "output_throughput_tokens_per_sec": 2391.8047044463233,
      "avg_batch_size": 63.8372591006424,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          207,
          67,
          56,
          58,
          45,
          54,
          44,
          40,
          36,
          26,
          31,
          17,
          24,
          14,
          10,
          10,
          8,
          5,
          1,
          1,
          1,
          2,
          2,
          3,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          261
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.6566271907937724,
      "energy_per_request_joules": 878.8845938401172,
      "avg_power_watts": 677.5667436886174,
      "median_itl_ms": 7.196357488282956,
      "p90_itl_ms": 10.500433313427497,
      "p95_itl_ms": 12.215735411155038,
      "p99_itl_ms": 16.57573381176917,
      "output_throughput_tokens_per_sec": 1002.2707910271274,
      "avg_batch_size": 7.955950540958269,
      "output_length_distribution": {
        "bins": [
          3.0,
          84.86,
          166.72,
          248.57999999999998,
          330.44,
          412.3,
          494.15999999999997,
          576.02,
          657.88,
          739.74,
          821.6,
          903.46,
          985.3199999999999,
          1067.18,
          1149.04,
          1230.9,
          1312.76,
          1394.62,
          1476.48,
          1558.34,
          1640.2,
          1722.06,
          1803.92,
          1885.78,
          1967.6399999999999,
          2049.5,
          2131.36,
          2213.22,
          2295.08,
          2376.94,
          2458.8,
          2540.66,
          2622.52,
          2704.38,
          2786.24,
          2868.1,
          2949.96,
          3031.82,
          3113.68,
          3195.54,
          3277.4,
          3359.2599999999998,
          3441.12,
          3522.98,
          3604.84,
          3686.7,
          3768.56,
          3850.42,
          3932.2799999999997,
          4014.14,
          4096.0
        ],
        "counts": [
          212,
          91,
          53,
          64,
          38,
          35,
          38,
          41,
          30,
          30,
          23,
          32,
          14,
          15,
          16,
          10,
          12,
          2,
          3,
          2,
          0,
          3,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          256
        ]
      }
    }
  ]
}