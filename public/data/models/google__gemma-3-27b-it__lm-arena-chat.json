{
  "model_id": "google/gemma-3-27b-it",
  "task": "lm-arena-chat",
  "total_params_billions": 27.0,
  "activated_params_billions": 27.0,
  "architecture": "Dense Transformer",
  "weight_precision": "bfloat16",
  "output_length_distribution": {
    "bins": [
      2.0,
      83.88,
      165.76,
      247.64,
      329.52,
      411.4,
      493.28,
      575.16,
      657.04,
      738.92,
      820.8,
      902.68,
      984.56,
      1066.44,
      1148.32,
      1230.1999999999998,
      1312.08,
      1393.96,
      1475.84,
      1557.7199999999998,
      1639.6,
      1721.48,
      1803.36,
      1885.2399999999998,
      1967.12,
      2049.0,
      2130.88,
      2212.7599999999998,
      2294.64,
      2376.52,
      2458.3999999999996,
      2540.2799999999997,
      2622.16,
      2704.04,
      2785.92,
      2867.7999999999997,
      2949.68,
      3031.56,
      3113.4399999999996,
      3195.3199999999997,
      3277.2,
      3359.08,
      3440.96,
      3522.8399999999997,
      3604.72,
      3686.6,
      3768.4799999999996,
      3850.3599999999997,
      3932.24,
      4014.12,
      4096.0
    ],
    "counts": [
      3269,
      1369,
      1073,
      801,
      696,
      578,
      553,
      579,
      628,
      559,
      542,
      489,
      457,
      477,
      509,
      436,
      461,
      461,
      429,
      396,
      325,
      295,
      256,
      189,
      116,
      101,
      62,
      43,
      35,
      33,
      25,
      28,
      13,
      10,
      12,
      5,
      5,
      3,
      1,
      7,
      4,
      2,
      1,
      2,
      8,
      5,
      6,
      0,
      4,
      26
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8633876449488428,
      "energy_per_request_joules": 626.4096583623079,
      "avg_power_watts": 539.235305519997,
      "median_itl_ms": 25.104925502091646,
      "p90_itl_ms": 25.871247697796207,
      "p95_itl_ms": 26.233697752468288,
      "p99_itl_ms": 29.62442388670752,
      "output_throughput_tokens_per_sec": 605.6304900115186,
      "avg_batch_size": 15.966552315608919,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          203,
          91,
          59,
          60,
          41,
          26,
          30,
          34,
          50,
          26,
          35,
          34,
          28,
          25,
          37,
          27,
          24,
          27,
          36,
          28,
          16,
          24,
          12,
          10,
          11,
          8,
          3,
          4,
          3,
          1,
          1,
          3,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5251489012827982,
      "energy_per_request_joules": 375.1188860253971,
      "avg_power_watts": 571.4471831334777,
      "median_itl_ms": 28.28457900614012,
      "p90_itl_ms": 29.135124199092388,
      "p95_itl_ms": 29.889975202968344,
      "p99_itl_ms": 47.08953475928857,
      "output_throughput_tokens_per_sec": 1052.1862141792835,
      "avg_batch_size": 31.734567901234566,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          206,
          83,
          65,
          50,
          35,
          40,
          44,
          31,
          40,
          38,
          36,
          27,
          28,
          23,
          41,
          29,
          30,
          27,
          28,
          18,
          19,
          23,
          20,
          13,
          6,
          5,
          6,
          0,
          1,
          1,
          3,
          3,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.5108347604441896,
      "energy_per_request_joules": 1086.455440311296,
      "avg_power_watts": 510.4211657968816,
      "median_itl_ms": 23.425721999956295,
      "p90_itl_ms": 23.847885405120905,
      "p95_itl_ms": 24.02262069954304,
      "p99_itl_ms": 24.892170185485135,
      "output_throughput_tokens_per_sec": 332.6205512418793,
      "avg_batch_size": 7.988339552238806,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          202,
          86,
          66,
          55,
          41,
          40,
          27,
          40,
          42,
          26,
          32,
          34,
          33,
          37,
          18,
          23,
          39,
          28,
          32,
          25,
          20,
          15,
          20,
          11,
          4,
          5,
          3,
          2,
          2,
          5,
          0,
          3,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3061551500968861,
      "energy_per_request_joules": 215.93595124162627,
      "avg_power_watts": 1137.067654131935,
      "median_itl_ms": 31.995583325624466,
      "p90_itl_ms": 34.478471428155906,
      "p95_itl_ms": 40.37652723491191,
      "p99_itl_ms": 90.45042231678961,
      "output_throughput_tokens_per_sec": 3108.4218463947554,
      "avg_batch_size": 127.80357142857143,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          204,
          84,
          71,
          49,
          40,
          40,
          37,
          31,
          33,
          41,
          44,
          35,
          24,
          29,
          27,
          30,
          26,
          30,
          26,
          25,
          21,
          17,
          15,
          9,
          9,
          9,
          5,
          3,
          1,
          1,
          1,
          2,
          0,
          0,
          1,
          0,
          2,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.89120135421836,
      "energy_per_request_joules": 629.7643038286432,
      "avg_power_watts": 871.8307328742193,
      "median_itl_ms": 16.05406031012535,
      "p90_itl_ms": 16.38836171478033,
      "p95_itl_ms": 16.533141303807497,
      "p99_itl_ms": 19.79724021628478,
      "output_throughput_tokens_per_sec": 957.4647155060467,
      "avg_batch_size": 15.979310344827587,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          204,
          86,
          71,
          56,
          39,
          29,
          33,
          39,
          43,
          34,
          32,
          28,
          35,
          27,
          34,
          32,
          28,
          29,
          24,
          25,
          17,
          18,
          14,
          17,
          4,
          7,
          2,
          2,
          5,
          1,
          1,
          2,
          0,
          0,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2895194806492324,
      "energy_per_request_joules": 206.79777106974888,
      "avg_power_watts": 1210.4252130316443,
      "median_itl_ms": 39.78635370731354,
      "p90_itl_ms": 45.55294439196587,
      "p95_itl_ms": 62.64864569529892,
      "p99_itl_ms": 141.18140656501055,
      "output_throughput_tokens_per_sec": 3389.7690283137836,
      "avg_batch_size": 186.993006993007,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          208,
          77,
          75,
          50,
          46,
          37,
          33,
          32,
          41,
          32,
          31,
          28,
          35,
          35,
          30,
          22,
          33,
          27,
          24,
          25,
          20,
          22,
          16,
          11,
          5,
          5,
          4,
          5,
          1,
          2,
          1,
          1,
          2,
          1,
          0,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5544002112850572,
      "energy_per_request_joules": 393.541856231028,
      "avg_power_watts": 935.1903041557412,
      "median_itl_ms": 18.39852798730135,
      "p90_itl_ms": 18.943024426698685,
      "p95_itl_ms": 19.220177456736565,
      "p99_itl_ms": 28.431920204311563,
      "output_throughput_tokens_per_sec": 1592.540324022475,
      "avg_batch_size": 31.96135265700483,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          206,
          87,
          62,
          45,
          46,
          33,
          43,
          42,
          35,
          36,
          35,
          31,
          26,
          30,
          34,
          25,
          28,
          38,
          20,
          24,
          22,
          14,
          16,
          9,
          5,
          10,
          4,
          2,
          5,
          2,
          3,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.3880231496212807,
      "energy_per_request_joules": 275.8018528898932,
      "avg_power_watts": 1029.7000798888814,
      "median_itl_ms": 22.762875072658062,
      "p90_itl_ms": 23.736554197967052,
      "p95_itl_ms": 25.15928894281387,
      "p99_itl_ms": 51.5003892965615,
      "output_throughput_tokens_per_sec": 2470.0732826959825,
      "avg_batch_size": 63.91119691119691,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          199,
          91,
          67,
          48,
          46,
          31,
          38,
          44,
          39,
          36,
          30,
          27,
          33,
          36,
          27,
          25,
          21,
          33,
          24,
          29,
          18,
          22,
          13,
          7,
          12,
          6,
          4,
          3,
          4,
          1,
          3,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.5486857000794645,
      "energy_per_request_joules": 1101.4679192488024,
      "avg_power_watts": 812.9914005533786,
      "median_itl_ms": 15.06505161523819,
      "p90_itl_ms": 15.434471890330315,
      "p95_itl_ms": 15.643206611275673,
      "p99_itl_ms": 16.760235279798508,
      "output_throughput_tokens_per_sec": 519.7547636686174,
      "avg_batch_size": 7.9897810218978105,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          209,
          83,
          75,
          43,
          45,
          31,
          35,
          44,
          31,
          32,
          34,
          30,
          28,
          33,
          36,
          32,
          34,
          25,
          20,
          26,
          18,
          16,
          17,
          14,
          8,
          8,
          1,
          2,
          2,
          4,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          2,
          0,
          0,
          1,
          2
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 2,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.32930270385028265,
      "energy_per_request_joules": 233.97439485570175,
      "avg_power_watts": 1101.2112240966244,
      "median_itl_ms": 27.00553648173809,
      "p90_itl_ms": 28.48411053419113,
      "p95_itl_ms": 32.965153269469745,
      "p99_itl_ms": 63.57433378696441,
      "output_throughput_tokens_per_sec": 2994.1903342141627,
      "avg_batch_size": 95.84924623115577,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          209,
          80,
          68,
          47,
          46,
          47,
          31,
          37,
          32,
          41,
          38,
          23,
          26,
          30,
          25,
          25,
          32,
          33,
          24,
          22,
          31,
          19,
          16,
          11,
          9,
          4,
          4,
          2,
          0,
          2,
          2,
          1,
          1,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.7109459813163599,
      "energy_per_request_joules": 512.7246606174074,
      "avg_power_watts": 799.9626972468399,
      "median_itl_ms": 13.531176999094896,
      "p90_itl_ms": 18.042510224040598,
      "p95_itl_ms": 21.11968814861028,
      "p99_itl_ms": 35.80351640412114,
      "output_throughput_tokens_per_sec": 1101.4578302118568,
      "avg_batch_size": 15.939157566302653,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          203,
          87,
          65,
          45,
          47,
          37,
          39,
          25,
          45,
          32,
          31,
          38,
          20,
          38,
          34,
          30,
          28,
          26,
          28,
          26,
          18,
          15,
          16,
          14,
          9,
          6,
          5,
          3,
          1,
          2,
          0,
          2,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          2,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.4662487300306307,
      "energy_per_request_joules": 334.4961274728931,
      "avg_power_watts": 859.7463831809043,
      "median_itl_ms": 15.783169510541484,
      "p90_itl_ms": 23.05839310283773,
      "p95_itl_ms": 28.190243343124163,
      "p99_itl_ms": 44.58779252308886,
      "output_throughput_tokens_per_sec": 1773.1750991429765,
      "avg_batch_size": 31.92207792207792,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          202,
          91,
          57,
          60,
          45,
          37,
          32,
          37,
          34,
          40,
          29,
          26,
          33,
          33,
          35,
          27,
          25,
          31,
          25,
          20,
          19,
          13,
          23,
          9,
          13,
          6,
          3,
          3,
          2,
          3,
          1,
          1,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          3
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2937081711042084,
      "energy_per_request_joules": 209.05826375885408,
      "avg_power_watts": 899.3569074838913,
      "median_itl_ms": 19.319453509524465,
      "p90_itl_ms": 28.405169697362,
      "p95_itl_ms": 35.142206303135026,
      "p99_itl_ms": 47.441880211117734,
      "output_throughput_tokens_per_sec": 2727.1470444631955,
      "avg_batch_size": 63.83783783783784,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          205,
          83,
          77,
          44,
          47,
          32,
          33,
          33,
          46,
          36,
          33,
          33,
          23,
          23,
          36,
          24,
          29,
          24,
          35,
          23,
          26,
          22,
          12,
          12,
          5,
          7,
          8,
          3,
          0,
          2,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.3541189465741552,
      "energy_per_request_joules": 972.0061511013283,
      "avg_power_watts": 804.576084108009,
      "median_itl_ms": 13.200574001530185,
      "p90_itl_ms": 15.534032200230286,
      "p95_itl_ms": 17.338150605792176,
      "p99_itl_ms": 25.748170475708182,
      "output_throughput_tokens_per_sec": 588.6790884259476,
      "avg_batch_size": 7.974527526705012,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          205,
          89,
          58,
          48,
          40,
          40,
          34,
          45,
          32,
          35,
          42,
          29,
          28,
          29,
          32,
          28,
          27,
          25,
          26,
          24,
          21,
          22,
          17,
          19,
          5,
          5,
          3,
          1,
          1,
          1,
          2,
          3,
          3,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.2157048892701669,
      "energy_per_request_joules": 153.91765615400791,
      "avg_power_watts": 957.4702142580207,
      "median_itl_ms": 26.413496991153806,
      "p90_itl_ms": 35.59680680336897,
      "p95_itl_ms": 40.885346494906116,
      "p99_itl_ms": 60.39131319092144,
      "output_throughput_tokens_per_sec": 3719.0347497292682,
      "avg_batch_size": 127.81944444444444,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          199,
          86,
          70,
          54,
          42,
          42,
          31,
          31,
          47,
          38,
          26,
          35,
          30,
          19,
          33,
          30,
          24,
          34,
          25,
          33,
          17,
          17,
          18,
          8,
          5,
          5,
          5,
          5,
          2,
          1,
          1,
          2,
          2,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          2
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 1,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 1,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.17674549907133558,
      "energy_per_request_joules": 126.64505420566941,
      "avg_power_watts": 973.9345699315605,
      "median_itl_ms": 39.601704498636536,
      "p90_itl_ms": 54.347466814215295,
      "p95_itl_ms": 63.79778845002875,
      "p99_itl_ms": 111.33141885075047,
      "output_throughput_tokens_per_sec": 4196.034943904649,
      "avg_batch_size": 247.31,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          205,
          85,
          67,
          47,
          50,
          36,
          33,
          34,
          38,
          36,
          34,
          31,
          27,
          30,
          30,
          27,
          33,
          24,
          32,
          23,
          22,
          16,
          11,
          15,
          6,
          5,
          2,
          3,
          5,
          4,
          5,
          0,
          0,
          2,
          2,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          1
        ]
      }
    }
  ]
}