{
  "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
  "task": "lm-arena-chat",
  "total_params_billions": 235.0,
  "activated_params_billions": 22.0,
  "architecture": "MoE",
  "weight_precision": "fp8",
  "output_length_distribution": {
    "bins": [
      2.0,
      83.88,
      165.76,
      247.64,
      329.52,
      411.4,
      493.28,
      575.16,
      657.04,
      738.92,
      820.8,
      902.68,
      984.56,
      1066.44,
      1148.32,
      1230.1999999999998,
      1312.08,
      1393.96,
      1475.84,
      1557.7199999999998,
      1639.6,
      1721.48,
      1803.36,
      1885.2399999999998,
      1967.12,
      2049.0,
      2130.88,
      2212.7599999999998,
      2294.64,
      2376.52,
      2458.3999999999996,
      2540.2799999999997,
      2622.16,
      2704.04,
      2785.92,
      2867.7999999999997,
      2949.68,
      3031.56,
      3113.4399999999996,
      3195.3199999999997,
      3277.2,
      3359.08,
      3440.96,
      3522.8399999999997,
      3604.72,
      3686.6,
      3768.4799999999996,
      3850.3599999999997,
      3932.24,
      4014.12,
      4096.0
    ],
    "counts": [
      4306,
      1928,
      1410,
      1267,
      1254,
      1141,
      1042,
      1002,
      820,
      834,
      739,
      757,
      737,
      632,
      631,
      534,
      485,
      401,
      354,
      319,
      302,
      238,
      246,
      210,
      208,
      192,
      194,
      208,
      161,
      150,
      144,
      129,
      124,
      90,
      103,
      81,
      65,
      72,
      65,
      57,
      47,
      61,
      36,
      32,
      33,
      21,
      33,
      24,
      21,
      636
    ]
  },
  "configurations": [
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.100828839199788,
      "energy_per_request_joules": 949.5175501898179,
      "avg_output_len": 862.5478515625,
      "avg_power_watts": 2526.2738006461814,
      "median_itl_ms": 53.126478000194766,
      "p90_itl_ms": 56.17911879380699,
      "p95_itl_ms": 60.4096467985073,
      "p99_itl_ms": 105.0155172747327,
      "output_throughput_tokens_per_sec": 1861.8918685506842,
      "avg_batch_size": 127.89090909090909,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          185,
          77,
          55,
          57,
          50,
          44,
          53,
          41,
          37,
          35,
          34,
          24,
          30,
          22,
          29,
          25,
          23,
          11,
          11,
          15,
          14,
          13,
          7,
          10,
          9,
          6,
          6,
          11,
          6,
          8,
          5,
          3,
          5,
          10,
          4,
          2,
          2,
          0,
          5,
          5,
          0,
          2,
          2,
          0,
          3,
          1,
          2,
          1,
          0,
          24
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 5.2530122413493086,
      "energy_per_request_joules": 4577.523088122597,
      "avg_output_len": 871.4091796875,
      "avg_power_watts": 2209.765938093048,
      "median_itl_ms": 37.27450594305992,
      "p90_itl_ms": 37.85925358533859,
      "p95_itl_ms": 38.39360661804676,
      "p99_itl_ms": 67.92267538607122,
      "output_throughput_tokens_per_sec": 412.6975384545872,
      "avg_batch_size": 15.981186685962374,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          182,
          72,
          64,
          47,
          65,
          54,
          43,
          34,
          26,
          41,
          34,
          33,
          24,
          29,
          25,
          12,
          15,
          26,
          14,
          17,
          12,
          11,
          10,
          7,
          11,
          5,
          10,
          11,
          10,
          3,
          6,
          7,
          7,
          1,
          3,
          3,
          3,
          4,
          1,
          0,
          4,
          3,
          1,
          2,
          2,
          0,
          2,
          2,
          0,
          26
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8402416447543337,
      "energy_per_request_joules": 725.8982138983607,
      "avg_output_len": 863.916015625,
      "avg_power_watts": 2533.7933939862187,
      "median_itl_ms": 60.29347349976888,
      "p90_itl_ms": 63.27185699774418,
      "p95_itl_ms": 79.10008025646675,
      "p99_itl_ms": 119.78105250091176,
      "output_throughput_tokens_per_sec": 2217.0700629568514,
      "avg_batch_size": 191.75,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          187,
          81,
          63,
          48,
          57,
          43,
          34,
          50,
          29,
          36,
          31,
          21,
          37,
          23,
          25,
          29,
          17,
          16,
          19,
          18,
          9,
          12,
          13,
          4,
          8,
          7,
          11,
          7,
          6,
          5,
          7,
          7,
          8,
          5,
          3,
          3,
          2,
          2,
          2,
          2,
          4,
          1,
          0,
          0,
          1,
          1,
          2,
          1,
          0,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.009396535359466,
      "energy_per_request_joules": 2676.3674279469665,
      "avg_output_len": 889.3369140625,
      "avg_power_watts": 2201.57691316768,
      "median_itl_ms": 42.75384545326233,
      "p90_itl_ms": 43.42821389436722,
      "p95_itl_ms": 43.75521503388882,
      "p99_itl_ms": 69.76336650550363,
      "output_throughput_tokens_per_sec": 691.0539567407151,
      "avg_batch_size": 31.96929460580913,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          176,
          82,
          61,
          52,
          51,
          38,
          50,
          40,
          38,
          28,
          33,
          38,
          27,
          25,
          30,
          20,
          20,
          9,
          21,
          13,
          11,
          11,
          10,
          9,
          12,
          7,
          8,
          9,
          6,
          7,
          7,
          3,
          5,
          0,
          10,
          2,
          5,
          3,
          3,
          2,
          3,
          4,
          1,
          2,
          0,
          1,
          2,
          2,
          0,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.7413487365032319,
      "energy_per_request_joules": 1502.6156065506154,
      "avg_output_len": 862.9033203125,
      "avg_power_watts": 2198.09276787414,
      "median_itl_ms": 49.0025170147419,
      "p90_itl_ms": 49.943381920456886,
      "p95_itl_ms": 51.18645802140236,
      "p99_itl_ms": 90.44502444565296,
      "output_throughput_tokens_per_sec": 1137.410549054293,
      "avg_batch_size": 63.91310975609756,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          176,
          83,
          64,
          50,
          45,
          58,
          42,
          47,
          34,
          29,
          30,
          37,
          25,
          23,
          32,
          23,
          19,
          12,
          19,
          17,
          15,
          11,
          8,
          8,
          7,
          7,
          7,
          8,
          7,
          4,
          6,
          6,
          6,
          2,
          3,
          3,
          4,
          6,
          3,
          1,
          2,
          1,
          1,
          0,
          2,
          1,
          1,
          0,
          2,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 9.47137107940121,
      "energy_per_request_joules": 8100.649098460837,
      "avg_output_len": 855.27734375,
      "avg_power_watts": 2120.09324571957,
      "median_itl_ms": 35.24416498839855,
      "p90_itl_ms": 36.37699596583843,
      "p95_itl_ms": 36.59535786136985,
      "p99_itl_ms": 37.07177681848407,
      "output_throughput_tokens_per_sec": 222.6413878143073,
      "avg_batch_size": 7.9914574165156615,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          178,
          84,
          53,
          61,
          47,
          47,
          52,
          48,
          22,
          30,
          31,
          35,
          31,
          23,
          31,
          24,
          21,
          16,
          14,
          15,
          14,
          12,
          6,
          11,
          10,
          4,
          14,
          6,
          4,
          9,
          3,
          6,
          7,
          8,
          4,
          3,
          3,
          0,
          2,
          1,
          0,
          0,
          2,
          3,
          2,
          0,
          2,
          1,
          2,
          22
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 4,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 4,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.2680547621589875,
      "energy_per_request_joules": 1094.4910049232049,
      "avg_output_len": 863.1259765625,
      "avg_power_watts": 2222.2427318286004,
      "median_itl_ms": 52.73650772869587,
      "p90_itl_ms": 53.88541780412197,
      "p95_itl_ms": 58.11721198260784,
      "p99_itl_ms": 100.46623401343822,
      "output_throughput_tokens_per_sec": 1488.6583456074031,
      "avg_batch_size": 95.8923076923077,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          182,
          78,
          56,
          60,
          48,
          53,
          42,
          39,
          32,
          34,
          28,
          35,
          31,
          32,
          24,
          24,
          20,
          19,
          15,
          8,
          8,
          10,
          12,
          12,
          8,
          3,
          9,
          13,
          8,
          10,
          4,
          3,
          6,
          6,
          3,
          6,
          2,
          0,
          4,
          0,
          2,
          2,
          1,
          2,
          2,
          0,
          1,
          1,
          2,
          24
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.3641468688010399,
      "energy_per_request_joules": 1198.584199997726,
      "avg_output_len": 878.6328125,
      "avg_power_watts": 3874.1341684941376,
      "median_itl_ms": 42.144618928432465,
      "p90_itl_ms": 44.59398053586483,
      "p95_itl_ms": 48.33376640453935,
      "p99_itl_ms": 101.21062705293299,
      "output_throughput_tokens_per_sec": 2346.234118747615,
      "avg_batch_size": 127.82608695652173,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          183,
          76,
          64,
          55,
          43,
          48,
          46,
          41,
          37,
          44,
          18,
          31,
          26,
          28,
          33,
          24,
          17,
          18,
          16,
          10,
          14,
          12,
          6,
          2,
          7,
          10,
          9,
          8,
          6,
          10,
          10,
          5,
          2,
          5,
          6,
          3,
          3,
          1,
          2,
          2,
          2,
          3,
          2,
          1,
          1,
          0,
          1,
          2,
          0,
          31
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 6.296944834248159,
      "energy_per_request_joules": 5495.996818900514,
      "avg_output_len": 872.8037109375,
      "avg_power_watts": 3638.3735050517316,
      "median_itl_ms": 26.786433532834053,
      "p90_itl_ms": 27.224621549248695,
      "p95_itl_ms": 27.381783351302147,
      "p99_itl_ms": 82.417909540236,
      "output_throughput_tokens_per_sec": 567.3633207099339,
      "avg_batch_size": 15.984137475214805,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          179,
          81,
          59,
          45,
          55,
          47,
          47,
          42,
          33,
          40,
          32,
          27,
          32,
          31,
          20,
          21,
          26,
          14,
          12,
          13,
          17,
          9,
          10,
          13,
          5,
          6,
          5,
          7,
          6,
          8,
          9,
          4,
          6,
          4,
          7,
          3,
          2,
          2,
          4,
          1,
          2,
          5,
          2,
          2,
          1,
          0,
          0,
          3,
          1,
          24
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 192,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.1039671967014222,
      "energy_per_request_joules": 979.1941073359543,
      "avg_output_len": 886.9775390625,
      "avg_power_watts": 3984.6582773008904,
      "median_itl_ms": 49.6076624840498,
      "p90_itl_ms": 53.009020164608955,
      "p95_itl_ms": 59.90309827029705,
      "p99_itl_ms": 116.0414159297943,
      "output_throughput_tokens_per_sec": 2732.7665930198195,
      "avg_batch_size": 191.76960784313727,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          175,
          85,
          56,
          54,
          58,
          41,
          38,
          43,
          38,
          38,
          31,
          28,
          36,
          21,
          24,
          16,
          25,
          14,
          18,
          13,
          16,
          8,
          14,
          7,
          5,
          9,
          9,
          6,
          8,
          8,
          4,
          8,
          6,
          2,
          5,
          2,
          1,
          2,
          6,
          3,
          2,
          2,
          1,
          2,
          3,
          3,
          1,
          0,
          1,
          28
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.9503259044460555,
      "energy_per_request_joules": 819.2440372120919,
      "avg_output_len": 862.06640625,
      "avg_power_watts": 4107.038743075696,
      "median_itl_ms": 54.93493750691414,
      "p90_itl_ms": 59.989769384264946,
      "p95_itl_ms": 67.8470803424716,
      "p99_itl_ms": 123.05417845025649,
      "output_throughput_tokens_per_sec": 3030.4450437915193,
      "avg_batch_size": 255.72972972972974,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          176,
          79,
          64,
          62,
          47,
          50,
          46,
          42,
          34,
          28,
          31,
          31,
          31,
          28,
          23,
          26,
          20,
          20,
          11,
          9,
          15,
          6,
          11,
          8,
          7,
          9,
          7,
          8,
          14,
          9,
          3,
          6,
          9,
          2,
          3,
          4,
          2,
          5,
          2,
          1,
          1,
          1,
          0,
          1,
          3,
          2,
          2,
          1,
          1,
          23
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 3.6444220874251374,
      "energy_per_request_joules": 3179.0357930716477,
      "avg_output_len": 872.3017578125,
      "avg_power_watts": 3705.948513878366,
      "median_itl_ms": 30.15841171145439,
      "p90_itl_ms": 30.648254230618477,
      "p95_itl_ms": 30.96773363649845,
      "p99_itl_ms": 81.87093801796436,
      "output_throughput_tokens_per_sec": 962.5432143424094,
      "avg_batch_size": 31.97048406139315,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          185,
          76,
          55,
          53,
          53,
          51,
          33,
          45,
          43,
          35,
          30,
          29,
          27,
          26,
          32,
          22,
          21,
          23,
          10,
          12,
          15,
          7,
          8,
          6,
          10,
          14,
          4,
          9,
          8,
          8,
          5,
          6,
          0,
          3,
          3,
          4,
          3,
          3,
          4,
          1,
          2,
          3,
          2,
          1,
          4,
          0,
          0,
          0,
          1,
          29
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 384,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8259377686610403,
      "energy_per_request_joules": 721.5324594315263,
      "avg_output_len": 873.591796875,
      "avg_power_watts": 4148.866789614736,
      "median_itl_ms": 66.64565298706293,
      "p90_itl_ms": 75.68840105086566,
      "p95_itl_ms": 103.03171053528784,
      "p99_itl_ms": 160.3875942155719,
      "output_throughput_tokens_per_sec": 3386.334192708989,
      "avg_batch_size": 383.46,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          183,
          83,
          48,
          44,
          58,
          50,
          49,
          40,
          34,
          35,
          31,
          27,
          25,
          37,
          26,
          29,
          23,
          14,
          16,
          11,
          13,
          6,
          11,
          8,
          9,
          4,
          7,
          11,
          4,
          4,
          8,
          6,
          4,
          6,
          5,
          3,
          5,
          3,
          1,
          5,
          2,
          4,
          2,
          1,
          0,
          2,
          3,
          0,
          1,
          23
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 512,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.7414699218950929,
      "energy_per_request_joules": 653.5586701886854,
      "avg_output_len": 881.4365234375,
      "avg_power_watts": 3960.90471917865,
      "median_itl_ms": 75.83757489919662,
      "p90_itl_ms": 115.92580489814281,
      "p95_itl_ms": 130.9320306405425,
      "p99_itl_ms": 197.445574700832,
      "output_throughput_tokens_per_sec": 3466.694034419854,
      "avg_batch_size": 511.18666666666667,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          175,
          82,
          53,
          59,
          54,
          49,
          36,
          43,
          32,
          32,
          38,
          38,
          31,
          23,
          29,
          23,
          22,
          16,
          11,
          11,
          7,
          8,
          7,
          10,
          16,
          8,
          8,
          11,
          10,
          6,
          5,
          4,
          3,
          4,
          3,
          3,
          5,
          6,
          1,
          1,
          2,
          2,
          0,
          2,
          1,
          1,
          1,
          3,
          2,
          27
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.1159702941061393,
      "energy_per_request_joules": 1854.4103294013923,
      "avg_output_len": 876.3876953125,
      "avg_power_watts": 3725.2104772419757,
      "median_itl_ms": 34.669145941734314,
      "p90_itl_ms": 35.32791547477245,
      "p95_itl_ms": 36.43390350043774,
      "p99_itl_ms": 83.94805938005449,
      "output_throughput_tokens_per_sec": 1592.3839744255804,
      "avg_batch_size": 63.937106918238996,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          179,
          79,
          63,
          56,
          37,
          58,
          42,
          39,
          32,
          43,
          28,
          28,
          39,
          24,
          24,
          20,
          22,
          19,
          7,
          13,
          16,
          11,
          11,
          11,
          8,
          8,
          8,
          13,
          4,
          3,
          5,
          8,
          4,
          5,
          3,
          4,
          2,
          2,
          5,
          3,
          1,
          2,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          31
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 11.389550351963965,
      "energy_per_request_joules": 9984.831726816567,
      "avg_output_len": 876.666015625,
      "avg_power_watts": 3596.4456629623637,
      "median_itl_ms": 24.736017920076847,
      "p90_itl_ms": 24.99899808317423,
      "p95_itl_ms": 25.11235298588872,
      "p99_itl_ms": 25.919590368866917,
      "output_throughput_tokens_per_sec": 313.8238698026664,
      "avg_batch_size": 7.992145662263478,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          181,
          78,
          63,
          52,
          60,
          36,
          46,
          42,
          41,
          24,
          28,
          34,
          24,
          37,
          21,
          17,
          23,
          19,
          19,
          11,
          10,
          8,
          11,
          10,
          12,
          10,
          9,
          6,
          9,
          5,
          6,
          2,
          5,
          4,
          6,
          5,
          3,
          6,
          2,
          2,
          0,
          2,
          2,
          0,
          0,
          3,
          0,
          3,
          1,
          26
        ]
      }
    },
    {
      "gpu_model": "H100",
      "num_gpus": 8,
      "max_num_seqs": 96,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 8,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.6266692596103178,
      "energy_per_request_joules": 1419.7867944188235,
      "avg_output_len": 872.818359375,
      "avg_power_watts": 3817.2735790542147,
      "median_itl_ms": 38.73824793845415,
      "p90_itl_ms": 39.73771445453167,
      "p95_itl_ms": 41.582258231937885,
      "p99_itl_ms": 89.86550176516175,
      "output_throughput_tokens_per_sec": 2003.450517998498,
      "avg_batch_size": 95.9093567251462,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          177,
          88,
          45,
          63,
          52,
          52,
          41,
          39,
          39,
          32,
          35,
          27,
          36,
          20,
          31,
          23,
          14,
          17,
          19,
          15,
          10,
          4,
          12,
          14,
          5,
          13,
          8,
          7,
          5,
          2,
          2,
          5,
          8,
          2,
          4,
          1,
          3,
          5,
          1,
          6,
          0,
          4,
          2,
          0,
          0,
          2,
          1,
          1,
          1,
          31
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 128,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.8217263225202562,
      "energy_per_request_joules": 727.0552650013819,
      "avg_output_len": 884.7900390625,
      "avg_power_watts": 1853.3838545799715,
      "median_itl_ms": 53.917051991447806,
      "p90_itl_ms": 57.904711982700974,
      "p95_itl_ms": 61.82281699148007,
      "p99_itl_ms": 108.06301402044483,
      "output_throughput_tokens_per_sec": 1805.5393989354168,
      "avg_batch_size": 127.85227272727273,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          178,
          80,
          58,
          60,
          43,
          42,
          43,
          44,
          40,
          32,
          31,
          31,
          33,
          28,
          22,
          25,
          16,
          16,
          20,
          10,
          12,
          14,
          9,
          6,
          10,
          14,
          10,
          7,
          5,
          4,
          7,
          6,
          6,
          5,
          5,
          4,
          1,
          1,
          0,
          1,
          2,
          4,
          3,
          2,
          3,
          1,
          2,
          0,
          0,
          28
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 16,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 4.669943195513622,
      "energy_per_request_joules": 4068.3596537103085,
      "avg_output_len": 871.1796875,
      "avg_power_watts": 1818.2945061663515,
      "median_itl_ms": 40.43045798607636,
      "p90_itl_ms": 41.137090703705326,
      "p95_itl_ms": 41.47334825247526,
      "p99_itl_ms": 82.23042580037145,
      "output_throughput_tokens_per_sec": 383.01404784384545,
      "avg_batch_size": 15.979510022271715,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          180,
          78,
          66,
          46,
          61,
          42,
          36,
          45,
          35,
          41,
          29,
          30,
          42,
          21,
          15,
          25,
          24,
          21,
          13,
          12,
          11,
          11,
          9,
          9,
          8,
          9,
          5,
          6,
          12,
          5,
          7,
          6,
          3,
          2,
          4,
          2,
          1,
          3,
          5,
          3,
          4,
          2,
          2,
          1,
          0,
          0,
          1,
          1,
          0,
          30
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 256,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 0.5006937029286922,
      "energy_per_request_joules": 438.619907732891,
      "avg_output_len": 876.0244140625,
      "avg_power_watts": 1890.8444703429448,
      "median_itl_ms": 64.47548398864456,
      "p90_itl_ms": 70.13620478683151,
      "p95_itl_ms": 80.76567870884868,
      "p99_itl_ms": 119.52163472480606,
      "output_throughput_tokens_per_sec": 3027.3774194003,
      "avg_batch_size": 255.74937965260546,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          356,
          158,
          124,
          98,
          110,
          97,
          83,
          82,
          66,
          71,
          64,
          65,
          45,
          56,
          64,
          37,
          44,
          36,
          28,
          29,
          25,
          26,
          23,
          22,
          19,
          11,
          15,
          14,
          11,
          10,
          12,
          15,
          8,
          3,
          8,
          5,
          8,
          7,
          6,
          7,
          6,
          7,
          2,
          5,
          1,
          2,
          3,
          1,
          0,
          53
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 32,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 2.6271712915194674,
      "energy_per_request_joules": 2317.5088691133965,
      "avg_output_len": 882.130859375,
      "avg_power_watts": 1894.6462274541648,
      "median_itl_ms": 43.2236600026954,
      "p90_itl_ms": 44.146505699609406,
      "p95_itl_ms": 44.5199030888034,
      "p99_itl_ms": 90.64704591408372,
      "output_throughput_tokens_per_sec": 692.4756994576509,
      "avg_batch_size": 31.96029776674938,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          177,
          80,
          65,
          44,
          57,
          44,
          46,
          35,
          28,
          33,
          33,
          33,
          47,
          25,
          25,
          18,
          23,
          14,
          16,
          13,
          15,
          9,
          14,
          6,
          6,
          9,
          6,
          14,
          5,
          8,
          6,
          3,
          2,
          4,
          5,
          6,
          3,
          2,
          1,
          5,
          1,
          1,
          2,
          3,
          0,
          0,
          2,
          0,
          2,
          28
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 64,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 1.4719871138494172,
      "energy_per_request_joules": 1279.8051087597003,
      "avg_output_len": 869.4404296875,
      "avg_power_watts": 1892.042070500693,
      "median_itl_ms": 47.80994201428257,
      "p90_itl_ms": 49.54287161817774,
      "p95_itl_ms": 51.0372142191045,
      "p99_itl_ms": 93.26520285278093,
      "output_throughput_tokens_per_sec": 1123.240198600195,
      "avg_batch_size": 63.93798449612403,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          182,
          84,
          52,
          47,
          51,
          53,
          44,
          45,
          31,
          41,
          27,
          38,
          25,
          27,
          28,
          25,
          14,
          15,
          13,
          17,
          11,
          9,
          10,
          8,
          10,
          6,
          10,
          8,
          6,
          7,
          9,
          6,
          7,
          5,
          2,
          4,
          1,
          4,
          1,
          4,
          2,
          4,
          3,
          0,
          2,
          0,
          0,
          1,
          1,
          24
        ]
      }
    },
    {
      "gpu_model": "B200",
      "num_gpus": 2,
      "max_num_seqs": 8,
      "max_num_batched_tokens": null,
      "parallelization": {
        "tensor_parallel": 1,
        "expert_parallel": 2,
        "data_parallel": 1,
        "notes": ""
      },
      "energy_per_token_joules": 8.421096003608643,
      "energy_per_request_joules": 7367.011627281942,
      "avg_output_len": 874.828125,
      "avg_power_watts": 1805.668383628926,
      "median_itl_ms": 36.719368494232185,
      "p90_itl_ms": 37.812683993251994,
      "p95_itl_ms": 37.99658724456094,
      "p99_itl_ms": 38.57398231921252,
      "output_throughput_tokens_per_sec": 212.54132774460922,
      "avg_batch_size": 7.990046127700898,
      "output_length_distribution": {
        "bins": [
          2.0,
          83.88,
          165.76,
          247.64,
          329.52,
          411.4,
          493.28,
          575.16,
          657.04,
          738.92,
          820.8,
          902.68,
          984.56,
          1066.44,
          1148.32,
          1230.1999999999998,
          1312.08,
          1393.96,
          1475.84,
          1557.7199999999998,
          1639.6,
          1721.48,
          1803.36,
          1885.2399999999998,
          1967.12,
          2049.0,
          2130.88,
          2212.7599999999998,
          2294.64,
          2376.52,
          2458.3999999999996,
          2540.2799999999997,
          2622.16,
          2704.04,
          2785.92,
          2867.7999999999997,
          2949.68,
          3031.56,
          3113.4399999999996,
          3195.3199999999997,
          3277.2,
          3359.08,
          3440.96,
          3522.8399999999997,
          3604.72,
          3686.6,
          3768.4799999999996,
          3850.3599999999997,
          3932.24,
          4014.12,
          4096.0
        ],
        "counts": [
          174,
          84,
          59,
          54,
          52,
          44,
          50,
          36,
          39,
          32,
          32,
          37,
          33,
          23,
          18,
          26,
          16,
          16,
          12,
          17,
          12,
          10,
          14,
          9,
          6,
          13,
          9,
          8,
          1,
          7,
          8,
          4,
          7,
          2,
          4,
          6,
          1,
          5,
          4,
          1,
          3,
          2,
          2,
          2,
          1,
          1,
          3,
          0,
          2,
          23
        ]
      }
    }
  ]
}