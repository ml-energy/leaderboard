- command:
    - "python scripts/benchmark_one_model.py --model {{ model }} --result-root results/joule --gpu-ids {{ gpu }} --backends vllm --server-images mlenergy/vllm:v0.5.4-openai --request-rate inf --power-limits 700 --max-num-seqs 1536 1280 1024 768 512 320 256 192 128 64 32 --data-dup-factor 4"
  model:
    - meta-llama/Meta-Llama-3.1-8B-Instruct
    - google/gemma-2-2b-it
    - google/gemma-2-9b-it
    - mistralai/Mistral-7B-Instruct-v0.3
    - mistralai/Mistral-Nemo-Instruct-2407
    - microsoft/Phi-3-mini-4k-instruct
    - microsoft/Phi-3-small-8k-instruct
    - microsoft/Phi-3-medium-4k-instruct
